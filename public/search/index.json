[{"content":" 实验手册\n实验代码仓库\nexp6：20条指令单周期CPU 目标：\n学习使用龙芯提供的基于trace比对的调试框架 学习龙芯提供的单周期CPU的数据通路 学习基本仿真调试思路 学习使用trace比对的CPU系统调试 数据通路 数据通路是芯片上最重要的“路”之一，介于初学时对CPU的数据通路不够了解，自己动手拼搭模块会无从下手，我们建议学习现有的CPU的数据通路，这里我们采用龙芯实验代码仓库中提供的单周期CPU（存在错误需要调试）。\n简单的数据通路结构图，请自己理解给出的单周期CPU的结构、不同部件之间如何协同工作、各个控制信号如何控制数据的流动。\nCPU的debug实际上就是在观察数据通路上各处流动的数据是不是我们想要的数据，然后修改控制信号的逻辑或者数据通路本身以获得预期结果。\n调试Tips 善用反汇编文件（func/obj/test.s）查询某个PC对应的指令 当CPU的第一条指令都没有成功运行，而你一点思路都没有的话，不妨试着在数据通路图上模拟运行一遍第一条指令 运行过程中的Error一般出在之前成功运行的指令都没有用的部分 exp7：不考虑相关冲突处理的简单流水线CPU 目标：\n学习流水线的基本概念（课上讲义、百度、计算机体系结构基础） 多周期CPU的概念 修改单周期CPU，使其流水线化 流水线的作用 随着CPU电路中组合逻辑部分越来越复杂，其延迟也必然增大，整个电路的频率就会变低。\n在单周期CPU中，每个时钟周期必须完成取指、译码、读寄存器、执行、访存等很多组合逻辑工作，为了保证在下一个时钟上升沿到来之前准备好寄存器堆的写数据，需要将每个时钟周期的间隔拉长，导致处理器的主频无法提高，使用流水线技术可以提高处理器的主频。\n在这里我将跳过流水线的基本概念，直接分析经典的五级静态单发射流水线CPU。\n修改步骤 划分流水级 按照经典五级流水线，我们将单周期CPU的处理流程划分为五个阶段：\nIF（取指）：从指令存储器读取指令。 ID（译码）：解析指令，读取寄存器堆数据。 EX（执行）：执行算术/逻辑运算或计算地址。 MEM（访存）：访问数据存储器（如加载/存储指令）。 WB（写回）：将结果写回寄存器堆。 插入流水线寄存器 在流水线中，每一级都可能处理着不同的指令，这时我们就需要一些存储当前级指令信息的级间寄存器，这些级间寄存器储存着指令相关的数据和控制信息以供当前级处理使用。\n以下是流水线化后的CPU数据通路示意图：\n调试Tips 调整CPU顶层接口，增加指令RAM的片选信号 inst_sram_en 和数据RAM的片选信号 data_sram_en 调整CPU顶层接口，将inst_sram_we 和 data_sram_we 都从1比特的写使能调整为4比特的字节写使能 在流水线CPU中，调试定错可以基于级间寄存器的内容判断 各级流水线中命名需要有命名逻辑，很容易找不到 exp8：阻塞技术解决相关引发的冲突 目标：\n流水线CPU的运行过程 流水线冲突以及如何处理流水线冲突（阻塞方法） 流水线冲突 流水线冲突（Hazard） 是指由于指令在流水线中并行执行时产生的依赖关系或资源竞争，导致后续指令无法正常执行的现象。主要分为三类：数据相关、控制相关和结构相关。\n数据冲突 数据相关根据冲突访问读和写的次序可以分为3种。\n写后读（Read After Write,简称RAW）相关，即后面指令要用到前面指令所写的数据，也称为真相关。 写后写（Write After Write,简称WAW）相关，即两条指令写同一个单元，也称为输出相关。 读后写（Write After Read,简称WAR）相关，即后面的指令覆盖前面指令所读的单元，也称为反相关。 在静态五级流水线CPU中，仅会出现RAW相关流水线冲突，WAW和WAR在乱序流水线中需要考虑。\n对于以下两条指令：\n1 2 add.w $r2, $r1, $r1 add.w $r3, $r2, $r2 第2条指令的源寄存器r2为第1条指令的目的寄存器，即存在RAW相关。其时空图如下：\n我们注意到在第3个时钟周期时，第2条指令读取r2寄存器的值，但此时第1条指令未执行写回，也就是说读取到r2寄存器的值并非是最新的、正确的值，第2条指令的运行数据必然是错误的。\n为了保证执行的正确，一种最直接的解决方式是让第2条指令在译码阶段等待（阻塞）3拍，直到第1条指令将结果写入寄存器后才能读取寄存器，进入后续的执行阶段。这时时空图如下：\n控制冲突 控制冲突主要是由于分支/跳转指令导致后续指令的取指目标不确定。\n对于以下的指令序列：\n1 2 3 jirl $r0, $r1, 0 add.w $r2, $r1, $r1 add.w $r7, $r8, $r9 其时空图如下：\n我们注意到在第3周期jirl指令被执行的时候，两条add.w指令已经进入流水线，而这两条指令是不需要被执行的，这就引发了控制冲突。\n为了解决这个问题，可以通过在取指阶段引入2拍的流水线阻塞来解决，此时时空图如下：\n在单发射5级静态流水线中，如果增加专用的运算资源将转移指令条件判断和计算下一条指令PC的处理调整到译码阶段，那么转移指令后面的指令只需要在取指阶段等1拍。\n在前文中的数据通路图中，我其实已经将跳转处理调整到译码阶段了。\n为更进一步减少由控制相关引起的阻塞，可以采用转移指令的延迟槽技术，在定义指令系统的时候就明确转移指令延迟槽指令的执行不依赖于转移指令的结果（如MIPS），这样转移指令后面的指令在取指阶段1拍也不用等。\n另外一种思路是分支预测，通过合理的方式对跳转目标PC的预测以消除等待计算的时间，具体可参考《超标量处理器设计》一书中分支预测相关部分。\n结构冲突 结构相关引起冲突的原因是两条指令要同时访问流水线中的同一个功能部件。\n回顾前文中使用阻塞处理冲突时，被阻塞的指令之后的指令也由于执行部件被占用而无法在流水线中执行，一起被堵在后面。\n再回顾前文中数据通路，我们发现有指令、数据两个存储器（哈佛架构），这其实也是为了解决取指和访存同时读取存储器的结构冲突。\n流水线冲突的解决 流水线冲突的解决方式主要分为两种：阻塞和旁路。\n阻塞 在前文讲解流水线冲突的过程中，我们均采用的是阻塞方法，即一个字：等！等到该准备的都准备好了再执行。其优点是控制逻辑简单，无需添加很多电路单元；当然其缺点也很明显，CPU大部分时间都在摸鱼了，造成了很大的性能浪费。\n旁路 旁路技术主要原理是添加一些专用计算模块，以降低甚至消除阻塞时间，体现了芯片设计中的以空间换时间的思路。\n例如前文中将分支跳转的执行从执行级调整到译码级，并增加专用的分支跳转模块。\n修改方式 将流水线中添加阻塞控制的思路在这里提供两种：\n控制单元 添加一个流水线运行控制单元，其负责处理各级流水线发出的阻塞请求，并给各流水级发出阻塞信号，阻塞信号作为级间寄存器的使能信号即可。\n握手机制 握手机制需要在各级流水线中添加握手信号，当两方握上手后使能级间寄存器。\n1 2 3 4 5 always @(posedge clk) begin if (for_valid \u0026amp;\u0026amp; next_allowin) begin buffer \u0026lt;= for_input; end end for_valid为前级有效信号 next_allowin为后级允许进入信号 buffer为级间寄存器 for_input为前级输入数据 注意如果使用后级允许进入信号生成本级允许信号的话，可能会使关键路径贯穿整个流水线，在流水线深度较深的情况下需要注意。\n调试Tips 在已有部件正确的情况下，只需要判断新加入的部件是否正常运行 优先关注控制信号是否正确 如果需要可以先进行单独部件的仿真测试 exp9：前递技术解决相关引发的冲突 目标：\n流水线冲突的概念及阻塞处理实现 使用前递技术处理数据冲突 前递技术 让我们重新观察使用阻塞方式处理数据冲突的时空图：\n对于add.w指令，在流水线的执行级已经将结果计算出，如果我们可以提前将结果发送给译码级处，就不用阻塞流水线等待了，这就是流水线前递（Forwarding）技术。同样，我们也要添加访存级、写回级的数据前递回译码级的数据通路。\n数据通路 以下是添加了前递通路的数据通路参考：\n调试Tips 同样的我们几乎只需要关注前推处理的逻辑 注意ld.w等访存指令需要在访存级结束才能有正确数据 exp10：算术逻辑运算指令和乘除法运算指令添加 目标：\n熟悉CPU的数据通路 学习如何控制数据流动 学习如何添加指令 学习如何使用IP核（基本方法参考RAM IP核定制，具体IP核请自行搜索） 拓展：学习乘法器、除法器原理 算术逻辑运算类指令 需要添加的指令有slti、sltui、andi、ori、xori、sll.w、srl.w、sra.w、pcaddu12i，指令具体信息可参考我的LoongArch32r指令表。\n首先，我们来观察需要添加的指令有什么特点、和我们已有的指令有什么联系吗？\nslti、sltui等与已添加的指令slt、sltu等仅在源操作数2从寄存器还是立即数中取值有区别，所以我们可以几乎复用slt、sltu等指令的数据通路，仅需在源操作数2的仲裁信号src2_is_imm处修改即可 sll.w、srl.w等与已添加的指令slli.w、srli.w等仅在源操作数2从寄存器还是立即数中取值有区别，所以我们也可以复用 pcaddu12i指令实际上等同addi.w的运算过程，只不过源操作数1为该指令的PC值，源操作数2的立即数处理为在最低位后接12bit零，所以我们只需增加一些仲裁和处理逻辑即可 你可能会在添加pcaddu12i的时候注意到，源操作数1的仲裁信号（src1_is_pc）和源操作数2的立即数处理和仲裁信号（need_si20、src2_is_imm）已经存在了，不需要额外添加。如果你傻乎乎的又新加了两块逻辑，那么你应该重新复习一下完整的数据通路了。\n当我们需要新添加一些东西的时候，首先需要考虑一下能否复用已有的，或者进行一些小小的修改，而非直接开堆。冗杂的堆砌不仅是对资源的浪费，对代码可读性也是一种灾难。\n经过这一通分析，我想完成这9条指令对你来说是易如反掌了吧(　‘◟ ‘)✧\n你可以现在开始仿真debug，当pass了29个点的时候这些指令就没问题了，也可以接着添加最后一起仿真debug。\n乘除运算类指令 需要添加的指令有mul.w、mulh.w、mulh.wu、div.w、mod.w、div.wu、mod.wu，指令具体信息可参考我的LoongArch32r指令表。\n首先，我们还是分析一下这些指令\n没有乘除法运算单元，肯定要添加乘除法器 （或者你也可以试试用加减法来算） 数据流动与add.w等 3R-type 指令相同，仅运算方式不一样（指令编码格式相同的指令的数据流动几乎相同） 指令间的区别为有/无符号运算、如何选取结果输出 这样来说，我们只需要新加一个乘除法运算单元，其它部分依照add.w复用即可。\n使用Vivado IP核实现 乘法 最简单的方式为：\n1 2 3 4 5 6 wire [31:0] src1, src2; wire [63:0] unsigned_prod; wire [63:0] signed_prod; assign unsigned_prod = src1 * src2; assign signed_prod = $signed(src1) * $signed(src2); Vivado中的综合工具遇到上面代码中的“＊’’运算符时，会自动调用片上的DSP48（内含固化的16位乘法器电路）实现，最终实现的电路的时序通常不错，也几乎不消耗LUT资源，推荐大家使用。\n也可以使用IP核Multiplier实现。\n除法 使用Divider GeneratorIP核实现。\n如何创建 首先找到Divider GeneratorIP核：\n开始定制Divider GeneratorIP核：\n开始建立IP核：\n实例化IP核：\n如何使用 目前Vivado中提供的除法器IP一定是AXI接口的，所以接下来我们对模块顶层信号及其工作方式进行基本介绍。\n在定制IP核的界面中（可通过双击IP核的资源名称重新打开定制界面），左侧有接口信号图\n总体上我们会看到时钟信号、被除数、除数通道以及输出（商和余数）通道。\n对于被除数、除数通道，其有相同的信号组成\ntdata信号为被除数、除数数据输入信号 tready、tvalid为一对握手信号。tvalid是请求信号，tready是应答信号，在时钟上升沿到来时，如果tvalid和tready都等于1则视为成功的握手，发送方的数据写入接收方的缓存中 需要注意的是在握手成功后，一定要把tvalid清0，如果再次握手成功的话将会被视为一个新的除法运算。\n对于输出（商和余数）通道\ntdata信号为商和余数数据输出信号，其中 [63:32] 位存放的是商，第 [31:0] 位存放的是余数 tvalid信号为输出有效信号，高电平表示除法计算完成，tdata线上为计算结果 自行设计电路实现 可参考附录中的乘法器、除法器部分以及其它网络资源。\n注意到IP核中无论是乘法还是除法都只能固定计算有/无符号数，这样需要实例化两个运算单元分别进行运算，这样看起来非常浪费资源。我们可以采取一些措施将符号单独计算，全部转化为无符号数处理；也可以将32位的运算全部转化为33位有符号运算，只要根据有/无符号在第33位补充符号位/0即可。\nexp11：转移指令和访存指令添加 目标：\n熟悉CPU的数据通路 练习如何修改数据流动 练习如何添加指令 了解“地址对齐” 转移指令 需要添加的指令有blt、bge、bltu、bgeu，指令具体信息可参考我的LoongArch32r指令表。\n相信经过exp10的分析，大家很快就能发现这些b指令都是换汤不换药（仅跳转条件判断不同）的一类指令，只要照着如beq指令的过程添加即可。\n访存指令 需要添加的指令有ld.b、ld.h、ld.bu、ld.hu、st.b、st.h，指令具体信息可参考我的LoongArch32r指令表。\n在看完手册后，我们发现普通访存指令的数据通路、控制逻辑都是相同的，区别仅在处理的数据位宽不同。\n接下来让我们回忆一下我们的data_sram，它是一个宽度为32的Memory单元，每次读写的数据为32位。\n当读回32位数据后，我们选择访存地址对应的字/半字/字节并按照有/无符号扩展到32位就是读取的数据；当需要写入时，我们将需要写入的字/半字/字节按照访存地址对应的位置填入32位数据的位置，并将字节写使能信号的对应位使能即可。\n地址对齐 访存地址对应的位置即地址对齐，其有一定的规则，假设存储器中存储的数据如下图所示，每个字节中存储其所在字节地址\n假如运行ld.w，访存地址为00B，则得到的数据为03020100H。（Loongarch采用小尾端的存储方式）\n假如运行ld.h，存储器返回数据为03020100H\n访存地址末尾为00B，最终得到00000100H。 访存地址末尾为10B，最终得到00000302H。 假如运行ld.b，存储器返回数据为03020100H\n访存地址末尾为00B，最终得到00000000H。 访存地址末尾为01B，最终得到00000001H。 访存地址末尾为10B，最终得到00000002H。 访存地址末尾为11B，最终得到00000003H。 你应该会想问，剩下的情况呢？剩下的情况是不被允许的！剩下的情况被称为访存地址非自然对齐。\n假如从地址01H处读取一个字（32bit），由于存储器的特性，我们需要先读取00H处的一个字，再读取04H处的一个字，再将它们的01H~04H处的数据拼接起来作为最终数据。实际上，读取一个字的数据对于CPU来说是非常费时间的（可能是上千个周期），更不用说读两个字了，所以我们在定义的时候就不允许这种跨字的数据读写（编译器分配地址空间时也会按照自然对齐地址分配）。\n字节写使能 如果你不知道字节写使能是哪根线的话请重新看exp7的实践任务第2条\n字节写使能即以字节为单位控制存储器写入的数据。\n例如字节写使能为0011B，则地址为00B、01B处会写入新的数据，地址为10B、11B处数据不会被修改。\n接下来让我们针对00H处的一个字的存储单元运行一段指令序列吧~\n指令序号 指令 访存地址（B） 数据（H） 存储器数据（H） 1 st.w 00 1234ABCD 1234ABCD 2 ld.b 01 FFFFFFAB 1234ABCD 3 st.h 10 00009876 9876ABCD 4 ld.hu 00 0000ABCD 9876ABCD 5 st.b 11 12345678 7876ABCD 6 ld.w 01 ERROR 7876ABCD 调试Tips 顶层信号中地址线addr在接入存储器时将末两位截去，所以00B~11B的访存地址均会取出00H开始的一个字，详见soc_lite_top.v文件 大部分分支跳转指令本身的执行错误不会引发trace比对的ERROR，其后一条指令才会引发 当功能点越来越多，你可以尝试编译只有新指令的func程序来跳过前面已经pass的指令以提高仿真速度，但请最后跑一遍完整的func程序 exp12：添加系统调用异常支持 目标：\n理解CPU中断例外的概念 学习精确异常处理的过程 在CPU中添加系统调用异常的支持 完全掌握exp11及以前的内容 特权指令 在计算机系统层次结构中，应用层在操作系统层之上，只能看到和使用指令系统的一个子集，即指令系统的用户态部分。每个应用程序都有自己的寄存器、内存空间以及可执行的指令。现代计算机的指令系统在用户态子集之外还定义了操作系统核心专用的特权态部分，我们称之为特权指令系统。\n特权指令系统的存在主要是为了让计算机变得更好用、更安全。操作系统通过特权指令系统管理计算机，使得应用程序形成独占CPU的假象，并使应用间相互隔离，互不干扰。应用程序只能在操作系统划定的范围内执行，一旦超出就会被CPU切换成操作系统代码运行。\n龙芯架构32位精简版中处理器核分为2个特权等级（PrivilegeLeVel，简称PLV），分别是PLV0和PLV3。处理器核当前处于哪个特权等级由CSR.CRMD中PLV域的值唯一确定。\n所有特权等级中，PLV0是具有最高权限的特权等级，也是唯一可以使用特权指令并访问所有特权资源的特权等级。PLV3这个特权等级不能执行特权指令访问特权资源。对于Linux系统来说，架构中仅PLV0级可对应核心态，PLV3级对应用户态。\n控制状态寄存器（CSR寄存器） 为了控制CPU的运行状态以及处理特权指令，有一组控制状态寄存器（在龙芯架构中称为CSR寄存器），其位于一个独立的地址空间。\n名称 地址 描述 CRMD 0x0 当前模式信息 PRMD 0x1 例外前模式信息 ESTAT 0x5 例外状态 ERA 0x6 例外返回地址 EENTRY 0xc 例外入口地址 SAVE0~SAVE3 0x30~0x33 数据保存 完整CSR寄存器表和各个CSR寄存器的定义详见原手册第7节。\nCSR寄存器有其专用的读写指令csrrd、csrwr、csrxchg，注意这些指令仅在核心态（即PLV0）可运行。\n异常和中断 计算机通常按照软件的执行流进行顺序执行和跳转，但有时会需要中断正常的执行流程去处理其他任务，可以触发这一过程的事件统称为异常。\n中断通常由CPU核外部事件发起，CPU核响应后暂停原先程序执行另一段程序的事件。从CPU角度看，中断也可以被视为一种特定的异常，接下来将不做区分统一以“异常”表达。\n顾名思义，“异常”不是常态。异常对应的情况发生的频度不高，但处理起来比较复杂。本着“好钢用在刀刃上”的设计原则，我们希望尽可能由软件程序而不是硬件逻辑来处理这些复杂的异常情况。这样做既能保证硬件的设计复杂度得到控制又能确保系统的实际运行性能没有太大的损失。\n异常处理绝大部分交给异常处理程序完成，但是在处理的开始和结束仍需硬件完成。\n预备阶段 CPU核内部或外部事件置起异常信号，表示有异常事件发生，请求CPU处理。 每个异常事件有其对应的异常编码，需要在申请时同时提供。编码对应详见这里或者原手册表7-7。 响应准备阶段 CPU确认自身可以响应异常处理。 记录被异常打断的指令的地址到CSR.ERA 记录当前运行状态（CSR.CRMD的PLV、IE）到CSR.PRMD的对应域。 同时调整CPU的权限等级（通常调整至最高特权等级CSR.CRMD.PLV=0）并关闭中断响应（CSR.CRMD.IE=0）。 响应阶段 根据例外优先级（见原手册6.2.2节）选择响应最高优先级的异常，将对应的异常编码写入CSR.ESTAT的Ecode和Esubcode。 跳转至例外入口（来自CSR.EENTRY）。 结束阶段 异常处理程序结束后会执行ertn指令，其指示CPU从例外处理状态返回。 例外前运行状态（CSR.PRMD的PLV、IE）被写回CSR.CRMD的对应域。 跳转到被异常打断的指令的地址CSR.ERA处取指。 精确异常 走完异常处理的全部流程，如果我们从原程序流的角度“看”，那么我们会发现它根本不知道某个时刻CPU被“借走”处理了另一段程序，这就是所谓的精确异常。\n简单的来说精确异常要求在处理异常时，发生异常的指令前面的所有指令都执行完（修改了机器状态），而发生异常的指令及其后面的指令都没有执行（没有修改机器状态）。\n在流水线处理器中，同时会有多条指令处于不同阶段，不同阶段都有发生异常的可能，那么如何实现精确异常呢？书中给出一种可行的设计方案：\n任何一级流水发生异常时，在流水线中记录下发生异常的事件，直到写回阶段再处理。 如果在执行阶段要修改机器状态（如状态寄存器），保存下来直到写回阶段再修改。 指令的PC值随指令流水前进到写回阶段为异常处理专用。 将外部中断作为取指的异常处理。 指定一个通用寄存器（或一个专用寄存器）为异常处理时保存PC值专用。 当发生异常的指令处在写回阶段时，保存该指令的PC及必需的其他状态，置取指的PC值为异常处理程序入口地址。 调试Tips 异常处理需要复杂的控制系统支持，添加起来有一定难度。但它对CPU意味着可以在考试中途出去上个厕所回来接着做而非必须一口气做到底 如果觉得直接在流水线上改动的不熟练的话，或许可以在单周期CPU上先添加一下，然后再切分到流水线的各个级。如果你有做好git版本控制的话应该很好找吧 某些CSR寄存器和PC寄存器一样存在特定的复位值，见原手册6.3节。 对于CSR寄存器，其也和通用寄存器一样存在冒险问题等待解决。 在CSR.ESTAT.IS域，其第10位在有些func程序中固定为0，有些开放读写，可能需要注意下。 例外返回的地址不一定是CSR.ERA中的地址。在本实验中返回原地址将会重新执行syscall。是死循环捏 exp13：添加其它异常支持 目标：\n完善ADEF、ALE、BRK、INE异常支持 添加中断支持 添加定时器、计时器 在exp12完成了syscall的异常支持后，我想CPU中完整的异常处理的数据和控制通路已经搭建完成了，添加新的异常支持只需要针对新的异常进行对应的判断，发出对应的异常消息即可。\n中断 中断可被视为一种特定的异常，但是其与其它异常有着一个关键的不同点。\n由于中断通常由CPU核外部事件触发，其相对CPU核是异步的，所以发出的中断信号需要保持到被CPU采样，否则将永远无法触发中断异常。当然这是由中断源负责维护的。\n在较为简单的线中断模式下，硬件仅需每拍采样各个中断源并将其状态记录于CSR.ESTAT.IS域中，并在认为有需要响应的中断时将中断例外标注至流水线中的某一条指令上，随后的过程与其它例外相同。\n定时器与定时器中断 在龙芯32位精简版架构中定义了一个定时器，其随着时钟自减，直到为零时置起定时器中断信号。\n详细定义及运行控制信息见原手册的TCFG、TVAL、TICLR寄存器定义（7.6.2~7.6.4）。\n计时器 龙芯架构 32 位精简版定义了一个恒定频率计时器，其主体是一个 64 位的计数器，称为 Stable Counter。Stable Counter 在复位后置为 0，随后每个计数时钟周期自增 1，当计数至全 1 时自动绕回至 0 继续自增。同时每个计时器都有一个软件可配置的全局唯一编号，称为 Counter ID，保存在CSR.TID寄存器中。\n调试Tips 在经过了exp12的锤炼后，本实验应该不难了吧~~\\doge~~ 在verilog描述中注意多驱动问题。如果你选择给每个CSR寄存器一个always块负责内容修改的话，请注意这个CSR寄存器中所有数据更新都必须在这个always块中，以避免多驱动问题产生。例如CSR.ESTAT.IS[11]的定时器中断状态位的赋值不能在CSR.TVAL寄存器中，当然还有其它情况，请自行注意避免。（可以在综合的警告或者Linter语法检查找到已有的多驱动） 选择你觉得舒服的CSR寄存器声明方式，可以按照名字定义32位的，也可以直接按照子域分开定义……善用宏定义将位索引转换为有意义的单词 exp14：添加类SRAM总线支持 目标：\n学习总线的原理及作用 在CPU中添加简单的类SRAM接口总线支持 总线 总线的本质作用是完成数据交换。总线用于将两个或两个以上的部件连接起来，使得它们之间可以进行数据交换，或者说通信。\n总线的具体介绍可见《计算机体系结构》。\n在总线通信中，通常将读写操作发起方称为主方（master），响应方称为从方（slave）。每一次读写操作的过程可大致分为：请求发起、响应请求、请求数据传输、请求数据返回。和我们之前的实验中不同的是，由于实际情况下总线上可能不止处理一件事物、数据的读写也需要一定的时间，所以每个步骤之间是有不确定的时间间隔的。为了明确何时的数据是有效的，每次有效的数据传输都基于握手信号，只有握手成功才会传输有效数据。\n类SRAM接口 我们的CPU最终需要实现AMBA AXI总线接口，但是直接上手AXI总线可能有些困难，所以我们先学习类SRAM接口，或者说在我们原先的SRAM接口上加入握手机制，其接口信号如下：\n信号名称 位宽 方向 功能 req 1 master-\u0026gt;slave 读写请求信号 wr 1 master-\u0026gt;slave 高电平表示写请求，低电平为读操作 size 2 master-\u0026gt;slave 传输字节数 addr 32 master-\u0026gt;slave 请求的地址 wstrb 4 master-\u0026gt;slave 写请求的写字节使能 wdata 32 master-\u0026gt;slave 写请求的写数据 addr_ok 1 slave-\u0026gt;master 请求的地址传输完毕 data_ok 1 slave-\u0026gt;master 请求的数据传输完毕（读取的数据or数据的写入） rdata 32 slave-\u0026gt;master 读请求返回的读数据 相较于原先的SRAM接口，我们只添加了size、addr_ok、data_ok三根信号线，接下来我们解释一下这三条线的作用。\nsize size信号表示该次请求传输的字节数，根据访存指令不同选择不同的值\n0: 1字节。ld.b、ld.ub、st.b 1: 2字节。ld.h、ld.uh、st.h 2: 4字节。ld.w、st.w addr_ok addr_ok信号用于和req信号一起完成读写请求的握手。只有在clk的上升沿同时看到req和addr_ok为1的时候才是一次成功的请求握手，读写请求、读写地址和可能的写数据被发送至从方。\ndata_ok data_ok信号有双重身份。对应读事务的时候它是数据返回的有效信号；对应写事务的时候，它是写入完成的有效信号。\n在类SRAM接口中主方对于数据响应总是可以接收，所以不再设置Master接收data_ok的握手信号。也就是说如果存在未返回数据响应的请求，则在clk的上升沿看到data_ok为1就可以认为是—次成功的数据响应握手。\n读写时序 需要注意的是，总线上支持多事务处理，比如说以下连续写读操作：\n对于初学者来说还是先一个一个事务处理，多事务会复杂上不少，对于我们的单发射流水线也起不到很大优化效果。\n建议阅读一下《CPU设计实战》中“类SRAM总线的设计”一节，书中有详细的分析。如果没有Loongarch版的话MIPS版也是相通的。\n调试Tips 从总线接口开始，你就会发现何为时序逻辑比组合逻辑难了。不出意外的话你应该会开始遇到各种差一拍或者其它奇奇怪怪的情况，请记得此时你的流水级处理的事情不像之前那样只有一拍，而变成类似一个状态机一样的多周期流水级，需要对流入和流出的控制有着明确的信号逻辑。 明确需要当拍更新（组合逻辑）和下拍更新（时序逻辑）的信号及它们间的相互依赖。 exp15、16：添加AXI总线支持、完成AXI随机延迟验证 CPU对外只有一个AXI接口，需在内部完成取指和数据访问的仲裁。推荐在本任务中实现一个类SRAM-AXI的2x1的转接桥，然后拼接上exp14完成的类SRAM接口的CPU，将myCPU封装为AXI接口。\nAXI接口 备注栏中是我们针对exp给出的—些设计建议。\nAXI接口的设计资料比较多，《CPU设计实战》和《计算机体系结构基础》以及网络上都有十分详细的分析和教学，我就不班门弄斧了。\n在这里提供一个转接桥参考。\n调试Tips 到这里提前恭喜你已经写出完整的CPU (◆゜∀゜）👍 在exp16实践任务中第6、7步比较费时间，建议各个种类各挑一个就行 到这我也没什么Tips可写了，靠各位自己STFW啦*(^_^)/* 附录 在学习之前，你需要\n学会verilog的基本语法\nVerilog 基础知识 | Vincent的图书馆\nVerilog HDL——运算符_verilog逻辑运算符_~Old的博客-CSDN博客\nVerilog语法之四：运算符 - 知乎 (zhihu.com)\nVerilog 基础仿真文件编写_verilog仿真程序编写_背影疾风的博客-CSDN博客\n学会补码及其加减法\n原码-反码-补码 \u0026ndash;数学公式分析_原码反码补码计算公式及关系-CSDN博客 【原创】计算机为什么要用补码？ - 知乎 (zhihu.com) 【计算机组成原理】补码的加减运算方法_补码相加怎么算的-CSDN博客 多路复选器 作用：从一组输入数据中选出某一个来\n核心：用与门当做开关，通过数据信号和控制信号相与实现各数据的选择效果\n二选一 电路图：\nverilog实现方式：\n门级电路（了解即可） 1 2 3 4 5 6 7 module mux2_gate ( input wire [7:0]a,b, input wire sel, output wire [7:0]y ); assign y = (a \u0026amp; {8{sel}}) | (b \u0026amp; {8{~sel}}); endmodule 行为级描述 1 2 3 4 5 6 7 8 module mux2 ( input wire[7:0] a,b, input wire sel, output wire[7:0] y ); assign y = sel ? a : b; endmodule //1=\u0026gt;a,0=\u0026gt;b 带参数的常用写法 1 2 3 4 5 6 7 8 9 module mux2_par #( parameter n=8 ) ( input wire[n-1:0] a,b, input wire sel, output wire[n-1:0] y\t); assign y = sel ? a : b; endmodule ​\t调用方式\n1 mux2_par #(.n()) u_mux2_par (.a(),.b(),.sel(),.y()); 四选一 电路图：\nverilog实现方式：\n门级电路（了解即可） 1 2 3 4 5 6 7 module mux4_gate ( input wire [7:0]a,b,c,d, input wire [1:0]sel, output wire y ); assign y=(a\u0026amp;\u0026amp;~sel[0]\u0026amp;\u0026amp;~sel[1])|(b\u0026amp;\u0026amp;sel[0]\u0026amp;\u0026amp;~sel[1])|(c\u0026amp;\u0026amp;~sel[0]\u0026amp;\u0026amp;sel[1])|(d\u0026amp;\u0026amp;sel[0]\u0026amp;\u0026amp;sel[1]); endmodule//00=\u0026gt;a,01=\u0026gt;b,10=\u0026gt;c,11=\u0026gt;d 行为级描述 1 2 3 4 5 6 7 8 module mux4 ( input wire[7:0] a,b,c,d, input wire[1:0] sel, output wire[7:0] y ); assign y = sel[0] ? (sel[1] ? d : c) : (sel[1] ? b : a); endmodule//00=\u0026gt;a,01=\u0026gt;b,10=\u0026gt;c,11=\u0026gt;d 带参数的常用写法 1 2 3 4 5 6 7 8 9 10 module mux4_par #( parameter n=8 ) ( input wire[n-1:0] a,b,c,d, input wire[1:0] sel, output wire[n-1:0] y ); assign y = sel[0] ? (sel[1] ? d : c) : (sel[1] ? b : a); endmodule//00=\u0026gt;a,01=\u0026gt;b,10=\u0026gt;c,11=\u0026gt;d ​\t调用方式\n1 mux4_par #(.n()) u_mux4_par (.a(),.b(),.c(),.d(),.sel(),.y()); 本章你需要学会的\n带参数的写法及其调用方法 加法器 半加器 只将两个1位二进制数相加，不考虑低位进位。\n真值表 输入 输出 A B S CO 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 逻辑函数 $$ S=\\overline{A}B+A\\overline{B}=A\\oplus B\\\\ CO=AB $$ 电路图 verilog实现方式 1 2 3 4 5 6 7 module half_adder ( input a,b, output s ); assign s = a ^ b; endmodule 全加器 除了要将两个1位二进制数相加外，还有考虑来自低位的进位。\n真值表 输入 输出 CI A B S CO 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 逻辑函数 可以通过两个半加器串联修改实现 $$ S=A\\oplus B\\oplus CI\\\\ CO=AB+\\left( A+B\\right) \\left( CI\\right) $$ 电路图 verilog实现方式 1 2 3 4 5 6 7 8 module adder_1bit ( input a,b,ci, output s,co ); assign s = a^b^ci; assign co = (a\u0026amp;b)|(ci\u0026amp;(a^b)); endmodule 多位加法器 行波进位加法器（Ripple-carry adder） 示意图 如同波一般向前计算。每次运算需要等待前一位的进位值，由全加器的电路图可知，从cin到cout有两级门电路的时延，所以对于N位行波进位加法器，时延就是$3+(N-1)*2=2N+1$级。可见，在位数更高的RCA中，串行计算带来的时延会相当大，这对于现代高速运算是不可忍受的。\nverilog实现方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 module adder_8bit ( input [7:0] a,b, input ci, output [7:0] s, output co ); wire [8:0] temp_co; assign temp_co[0] = ci; generate genvar i; for (i = 0;i\u0026lt;8 ;i=i+1 ) begin:adder_simple adder_1bit adder_unit(.a(a[i]),.b(b[i]),.ci(temp_co[i]),.s(s[i]),.co(temp_co[i+1])); end endgenerate assign co=temp_co[8]; endmodule 超前进位加法器（Carry-lookahead Adder） 为了提高运算速度，必须设法减小或消除由于进位信号逐级传递所耗费的时间，于是设计出超前进位加法器。\n超前进位逻辑 两个多位数中第i位相加产生的进位输出$(CO)_i$可表示为 $$ (CO)_i=A_iB_i+\\left( A_i+B_i\\right) \\left( CI\\right)_i $$ 我们将$G_i = A_iB_i$称为进位生成函数，将$P_i = (A_i+B_i)(CI)_i$称为进位传递函数。\n通过数学计算展开可得 $$ \\left( CO\\right) _{i}=G_{i}+P_{i}G_{i-1}+P_{i}P_{i-1}G_{i-2}+\\ldots +P_{i}P_{i-1}\\ldots P_{1}G_{0} +P_{i}P_{i-1}\\ldots P_{0}G_{0} $$ 于是我们得到了任意一位产生的进位，避免了等待进位信号的逐级传递，将实现上述逻辑的电路称为CLU（Carry Lookahead Unit）。由公式可以看出，并行生成各级$C_i$的时延来自$G_i$和$P_i$的先与后或，再加上生成$G_i$和$P_i$的一级门电路，总共是三级门电路时延。而且可以看出，时延的级数并不会随位数的增加而增加，不论多少位CLA，生成各级$C_i$的时延恒为三级门电路。\n由全加器的真值表可得第$i$位和$S_i$的逻辑式 $$ S_i=A_i\\oplus B_i\\oplus (CI)_i \\ \\ \\ 或 \\ \\ \\ S_i= \\sim G_i P_i\\oplus (CI)_i $$ 同样不超过三级门电路\n4位超前进位加法器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 module CLA4 ( input [3:0]a,b, input ci, output [3:0]s, output co ); wire [3:0]G,P; wire [3:0]co_buf,ci_buf; generate genvar i; for (i = 0;i\u0026lt;4 ;i=i+1 ) begin assign G[i] = a[i] \u0026amp; b[i]; assign P[i] = a[i] | b[i]; end endgenerate assign co_buf[0]=G[0] | G[0]\u0026amp;ci; assign co_buf[1]=G[1] | P[1]\u0026amp;G[0] | P[1]\u0026amp;P[0]\u0026amp;ci; assign co_buf[2]=G[2] | P[2]\u0026amp;G[1] | P[2]\u0026amp;P[1]\u0026amp;G[0] | P[2]\u0026amp;P[1]\u0026amp;P[0]\u0026amp;ci; assign co_buf[3]=G[3] | P[3]\u0026amp;G[2] | P[3]\u0026amp;P[2]\u0026amp;G[1] | P[3]\u0026amp;P[2]\u0026amp;P[1]\u0026amp;G[0] | P[3]\u0026amp;P[2]\u0026amp;P[1]\u0026amp;P[0]\u0026amp;ci; assign co = co_buf[3]; assign ci_buf = {co_buf[2:0],1\u0026#39;b0}; generate genvar i; for (i = 0;i\u0026lt;4 ;i=i+1) begin assign s[i] = ~G[0] \u0026amp; P[i] ^ ci_buf[i]; end endgenerate endmodule 更多位超前进位加法器 在设计出4位超前进位加法器后，一个很自然的想法是：要想得到更多位CLA，只需像4位CLA那样，只是多递归几次的区别。这个方法叫全超前进位。全超前进位理论上是可行的，但由CLU的公式可知，随着位数的增加，实现CLU的门电路数量会急剧增加，导致电路面积开销过大；另一方面，位数的增加也会使扇入飞速增大，导致时延增加。\n所以，单纯的递归并不是好的解决方案。\n一个解决方案是借鉴RCA。将多个4位CLA级联，即采用“组内超前进位，组间串行进位“来构成更多位超前进位加法器。其中每个4位CLA从进位输入到进位输出是两级门电路时延，加上第一级CLA的PG时延和最后一级CLA的异或门时延，这种方式构成的N位超前进位加法器的总时延为$1+2*(N/4)+1=N/2+2$。\n如果想获得更快的速度，就得采用另一种方法——多级超前进位加法器。多级超前进位加法器采用“组内超前进位，组间也超前进位”的方式，可进一步降低因组间串联进位带来的时延。即将每个4位CLA看做一位再由超前进位逻辑再次进行超前进位，故称为多级超前进位加法器。\n本章你要学会的\n超前进位加法器是怎么优化降低时延的 generate-for循环调用模块 一些可参考资料\n《数字电子技术基础》阎石 p172-176 《计算机体系结构基础》胡伟武 p188-193 32位超前进位加法器的设计-T-Tang-电子技术应用-AET-中国科技核心期刊-最丰富的电子设计资源平台 (chinaaet.com) 16位两级超前进位加法器的Verilog实现及时延分析 - 知乎 (zhihu.com) 乘法器 不采用任何优化算法的乘法过程，可以用我们小学就学过的列竖式乘法来说明。从乘数的低位开始，每次取一位与被乘数相乘，其乘积作为部分积暂存，乘数的全部有效位都乘完后，再将所有部分积根据对应乘数数位的权值错位累加，得到最后的乘积。\n这样原始的乘法在设计上是可以实现的，但在工程应用上几乎不会采用，在时延与面积上都需要优化。一个N位的乘法运算，需要产生N个部分积，并对它们进行全加处理，位宽越大，部分积个数越多，需要的加法器也越多，加法器延时也越大，那么针对乘法运算的优化，主要也就集中在两个方面：一是减少加法器带来的延时，二是减少部分积的个数。\n补码移位乘法器 首先解决负数乘法问题。在加减法中我们采用补码解决负数和减法问题，在负数乘法中同样可以使用补码。\n假定有 8 位定点数 $Y$， $[Y]_补$ 的二进制格式写作 $y_7 y_6 y_5 y_4 y_3 y_2 y_1 y_0$ ，根据补码定义，$Y$ 的值等于 $$ Y=y_{7}\\times -2^{7}+y_{6}\\times 2^{6}+y_{5}\\times 2^{5}+\\ldots +y_{0}\\times 2^{0} $$ 由此可得出 $$ \\begin{aligned}\\left[ X\\times Y\\right] _{补}\u0026=\\left[ X\\times (y _{7}\\times -2^{7}+y_{6}\\times 2^{6}+\\ldots +y_{0}\\times 2^0) \\right]_{补} \\\\ \u0026=\\left[X \\times -y_7\\times 2^{7}+X\\times y_{6}\\times 2^{6}+\\ldots +X\\times y_{0}\\times 2^{0}\\right] _{补}\\\\ \u0026=\\left[ X\\times-y_{7}\\times2^{7}\\right] _{补}+\\left[ X\\times y_6\\times 2^{6}\\right] _{补}+\\ldots +[ X\\times y_{0}\\times 2^{0}) _{补}\\\\ \u0026=-y_{7}\\times \\left[ X \\times 2^{7} \\right] _{补} + y_{6}\\times \\left[ X \\times 2^{6} \\right] _{补}+\\ldots +y_{0}\\times \\left[ X\\times 2^{0}\\right]_{补}\\\\ \u0026=\\left[ X\\right] _{补}\\times \\left( -y_{7}\\times 2^{7}+y_{6}\\times 2^{6}+\\ldots +y_{0}\\times 2^{0} \\right) \\end{aligned} $$ 根据公式可以用verilog设计出简单的移位补码乘法器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 module mult_simple ( input [7:0] op1,op2, output[15:0]out ); wire [15:0] op1_ext = op1[7] ? {8\u0026#39;b11111111,op1} : {8\u0026#39;b0,op1}; wire [15:0] mult_buf [7:0]; generate genvar i; for (i = 0;i\u0026lt;8 ;i=i+1 ) begin assign mult_buf[i] = ~op2[i] ? 16\u0026#39;b0 : (op1_ext\u0026lt;\u0026lt;i); end endgenerate assign out = mult_buf[0] + mult_buf[1] + mult_buf[2] + mult_buf[3] + mult_buf[4] + mult_buf[5] + mult_buf[6] - mult_buf[7]; endmodule 华莱士树 由于累加器本身的进位传递延时对电路性能依然存在非常大的影响，所以优化的第一个方面，就是改进部分积累加结构，提升累加性能。如果采用部分积直接相加的方式，因为全加器进位的关系，当前bit的相加结果依赖于它前一bit的进位输出，整个计算过程相当于串行化，位宽越大，延时越大，所以优化的关键就是消除进位链，使运算并行化。\n进位保留加法器（Carry Save Adder, CSA）是比较常用的一种优化方式，CSA实际上就是一位全加器。在上一章中我们学习了全加器有3个输入A,B,CI和2个输出S,CO，通过CI和上一级CO相接实现串行的加法，但是在CSA中我们保留每一位的CO，CI使用另外一个加数D来替代，即 $$ A+B+D=S+\\{C,0\\} $$ 这样我们就实现了3个加数变为2个加数的加数缩减，也就是说我们将加数减少了1/3，如果我们再往后加一层同样的CSA，可以进一步减少加数，直到只剩两个加数即可使用一个加法器得到最终结果。对于N个加数的加法，使用串行加法器需要N-1个加法器的延时，使用多层华莱士树大致需要$log_{1.5}(0.5N)$个加法器延迟，显然明显地降低计算延迟，数据宽度越宽，其效果越明显。\n下面为8个1位数相加的四层华莱士树结构图，同样也可将1位数扩展为多位数，结构是相似的。\n注意每一层的进位信号只能接到下一层，不能接到上一层\n1 2 3 4 5 6 7 8 9 module compressor32 ( input [15:0] op1,op2,op3, output[15:0] out1,out2 ); assign out1 = op1^op2^op3; assign out2 = (op1\u0026amp;op2|op2\u0026amp;op3|op3\u0026amp;op1)\u0026lt;\u0026lt;1; endmodule 同样也可以设计4-2压缩的华莱士树\nbooth乘法器 如果遵循第一节的补码乘法算法，需要特地挑出第 N 个部分积，并使用补码减法操作，这就需要实现一个额外的状态机来控制，增加了硬件设计复杂度。 因此对补码乘法公式进行变换 $$ \\begin{aligned} Y\u0026=-y_{7}\\times 2^{7}+y_{6}\\times 2^{6}+y_{5}\\times 2^{5}+\\ldots +y_{0}\\times 2^{0}\\\\ \u0026=\\left( -y_7 \\times 2^{7}+\\left( y_{6}\\times 2^{7}-y_{6}\\times 2^{6}\\right) +\\left( y_{5}\\times 2^{6}-y_{5}\\times 2^{5}\\right) +\\ldots +\\left( y_1\\times 2^{2}-y_1\\times 2^{1}\\right) +\\left( y_{0}\\times 2^1- y_{0}\\times 2^{0}\\right) +\\left( 0\\times 2^{0}\\right) \\right) \\\\ \u0026=\\left( y_{6}-y_{7}\\right) \\times 2^{7}+\\left( y_{5}-y_{6}\\right) \\times 2^{6}+\\ldots +\\left( y_{0}-y_{1}\\right) \\times 2^{1}+ \\left( y_{-1}-y_{0}\\right) \\times 2^{0}\\end{aligned} $$ 其中$y_{-1}$取值为 0。 经过变换，公式变得更加规整，不再需要专门对最后一次部分积采用补码减法，更适合硬件实现。 这个新公式被称为 Booth 一位乘算法。\n根据算法公式，很容易得出它的规则\n$y_i$ $y_{i-1}$ 操作 0 0 0 0 1 $+[X]_补$ 1 0 $-[X]_补$ 1 1 0 于是我们可以设计出booth一位乘\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 module compressor32 (//华莱士树32压缩 input [15:0] op1,op2,op3, output[15:0] out1,out2 ); assign out1 = op1^op2^op3; assign out2 = (op1\u0026amp;op2|op2\u0026amp;op3|op3\u0026amp;op1)\u0026lt;\u0026lt;1; endmodule module mult_booth1 (//booth一位乘 input signed [7:0] op1,op2, output signed [15:0] out ); wire signed [15:0] op1_ext = op1[7] ? {8\u0026#39;b11111111,op1} : {8\u0026#39;b0,op1}; wire signed [15:0] mult_buf [7:0]; generate genvar i; for (i = 0; i \u0026lt; 8; i = i + 1) begin if (i == 0) begin assign mult_buf[0] = op2[0] ? -op1_ext : 0; end else begin assign mult_buf[i] = op2[i] ^ op2[i - 1] ? (op2[i] ? -op1_ext : op1_ext) : 0; end end endgenerate wire [15:0] wallace1_buf [11:0]; begin:wallace1 compressor32 wallace1_1(mult_buf[0],mult_buf[1]\u0026lt;\u0026lt;1,mult_buf[2]\u0026lt;\u0026lt;2,wallace1_buf[0],wallace1_buf[1]); compressor32 wallace1_2(mult_buf[3]\u0026lt;\u0026lt;3,mult_buf[4]\u0026lt;\u0026lt;4,mult_buf[5]\u0026lt;\u0026lt;5,wallace1_buf[2],wallace1_buf[3]); end begin:wallace2 compressor32 wallace2_1(wallace1_buf[0],wallace1_buf[1],wallace1_buf[2],wallace1_buf[4],wallace1_buf[5]); compressor32 wallace2_2(wallace1_buf[3],mult_buf[6]\u0026lt;\u0026lt;6,mult_buf[7]\u0026lt;\u0026lt;7,wallace1_buf[6],wallace1_buf[7]); end begin:wallace3 compressor32 wallace3(wallace1_buf[4],wallace1_buf[5],wallace1_buf[6],wallace1_buf[8],wallace1_buf[9]); end begin:wallace4 compressor32 wallace4(wallace1_buf[8],wallace1_buf[9],wallace1_buf[7],wallace1_buf[10],wallace1_buf[11]); end begin:adder assign out = wallace1_buf[10] + wallace1_buf[11]; end endmodule 在 Booth 一位乘算法中，为了计算 N 位的补码乘法, 依然需要 N-1 次加法。 而数据宽度较大的补码加法器面积大、电路延迟长，限制了硬件乘法器的计算速度，所以优化的第二个方面就是减少部分积的个数。重新对补码乘法公式进行变换，得到 Booth 两位乘算法。 $$ 𝑌=(𝑦_5+𝑦_6−2𝑦_7 )×2^6+(𝑦_3+𝑦_4−2𝑦_5 )×2^4+⋯+(𝑦_{−1}+𝑦_0−2𝑦_1 )×2^0 $$ 根据算法公式，很容易得出它的规则\n$y_{i+1}$ $y_{i}$ $y_{i-1}$ 操作 0 0 0 0 0 0 1 $+[X]_补$ 0 1 0 $+[X]_补$ 0 1 1 $+2[X]_补$ 1 0 0 $-2[X]_补$ 1 0 1 $-[X]_补$ 1 1 0 $-[X]_补$ 1 1 1 0 于是你们就可以设计一个8位booth二位乘乘法器了\n本章你要学会的\n补码乘法 并行化优化思路 一些参考资料\n《计算机体系结构基础》胡伟武 p196-206 《CPU设计实战》p140-146 乘法器的布斯算法原理与VERILOG实现 - 知乎 (zhihu.com) 八位“Booth二位乘算法”乘法器 - 知乎 (zhihu.com) 除法器 符号解释：\n$N$ = numerator (dividend)，分子，被除数 $D$ = denominator (divisor)，分母，除数 $Q$ = quotient，商 $R$ = Remainder，余数 循环相减法 最简单粗暴的法子，减到没法减。\n其伪代码如下\n1 2 3 4 5 6 7 R := N Q := 0 while R ≥ D do R := R − D Q := Q + 1 end return (Q,R) 慢速算法（迭代） 以下恢复余数法、非恢复余数法、SRT算法均是慢速算法，其共同点为通过循环等式，对余数R进行迭代： $$ R_{j+1} = B \\times R_j - q_{n-(j+1)} \\times D $$ 其中：\n$R_j$ 是第 $j$ 个部分余数，$R$ = $R_n$ ，$N$ = $R_0$ $B$ 是基，在二进制中，为2 $q_{n−(j+1)}$ 是商的第 $n−(j+1)$ 位，例如第1次迭代（j=0）产生 $q_{n−1}$ ，商的最高位 $n$ 是商的位数 $D$ 是除数 $$ \\begin{aligned} R \u0026= R_n = 2R_{n-1}-q_0D = 2R_{n-2}-2^1q_1D-q_0D = \\cdots \\\\ \u0026= 2^nN - 2^{n-1}q_{n-1}D - \\cdots -2^1q_1D - q_0D \\\\ \u0026= 2^nN-QD \\end{aligned} $$ 注意要将N（被除数）左移n位\n恢复余数法 恢复余数法无法直接用于与有符号数，对于有符号数需要先转换为无符号数，然后根据除数与被除数的符号判断商与余数的符号。\n其算法核心是在每次迭代时都假定$q$为1，计算出下一个部分和。然后判断该部分和的正负性，如果为正则假定正确，即该位商为1；如果为负则假定不正确，即该位商为0，且将部分余数恢复为正（即将减去的除数加回去）。\n算法伪代码如下：\n1 2 3 4 5 6 7 8 9 10 11 R := N D := D \u0026lt;\u0026lt; n -- R和D需要两倍位宽 for i := n − 1 .. 0 do R := 2 * R − D if R \u0026gt;= 0 then q(i) := 1 -- 该位商为 1 else q(i) := 0 -- 该位商为 0 R := R + D -- 将部分余数恢复为正 end end 非恢复余数法 在非恢复余数法中，使用{-1,1}替代{0,1}，同时去除恢复余数的冗杂步骤，根据该位商情况迭代不同的。\n$-3 = (-1)(1)(1)(-1) = -2^3 + 2^2 + 2^1 - 2^0$\n算法伪代码如下：\n1 2 3 4 5 6 7 8 9 10 11 R := N D := D \u0026lt;\u0026lt; n -- R和D需要两倍位宽 for i = n − 1 .. 0 do if R \u0026gt;= 0 then q(i) := + 1 R := 2 * R − D else q(i) := − 1 R := 2 * R + D end end On-The-Fly算法 由于非恢复余数法中的商出现了负数，直接得出的商是非标准形式的，我们需要把非标准形式的商在算法的最后一步转换为标准形式，但是它需要耗费额外的延迟以及芯片面积。\nOn-the-fly转换是为了获得实时的转换结果而设计的，它仅仅使用2个Flip-Flop和一些简单的组合逻辑就可以完成转换过程。\nQ的值在每次迭代中的更新公式为： $$ Q_{j+1} = Q_j + q_{j+1}r^{-(j+1)} $$ 在存在负数的商位的情况下： $$ Q_{j+1} = \\left\\{\\begin{matrix} Q_j + q_{j+1}r^{-(j+1)} \u0026 , q_{j+1} \\ge 0\\\\ Q_j - r^{-j} + (r-\\left | q_{j+1} \\right | )r^{-(j+1)} \u0026 , q_{j+1} \u003c 0 \\end{matrix}\\right. $$ 该更新公式有一个缺点，需要做减法，进位的传播会使电路变得很慢，因此我们定义另一个寄存器$QM_{j+1} = Q_j - r^{-j}$。于是减法操作可替换为对寄存器 QM 进行采样。\n此时两个寄存器的更新公式为： $$ Q_{j+1} = \\left\\{\\begin{matrix} Q_j + q_{j+1}r^{-(j+1)} \u0026 , q_{j+1} \\ge 0\\\\ QM_j + (r-\\left | q_{j+1} \\right | )r^{-(j+1)} \u0026 , q_{j+1} \u003c 0 \\end{matrix}\\right. $$ $$ QM_{j+1} = \\left\\{\\begin{matrix} Q_j + q_{j+1}r^{-(j+1)} \u0026 , q_{j+1} \u003e 0\\\\ QM_j + (r-\\left | (r-1)-q_{j+1} \\right | )r^{-(j+1)} \u0026 , q_{j+1} \\le 0 \\end{matrix}\\right. $$ 初始化条件为： $$ Q = QM = \\left\\{\\begin{matrix} 全0 \u0026 , 商为正\\\\ 全1 \u0026 , 商为负 \\end{matrix}\\right. $$ 一些参考资料\n硬件除法专题-SRT除法 - devindd - 博客园 SRT除法的一些理解 - 知乎 除法器的实现（恢复余数、不恢复余数、级数展开、Newton-Raphson）_恢复余数除法器-CSDN博客 类SRAM-AXI转接桥 龙芯杯团队赛中曾经提供的一个转接桥参考，效率偏低，且不支持burst传输。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 module cpu_axi_interface ( input clk, input resetn, //inst sram-like input inst_req , input inst_wr , input [1 :0] inst_size , input [31:0] inst_addr , input [31:0] inst_wdata , output [31:0] inst_rdata , output inst_addr_ok , output inst_data_ok , //data sram-like input data_req , input data_wr , input [1 :0] data_size , input [31:0] data_addr , input [31:0] data_wdata , output [31:0] data_rdata , output data_addr_ok , output data_data_ok , //axi //ar output [3 :0] arid , output [31:0] araddr , output [7 :0] arlen , output [2 :0] arsize , output [1 :0] arburst , output [1 :0] arlock , output [3 :0] arcache , output [2 :0] arprot , output arvalid , input arready , //r input [3 :0] rid , input [31:0] rdata , input [1 :0] rresp , input rlast , input rvalid , output rready , //aw output [3 :0] awid , output [31:0] awaddr , output [7 :0] awlen , output [2 :0] awsize , output [1 :0] awburst , output [1 :0] awlock , output [3 :0] awcache , output [2 :0] awprot , output awvalid , input awready , //w output [3 :0] wid , output [31:0] wdata , output [3 :0] wstrb , output wlast , output wvalid , input wready , //b input [3 :0] bid , input [1 :0] bresp , input bvalid , output bready ); //addr reg do_req; reg do_req_or; //req is inst or data;1:data,0:inst reg do_wr_r; reg [1 :0] do_size_r; reg [31:0] do_addr_r; reg [31:0] do_wdata_r; wire data_back; assign inst_addr_ok = !do_req\u0026amp;\u0026amp;!data_req; assign data_addr_ok = !do_req; always @(posedge clk) begin do_req \u0026lt;= !resetn ? 1\u0026#39;b0 : (inst_req||data_req)\u0026amp;\u0026amp;!do_req ? 1\u0026#39;b1 : data_back ? 1\u0026#39;b0 : do_req; do_req_or \u0026lt;= !resetn ? 1\u0026#39;b0 : !do_req ? data_req : do_req_or; do_wr_r \u0026lt;= data_req\u0026amp;\u0026amp;data_addr_ok ? data_wr : inst_req\u0026amp;\u0026amp;inst_addr_ok ? inst_wr : do_wr_r; do_size_r \u0026lt;= data_req\u0026amp;\u0026amp;data_addr_ok ? data_size : inst_req\u0026amp;\u0026amp;inst_addr_ok ? inst_size : do_size_r; do_addr_r \u0026lt;= data_req\u0026amp;\u0026amp;data_addr_ok ? data_addr : inst_req\u0026amp;\u0026amp;inst_addr_ok ? inst_addr : do_addr_r; do_wdata_r \u0026lt;= data_req\u0026amp;\u0026amp;data_addr_ok ? data_wdata : inst_req\u0026amp;\u0026amp;inst_addr_ok ? inst_wdata :do_wdata_r; end //inst sram-like assign inst_data_ok = do_req\u0026amp;\u0026amp;!do_req_or\u0026amp;\u0026amp;data_back; assign data_data_ok = do_req\u0026amp;\u0026amp; do_req_or\u0026amp;\u0026amp;data_back; assign inst_rdata = rdata; assign data_rdata = rdata; //---axi reg addr_rcv; reg wdata_rcv; assign data_back = addr_rcv \u0026amp;\u0026amp; (rvalid\u0026amp;\u0026amp;rready||bvalid\u0026amp;\u0026amp;bready); always @(posedge clk) begin addr_rcv \u0026lt;= !resetn ? 1\u0026#39;b0 : arvalid\u0026amp;\u0026amp;arready ? 1\u0026#39;b1 : awvalid\u0026amp;\u0026amp;awready ? 1\u0026#39;b1 : data_back ? 1\u0026#39;b0 : addr_rcv; wdata_rcv \u0026lt;= !resetn ? 1\u0026#39;b0 : wvalid\u0026amp;\u0026amp;wready ? 1\u0026#39;b1 : data_back ? 1\u0026#39;b0 : wdata_rcv; end //ar assign arid = data_req?4\u0026#39;b0001:4\u0026#39;b0000; assign araddr = do_addr_r; assign arlen = 8\u0026#39;d0; assign arsize = do_size_r; assign arburst = 2\u0026#39;d0; assign arlock = 2\u0026#39;d0; assign arcache = 4\u0026#39;d0; assign arprot = 3\u0026#39;d0; assign arvalid = do_req\u0026amp;\u0026amp;!do_wr_r\u0026amp;\u0026amp;!addr_rcv; //r assign rready = 1\u0026#39;b1; //aw assign awid = 4\u0026#39;d0001; assign awaddr = do_addr_r; assign awlen = 8\u0026#39;d0; assign awsize = do_size_r; assign awburst = 2\u0026#39;d0; assign awlock = 2\u0026#39;d0; assign awcache = 4\u0026#39;d0; assign awprot = 3\u0026#39;d0; assign awvalid = do_req\u0026amp;\u0026amp;do_wr_r\u0026amp;\u0026amp;!addr_rcv; //w assign wid = 4\u0026#39;d0001; assign wdata = do_wdata_r; assign wstrb = do_size_r==2\u0026#39;d0 ? 4\u0026#39;b0001\u0026lt;\u0026lt;do_addr_r[1:0] : do_size_r==2\u0026#39;d1 ? 4\u0026#39;b0011\u0026lt;\u0026lt;do_addr_r[1:0] : 4\u0026#39;b1111; assign wlast = 1\u0026#39;d1; assign wvalid = do_req\u0026amp;\u0026amp;do_wr_r\u0026amp;\u0026amp;!wdata_rcv; //b assign bready = 1\u0026#39;b1; endmodule ","date":"2025-01-19T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/%E9%BE%99%E8%8A%AF%E5%AE%9E%E9%AA%8C%E6%94%BB%E7%95%A5/","title":"龙芯实验攻略"},{"content":"What is Coroutine? 协程，是相对与子过程（即我们熟悉的函数）的一种概念。子过程是一种被调用的过程，而协程是一种可以挂起和恢复的过程。简单地说，你调用一个子过程（函数），你就只能等它从头执行完毕，下一次你再调用它的时候，它还是从头开始执行。而协程，你可以在中途挂起它，然后再恢复它，它会从上次挂起的地方继续执行。\nWhy Coroutine? 协程被称为 Green Thread，似乎与线程有些类似，但是他们完全不同。\n对于用户程序来说，操作系统对 CPU 做了一层抽象，让用户程序感觉自己拥有了一个整个 CPU（核心）。而线程的意义在于用户程序，能够拥有多个 CPU 核心，从而提高程序的并发性。通过操作系统的抽象，你可以创建数千个线程，但是 CPU 实际上只有几个核心。通过多个 CPU 核心完成任务，来更好地利用一整块 CPU，这就是Parallelism（并行）。\n协程，并不关注 CPU 核心的问题，相反，协程可以在任意一个或多个 CPU 核心上调度运行，取决于调度器的实现。通常，当我们谈论协程的时候，我们会只关心一个 CPU 核心的问题，而将调度的问题交给调度器来解决。因此，协程解决的问题是，如何更加充分地利用一个 CPU 核心。这就是Concurrency（并发）。\n定义角度： 并行(Parallelism)是指在同一时刻，有多个任务在多个处理器上同时执行 并发(Concurrency)是指在同一时间段内，有多个任务在交替执行，从宏观来看似乎是同时进行的，但是在微观上是交替执行（串行，单核心）的。 CPU利用角度： 并行要求程序能够充分利用多个CPU核心，将任务分配到不同的核心上同时执行 并发则是通过合理安排任务的执行顺序，让单个CPU核心能够高效地处理多个任务 实现机制： 并行通常依赖于硬件的多核心支持，通过线程或进程实现多任务的真正同时执行 并发可以通过协程、时间片轮转等机制，在单个核心上实现任务的交替执行 一个形象的比喻： 并行就像多个收银员同时为不同顾客结账 并发就像一个收银员通过快速切换为多个顾客轮流结账 性能提升方式： 并行通过增加计算资源(CPU核心)来提高程序的整体吞吐量 并发通过优化任务调度和执行顺序来提高单个计算资源的利用效率 适用场景： 并行适合计算密集型任务，如图像处理、科学计算等 并发适合I/O密集型任务，如网络请求、文件操作等 单线程串行运行那么好，为什么要一直切换正在运行的任务呢？ 上节课中，展示了一个例子，即使用 Singlethreaded 允许 16 次 Add_100000() 函数，然后计算总时间。结果是 16 个任务串行执行的时间总和。然后，我们使用 Multithreaded 允许 16 次 Add_100000() 函数，然后计算总时间。结果是 16 个任务并行执行的时间总和。结果发现 Singlethreaded 的时间比 Multithreaded 的时间还要短。这是因为线程间争锁、切换线程等操作，会消耗额外的时间。\n说明单线程对于性能来说其实是最好的，那么为什么要一直切换正在运行的任务呢？并且我们总是可以预料到，即使是单线程，一直切换任务也会消耗额外的时间。\n这基于下面的两个主要原因：\n1. 阻塞，更差的响应性 当我们串行运行任务时，如果一个任务阻塞了，那么整个程序都会被阻塞。这是因为我们的程序是单线程的，只有一个任务在运行。\n考虑以下一个场景，你在电脑上编写了以下程序：\n1 2 3 4 5 fn main() { while true { println!(\u0026#34;Hello, World!\u0026#34;); } } 然后运行它，好了，由于程序串行运行，你的 OS 无法处理你的键盘鼠标输入，也无法绘制屏幕输出，因为这个程序一直在运行，不会停止，导致排队在后面的任务无法执行。\n但是如果我们不停切换任务，尽管一个任务阻塞，一段时间后，我们总是会切换到其他任务，这样就可以保证所有任务都能得到执行（至少有一小段时间），而不会因为一个任务阻塞而导致整个程序无法运行。\n在这个过程中，这个死循环任务被称为**CPU-bound（计算密集型）**任务，因为它一直在占用 CPU，而不会释放。\n2. Comsumer-Producer 间的协作 那还有什么其他类型的任务呢？大多数情况下，我们的程序不是在一直不停地做 CPU 计算，而是在等待 I/O 操作完成，比如等待网络请求返回、等待文件读写，甚至等待用户鼠标键盘输入。这些任务被称为**I/O-bound（I/O 密集型）**任务，因为它们需要等待 I/O 操作完成，才能继续执行。\n这些任务等待的对象通常归根结底是外部资源，比如网络、文件、用户输入等。这些资源的读写速度远远慢于 CPU 的计算速度，因此我们的程序在等待这些资源的时候，实际上是在浪费 CPU 的时间。如果我们不停切换任务，那么当一个任务等待 I/O 时，我们可以切换到其他任务，让它们继续执行，这样就可以充分利用 CPU 的时间，提高程序的响应性。\n在这个过程中，我们的任务被称为 Comsumer 任务，因为它们需要外设产生的数据；而外设产生数据的任务被称为 Producer 任务，因为它们给 Comsumer 任务提供数据。\n对于 Comsumer-Producer 的协作关系，解决 IO 阻塞是相对简单的。更重要的是，我们需要一种编程模型，简化 Comsumer-Producer 之间的协作，让我们能够更加方便地编写这种类型的程序。而协程就是这样一种编程模型。\n让我们考虑以下一种情况，其中一个 Produecer 一直不停地产生数据 1, 2, 3, 4, 5, \u0026hellip;，而一个 Comsumer 一直不停地消费这些数，然后打印出来。你大概率 100% 会写出以下代码：\n1 2 3 4 5 6 7 fn main() { let mut i = 0; loop { println!(\u0026#34;{}\u0026#34;, i); i += 1; } } 这是相当糟糕的代码，因为生产者与消费者高度耦合在一起，无法分离。我们希望的是，生产者与消费者能够分离，互不干扰，这样我们可以更加方便地编写这种类型的程序。就像下面一样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 static mut queue: VecDeque\u0026lt;i32\u0026gt; = VecDeque::new(); fn producer() { let mut i = 0; loop { queue.push_back(i); // 把产生的数据放到队列中 i += 1; } } fn consumer() { loop { if let Some(i) = queue.pop_front() { // 从队列中取出数据 println!(\u0026#34;{}\u0026#34;, i); } else { // 如果队列为空，等待一段时间 } } } 这样，生产者与消费者之间就可以分离，互不干扰，我们可以更加方便地编写这种类型的程序。但是这样的代码还是有问题，因为我们的程序是单线程的，如果生产者一直在产生数据，那么消费者就无法执行，反之亦然。我们需要一种编程模型，让我们能够更加方便地编写这种类型的程序，这就是协程。\n让我们考虑这个过程中的问题，即生产者一直在产生数据，那么消费者就无法执行。因此解决问题的方法就是，让其中一方，在执行到一定程度后，暂停执行，然后切换到另一方执行（调度方处理），这样就可以保证两者都能得到执行。这就是协程的作用。\nImplement a Coroutine 我们知道，要让一个任务能够在中途挂起，然后再恢复，我们需要保存这个任务的上下文，然后再恢复这个任务的上下文。这就是协程的基本原理。\nStackful Coroutine 最基本的实现是 Stackful Coroutine，即我们需要在挂起一个任务时，保存这个任务的栈和完整的寄存器状态。\n为什么要保存栈呢？因为栈保存了函数的局部变量、参数、返回地址等信息，是函数能够嵌套调用的基础。如果我们不保存栈，那么函数退出后，无法返回到调用方，甚至，我们无法保存函数的局部变量等信息，因为这些信息都保存在栈帧中（上两节课的内容）。那为什么要保存寄存器呢？因为寄存器保存了函数的全局状态，比如函数的指令指针、栈指针等信息，是函数能够恢复执行的基础。如果我们不保存寄存器，那么函数退出后，无法恢复到函数的执行状态，因为这些信息都保存在寄存器中。\n但是我们是否有必要保存整个栈呢？答案是当然的，因为我们需要保存函数的完整状态，包括局部变量、参数、返回地址等信息。因为所有嵌套调用的函数都保存在栈中，所以我们需要保存整个栈的状态。\n但是我们是否有必要保存整个寄存器呢？答案是不一定的。\n其实按道理说，我们需要保证在恢复任务后，任务的执行状态和挂起时一样，这就需要保存整个寄存器。但是实际上，我们可以从挂起任务的过程中做一些简化。Stackful Coroutine 挂起一个任务看起来就像调用一个函数一样，我们需要在这个函数中，将任务的状态保存到一个上下文中，然后再恢复任务的时候，将任务的状态从上下文中恢复。这个上下文保存了任务的完整状态，包括栈和寄存器等信息。写成代码就是这样：\n1 2 3 4 5 6 7 8 9 pub fn producer() { let mut i = 0; loop { queue.push_back(i); // 把产生的数据放到队列中 i += 1; yield(); // 挂起任务，任务从此处暂停，下次也将从此处恢复 } } 这个 yield() 函数就是将任务的状态保存到一个上下文中，然后再恢复任务的时候，将任务的状态从上下文中恢复。这个上下文保存了任务的完整状态，包括栈和寄存器等信息。如果你比较好奇这样的函数长什么样子，可以看看我的操作系统里的实现，我选中的这几行是保存操作系统内核协程上下文的代码，其他的则是保存/恢复用户程序上下文的的代码，基本上就是把一些寄存器和调用栈栈顶保存到一个结构体中，然后切换调用栈，然后再恢复的时候，将这些寄存器从结构体中恢复。注意这段代码必须使用汇编代码实现，一是我们需要手动操作指定寄存器，二是编译器生成的函数包含 Prologue 和 Epilogue，会修改我们的调用栈（同样是上两节课的内容）。\n而我们偷懒的做法就以来于，这是一个函数调用。既然是函数调用，就必须要遵循Calling Conventions。\nCalling Conventions要求将寄存器的保存职责分为两部分：Caller-Save 和 Callee-Save。Caller-Save 负责保存调用者需要保存的寄存器，Callee-Save 负责保存被调用者需要保存的寄存器。\nCaller-saved 要求，Caller在调用一个函数前保存这些寄存器，子过程可能使用这些寄存器的任意或全部，结束后，恢复也是 Caller 的责任。\n而 Callee-saved 要求，Callee 在调用一个函数前保存这些寄存器，子过程可能使用这些寄存器的任意或全部，在回到 Caller 时，Callee 必须保证这些寄存器的值与 Caller 调用自己前一样。\n因此，我们在这个过程中，只需要保存 Caller-saved 寄存器，而不需要保存 Callee-saved 寄存器。这样就可以简化我们的实现，只需要保存 Caller-saved 寄存器，而不需要保存 Callee-saved 寄存器。\nStackless Coroutine 你一定觉得，什么和调用栈切换，保存寄存器，还要用汇编指令进行操作太麻烦了，而且开销还一定特别大。因为我们需要保存整个栈，这个栈可能非常大，而且我们还需要保存整个寄存器，这个寄存器可能非常多。这样的开销是非常大的，而且实现起来也非常复杂。\n你的感觉没错！通常来说，一个栈的大小在，0.5 MB 到 4 MB 之间，而一个寄存器的数量在 16 到 32 个之间。这样的开销是非常大的，而且实现起来也非常复杂。\n考虑一下一个简单的生产者消费者模型，我们的生产者只产生 3 个数据，然后消费者消费这 3 个数据。\n1 2 3 4 5 6 7 8 fn producer() { // 产生数据 1 yield(); // 产生数据 2 yield(); // 产生数据 3 yield(); } 我们可以联想到，由于我们的代码是确定的，因此协程被挂起的时机或者说地点也是确定的！因此我们其实可以把这个过程视为一个 State Machine，即我们的协程有一个状态，然后根据这个状态，我们执行不同的代码。这样我们就可以实现 Stackless Coroutine。下面的函数是对上面代码所抽象的协程的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 static mut PRODUCER_STATE: i32 = -1; static mut PRODUCER_DATA: i32 = 0; fn producer() -\u0026gt; { match PRODUCER_STATE { -1 =\u0026gt; { PRODUCER_STATE = 0; // 产生数据 1，然后返回调用者 PRODUCER_DATA = \u0026lt;数据1\u0026gt;; } 0 =\u0026gt; { PRODUCER_STATE = 1; // 产生数据 2，然后返回调用者 PRODUCER_DATA = \u0026lt;数据2\u0026gt;; } 1 =\u0026gt; { PRODUCER_STATE = 2; // 产生数据 3，然后返回调用者 PRODUCER_DATA = \u0026lt;数据3\u0026gt;; } _ =\u0026gt; { PRODUCER_STATE = i32::MAX; // 标识协程过程的结束 // 任务结束，没有什么要做的 } } } 接下来，我们做一层包装，使得我们的协程看起来更加像一个函数：\n1 2 3 4 5 6 7 8 fn get_data() -\u0026gt; Option\u0026lt;i32\u0026gt; { if PRODUCER_STATE == i32::MAX { None } else { producer(); Some(PRODUCER_DATA) } } 当我们调用一次 get_data() 函数，我们的协程就会执行一次，然后返回一个数据。这样我们就实现了 Stackless Coroutine。\n不过我们这个 Stackless Coroutine 仍然非常 basic。倒不是说状态比较少。因为我们的状态是确定的，所以我们可以很容易地将状态转换为代码。事实上，像 .NET 这样的语言就会在编译期就将 Coroutine 方法转换为状态机函数，我们在编写代码时可以直接编写下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public static IEnumerable\u0026lt;int\u0026gt; Fib() { int prev = 0, next = 1; yield return prev; yield return next; while (true) { int sum = prev + next; yield return sum; prev = next; next = sum; } } 我想说的问题在于，我们的状态仍然是全局的，不与调用上下文关联，导致我们在不同地方想多次调用这个协程时，会出现问题。因此我们需要将状态与调用上下文关联，这就是下面要讲的 Generator。最显而易见的问题是，表示状态机状态的字段以及返回值的字段都是全局的，这样就无法在多个地方调用这个协程，因为这个协程的状态是全局的，不与调用上下文关联。因此我们定义一个 Struct。现在让我们尝试实现上面的 Fibonacci 协程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 enum State { Uninitialized, State1 State2, State3, Finished, Corrupted, } struct FibonacciCoroutine { state: i32, } impl Fibonacci { fn new() -\u0026gt; Self { Self { state: State::Uninitialized, } } } 当我们调用协程时，协程函数事实上需要与协程上下文关联，因此看起来像这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 impl Fibonacci { fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;i32\u0026gt; { match self.state { State::Uninitialized =\u0026gt; { self.state = State::State1; Some(0) } State::State1 =\u0026gt; { self.state = State::State2; Some(1) } State::State2 =\u0026gt; { self.state = State::State3; // ??? } _ =\u0026gt; { self.state = State::Finished; None } } } } 这样我们就实现了一个与调用上下文关联的协程。现在我们的无栈协程能够处理前两种状态了，也就是\n1 2 3 4 5 6 public static IEnumerable\u0026lt;int\u0026gt; Fib() { int prev = 0, next = 1; yield return prev; yield return next; } 但是后面的状态就麻烦了。当我们处于 State2 时，我们需要计算下一个数，然后返回。我们需要知道 prev 和 next 的值，但是这两个值是在上一个状态中计算的，我们无法在这个状态中访问这两个值。因此我们需要将这两个值保存到协程上下文中。让我们改造一下我们的状态机，将函数的所有局部变量都保存到协程上下文中：\n1 2 3 4 5 struct FibonacciCoroutine { state: i32, prev: i32, next: i32, } 然后我们的协程函数就变成了这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 impl FibonacciCoroutine { fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;i32\u0026gt; { match self.state { State::Uninitialized =\u0026gt; { self.state = State::State1; self.prev = 0; self.next = 1; Some(0) } State::State1 =\u0026gt; { self.state = State::State2; Some(1) } State::State2 =\u0026gt; { self.state = State::State3; // Watch this! let sum = self.prev + self.next; self.prev = self.next; self.next = sum; Some(sum) } _ =\u0026gt; { self.state = State::Finished; None } } } } 或者用更加 Type-safe 的方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 enum FibonacciCoroutine { Uninitialized, State1, State2, State3 { prev: i32, next: i32, }, Finished, } impl FibonacciCoroutine { fn new() -\u0026gt; Self { Self::Uninitialized } fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;i32\u0026gt; { match self { Self::Uninitialized =\u0026gt; { *self = Self::State1; Some(0) } Self::State1 =\u0026gt; { *self = Self::State2; Some(1) } Self::State2 =\u0026gt; { *self = Self::State3 { prev: 0, next: 1 }; Some(1) } Self::State3 { prev, next } =\u0026gt; { let sum = *prev + *next; *prev = *next; *next = sum; Some(sum) } _ =\u0026gt; { *self = Self::Finished; None } } } } 可以看到，我们通过将局部变量保存到协程上下文中，解决了这个问题。这就是无栈协程的基本原理。你可以思考一下，这个过程和有栈协程保存栈和寄存器的过程有什么不同，它们为什么明明看起来这么不同，但是实际上却是一样的。\nIterator Iterator 事实上就是一种无栈协程，只是是手动编写的。也并不总是一个显式状态机，但是它的实现原理和无栈协程是一样的。\n这里我给出一个遍历数组和前序遍历二叉树的例子：\nEnumerating an array 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 struct ArrayIterator\u0026lt;\u0026#39;a, T\u0026gt; { array: \u0026amp;\u0026#39;a [T], index: usize, } impl\u0026lt;\u0026#39;a, T\u0026gt; ArrayIterator\u0026lt;\u0026#39;a, T\u0026gt; { fn new(array: \u0026amp;\u0026#39;a [T]) -\u0026gt; Self { Self { array, index: 0, } } } impl\u0026lt;\u0026#39;a, T\u0026gt; ArrayIterator\u0026lt;\u0026#39;a, T\u0026gt; { pub fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;\u0026amp;\u0026#39;a T\u0026gt; { if self.index \u0026lt; self.array.len() { let result = \u0026amp;self.array[self.index]; self.index += 1; Some(result) } else { None } } } Preorder traversal of a binary tree 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 enum BinaryTree\u0026lt;\u0026#39;a, T\u0026gt; { Leaf(\u0026amp;\u0026#39;a T), Node(\u0026amp;\u0026#39;a T, Box\u0026lt;BinaryTree\u0026lt;\u0026#39;a, T\u0026gt;\u0026gt;, Box\u0026lt;BinaryTree\u0026lt;\u0026#39;a, T\u0026gt;\u0026gt;), } struct BinaryTreeIterator\u0026lt;\u0026#39;a, T\u0026gt; { stack: Vec\u0026lt;\u0026amp;\u0026#39;a BinaryTree\u0026lt;\u0026#39;a, T\u0026gt;\u0026gt;, } impl\u0026lt;\u0026#39;a, T\u0026gt; BinaryTreeIterator\u0026lt;\u0026#39;a, T\u0026gt; { fn new(tree: \u0026amp;\u0026#39;a BinaryTree\u0026lt;\u0026#39;a, T\u0026gt;) -\u0026gt; Self { let mut stack = Vec::new(); stack.push(tree); Self { stack } } } impl\u0026lt;\u0026#39;a, T\u0026gt; BinaryTreeIterator\u0026lt;\u0026#39;a, T\u0026gt; { pub fn next(\u0026amp;mut self) -\u0026gt; Option\u0026lt;\u0026amp;\u0026#39;a T\u0026gt; { while let Some(node) = self.stack.pop() { match node { BinaryTree::Leaf(leaf) =\u0026gt; return Some(leaf), BinaryTree::Node(node, left, right) =\u0026gt; { self.stack.push(left); self.stack.push(right); return Some(node); } } } None } } Asynchronous Programming C# 最早引入了异步编程模型和async/await编程模式，也是将异步应用得最成功的语言。通过 async 和 await 关键字，使得异步编程变得非常简单。Rust 也引入了异步编程模型，通过 async 和 await 关键字，使得异步编程变得非常简单。\n这里引用 Microsoft .NET team 员工 Stephen Toub 的文章，你可以在这里找到原文：Stephen Toub - How Async/Await Really Works in C#。直接从我给的地方开始阅读即可。\nAsync/Await 编程模型最大的好处在于，你只需要做很小的修改，就可以将同步代码转换为异步代码。这样就可以非常方便地编写异步代码，而不需要关心异步编程的细节。很小的修改在于：\n为方法添加 async 关键字，表示这个函数是一个异步函数 将方法中调用的方法全部替换为异步方法，并添加 await 关键字来等待异步方法的返回值 然后就结束了！考虑以下两段代码，一眼看上去几乎没有什么区别：\nSynchronous Version:\n1 2 3 4 5 6 7 8 9 public void CopyStreamToStream(Stream source, Stream destination) { var buffer = new byte[0x1000]; int numRead; while ((numRead = source.Read(buffer, 0, buffer.Length)) != 0) { destination.Write(buffer, 0, numRead); } } Asynchronous Version:\n1 2 3 4 5 6 7 8 9 public async Task CopyStreamToStreamAsync(Stream source, Stream destination) { var buffer = new byte[0x1000]; int numRead; while ((numRead = await source.ReadAsync(buffer, 0, buffer.Length)) != 0) { await destination.WriteAsync(buffer, 0, numRead); } } 这个过程与无栈协程非常相似，只是我们的状态是确定的，因此我们可以将状态转换为代码。首先我们可以构建以下状态机对象：\n1 2 3 4 5 6 7 8 struct CopyStreamToStreamAsyncStateMachine : IAsyncStateMachine { public int state; public Stream source; public Stream destination; private byte[] buffer ... } 然后我们编写的方法被替换成一个状态机初始化器，并返回一个状态机对象\n1 2 3 4 5 6 7 8 9 10 11 public Task CopyStreamToStreamAsync(Stream source, Stream destination) { var stateMachine = new CopyStreamToStreamAsyncStateMachine { state = -1, source = source, destination = destination, buffer = new byte[0x1000], }; return stateMachine.Task; } 当我们调用这个方法时，实际上并不会执行这个方法，而是返回一个状态机对象（C# 有些不同，具有 Fire and forget 的特性，但是这里我们不讨论这个问题）。然后们要调用这个方法时，实际上需要使用 await 关键字。\n这个关键字的作用是，将当前的方法挂起，然后将控制权交给状态机对象，然后状态机对象根据当前的状态，执行相应的代码。这个过程就是异步编程的基本原理。\n也就是说，对于下面的语句await CopyStreamToStreamAsync(src, dst);，实际上会被转换为：\n1 2 3 4 5 6 while (stateMachine.MoveNext()) // 轮询一次状态机，如果有工作，就去工作，如果没有，返回 false { yield(); // 这里的 yield，就是跟上面的 yield 一样，将当前任务挂起，然后返回调用者 // 在实际的代码中，就是 return. } result = stateMachine.Result; // 获取状态机的返回值 这就是异步编程的基本原理。你可以看到，异步编程的本质就是无栈协程，只是我们的状态是确定的，因此我们可以将状态转换为代码。这就是异步编程的基本原理。\n","date":"2024-12-01T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/os-week7-coroutine-iterator-asynchronous-programming/","title":"[OS Week7] Coroutine, Iterator \u0026 Asynchronous Programming"},{"content":" 本文摘自龙芯杯团队赛发布包中的仿真调试说明及《CPU设计实战》\n仿真调试 仿真调试概述 写在前面 首先的首先! 充分了解你的设计! 了解你的设计! 了解你的设计! 重要的事情说三遍! 千万不要在不了解设计功能的情况下进行调试，这样会浪费大量的时间。\n一些小技巧 记录所有信号的波形 在默认设置下, 只有被添加进波形窗口的信号才会被记录, 但是有时候我们需要记录所有信号的波形, 这时候就会发现新加入的波形并没有信号, 不得不重新运行一次仿真才能获得波形, 这样会浪费大量时间, 所以我们希望可以一次性记录所有信号的波形, 这样就可以避免重复运行仿真。 在Vivado工程视图下, 点击左侧\u0026quot;Project Manager\u0026quot; -\u0026gt; \u0026ldquo;Settings\u0026rdquo;, 在弹出的设置界面中选择\u0026quot;Project Settings\u0026quot; -\u0026gt; \u0026ldquo;Simulation\u0026rdquo;, 在右侧的\u0026quot;Simulation\u0026quot;选项卡中, 将\u0026quot;xsim.simulate.log_all_signals\u0026quot;复选框勾选, 这样就可以一次性记录所有信号的波形了。 给重要时刻做标记 善用波形窗口的标记功能, 可以避免回溯哪里出问题的时候浪费大量时间。 信号分组 当你的调试信号非常多的时候, 上下翻看信号十分容易出现混乱, 这时建议可以将信号分组, 比如把同一个模块或者同一个流水级的信号放在同一个group中, 这样可以试调试需求收起或展开。 信号搜索 如果你需要从某一时刻向前或向后找一个多位宽信号等于某个值的时刻, 除非你十分确定它就在附近, 否则强烈建议使用值查找方法, 而不是手动翻找。 调试思路概述 调试是指在我们设计的一个系统在执行功能出现了错误时，定位出错误的原因。比如我们设计了一个CPU，在运行一个测试程序时发现结果不对，这时就需要进行调试，以便后续进行纠正。可以看到全局上的调试原理是从结果推原因，难点就是定位错误的源头。 本文档编写时采用的的调试思路是: 时间上先定错，空间上再定错。一个设计在执行功能出现错误时，往往是在一个大片的时间段内该设计的电路的执行都不符合预期。“时间上先定错，空间上再定错”具体解释如下:\n时间上先定错: 在出错的大片时间段里，定位出源头部分，源头部分是一个较小的时间段。 空间上再定错: 在源头时间段里，查看设计电路的控制部分和数据通路，定位是哪个信号带来的错误，或者是哪几个信号的组合带来的错误，或者是设计上哪里有疏忽带来的错误。 比如一个设计的 CPU 在执行测试程序出错了，这个程序是分很多指令的，这些指令是在时间上顺序执行的，我们首先需要找出第一个错误的的指令（也就是时间上定位错误），随后在 CPU 的数据通路和控制信号里定位该指令错误的原因（也就是空间上定位错误）。\n相对于空间上的定错，时间上的定错更加困难。特别是对CPU调试而言，更是如此，往往80%的精力都用于时间上定错了。 时间上定错和空间上定错，是一种针对设计的整体调试的指导思想。但当我们仿真发现一个错误时，往往需要先去辨别错误时什么类型，并按照一定的方法追踪错误原因。\n仿真出错情况按照波形直接观察结果可分为两类:\n波形出错: 从波形图里直接观察，而不需要分析电路设计的功能，就能判断的错，比如波形中信号为 “X”。 逻辑出错: 波形直接观察很正常，但其电路执行结果不符合预期，属于逻辑出错，比如加法器运行结果不 对。 “波形出错”为浅层次的出错，都是很容易查找到原因的。 “逻辑出错”则是深层次的出错，是真正调试难点，其具体内容也是包罗万象。 波形出错 波形出错，细分又可归为以下几类:\n发现信号为“Z” 发现信号为“X” 波形停止: 某一时刻开始仿真波形不再输出新内容, 而仿真仍在进行 越沿采样: 上升沿采样到被采样数据在上升沿后的值 其他，波形怪异: 仿真波形图显示怪异，与设计的电路功能无关的错误 信号为“Z” “Z”表示高阻，比如电路断路了就是显示为高阻，往往是模块调用的信号未连接导致的信号悬空，如下图: 上图示例中有一下几点比较重要：\n信号值为“Z”，为模块调用是信号未连接，未连接包括两种：显式的未连接，如图 1-1(a)中的.c()；隐式的未连接，如图 1-1(a)中模块adder调用时，a端口即未连接。“显式的未连接”一般是人为故意设置的，只针对 output 类接口；“隐式的未连接”则是疏忽，属于代码不规范，往往也是导致信号值为“Z”的主要原因。 adder 模块里，a 端口未连接，导致 a 为“Z”，但 c 端口也未连接，c 却是固定值。这是因而 a 端口是input，c 端口是 output。output 类接口未连接是母模块里不使用该信号，可能是人为故意设置的。所有的input 类接口被调用时不允许悬空。 adder 模块里 a信号从 0时刻开始就是“Z”，而 a_r 信号确实在 100ns 左右才变成“Z”的。这是因而 a信号为端口，被调用时就未链接，故从0刻就为“Z”，但a_r信号是内部寄存器，从100ns时刻才使用a信号参与赋值，所以也变成了“Z”。 针对以上以上几点，我们有一下几点建议：\nRTL编写时注意代码规范，特别是模块调用时，按接口顺序一一对应。 所有input类接口被调用时不允许悬空。 一旦发现一个信号为“Z”，向前追踪产生该信号的因子信号，看是哪个为“Z”，一直追踪下去直到追踪到该模块里的input接口，随后进行修正。 有可能“Z”只出现在向量信号里的某几位上，也是一样的追踪，有可能调用时某个接口存在宽度不匹配也会带来该接口上某些位为“Z”。 信号为“X” “X”表示未赋值，比如寄存器未初始化，多驱动等，如下图: 在上图中，由于b_r信号声明后始终未赋值，导致其值为“X”，后续 c信号由于使用了b_r信号，导致其值也为“X”。\n另外，Vivado对于多驱动（2个及2个以上电路单元驱动同一信号），仿真时也会产生“X”信号，如下图: 这种情况下追寻信号为“X”的原因可能不太好追，可以尝试先进行综合，观察下Critial warning，此时会报出多驱 动的警告, 如下图: 针对信号为“X”情况，我们有以下几点建议:\n一旦发现仿真错误来自某个信号为“X”，则向前追踪产生该信号的因子信号，看是哪个为“X”，一直追踪下去直到追踪到某个信号未赋值，随后修正。 如果因子信号都没有为X的，则很可能是多驱动导致的，则综合排查Error和Critical warning。 寄存器型信号如果没有复位值，在复位阶段其值可能也为“X”，但可能这并不会带来错误。 “X”和1进行或运算结果为1，“X”和0进行或运行结果为0。 波形停止 波形停止是指仿真停止某一时刻，再也无法前进分毫，而仿真却显示不停地在运行，如下图: 另外一种波形停止的情况是tcl报错“FATAL_ERROR: Iteration limit 10000 is reached.” 波形停止基本都是由于“组合环路”导致的，所谓组合环路就是信号A的组合逻辑表达式中某个产生因子为B，而B的组合逻辑表达式中又用到了信号A，如上图源码c_t用到了c，而c又用到c_t。仿真器是在每个周期内计算该周期的所有表达式，组合逻辑循环嵌套，带来的是仿真器的循环计算，导致其无法退出该计算，带来了波形停止的现象。 由于波形停止出现时，并不好排查哪里写出了组合环路，我们建议按以下处理：\n一旦发现波形停止，则先对设计进行综合。 查看综合产生的Error和Critical warning，并尝试修正。比如上图示例中的组合环路，经过Vivado的综合 后变成了一个多驱动的关键警告，如下图: 另外，Vivado工程中有 TCL命令 report_timing_summary，会检查组合环路，并报出检查结果。但很遗憾，对于我们上图的示例，该命令并没有检查出组合环路，很有可能和综合时变成了多驱动有关。\n越沿采样 越沿采样在波形出错中是一个隐藏较深的出错，往往可能会和逻辑出错混在一起。初看起来，其波形也是很正常的，而且在发生越沿采样后，往往会再执行很长时间才会出错。因而需要大家先按照逻辑出错去调试，最后如果发现数据采样有些异常，就需要甄别下是否是越沿采样的错误了。 越沿采样是指一个被采样的信号在上升沿采样到了其在上升沿后的值，一般情况下，认为这是一个错误，如下图: 上图示例中在105ns时刻，clk上升沿到来，a_r和a_r_r同时变为了 1（也就是a的值）。a_r在105时刻前是0，在 105时刻后是 1。从源码来看，a_r_r是在上升沿采样a_r的值，结果其在 105时刻采样到 a_r为1的值，也就是采样到了a_r在同一上升沿后的值。这就属于越沿采样。 造成这一现象更深层的原因是Verilog里阻塞赋值“=”和非阻塞赋值“\u0026lt;=” 混用。上图源码中a_r采用阻塞赋值，而a_r_r采用非阻塞赋值。 每一次赋值，分为两步：为计算等式左侧的表达式和赋值给右侧的信号，简记为计算和赋值。在一个上升沿到来时，所有由上升沿驱动的信号按以下顺序进行处理：\n先处理阻塞赋值，先完成计算和赋值，同一信号完成计算后立马完成赋值。同一 always 块里的阻塞赋值从上到下按顺序串行执行，不同 always 块里的阻塞赋值依赖工具实现确定顺序串行执行，一一完成计算和赋值。 再进行非阻塞赋值的计算。所有非阻塞赋值其等式左侧的值都同时计算好。 上升沿结束时，所有非阻塞赋值同时完成最终的赋值动作。 从以上描述可以看到，非阻塞赋值是在上升沿的最后一个时间步里完成处理的，晚于阻塞赋值的处理。所以上图示例中，a_r_r的赋值晚于a_r的赋值，造成了越沿采样的情况。 越沿采样，除非特意设计，一般我们认为是一个设计错误，针对越沿采样，我们有一下几点建议：\nRTL编写时注意代码规范，所有always写的时序逻辑只允许采用非阻塞赋值。 一旦发现越沿采样的情况，追踪被采样信号，直到追踪到某一个阻塞赋值的信号，随后进行修正。 波形怪异 目前未能想到的波形出错的类型都归为波形怪异。 当出现波形怪异类的错时，需要区分其是仿真工具出错还是RTL代码出错：\n观察出错的信号，看其生成因子，如果自我判断 RTL 应该没有，且波形显示确实太怪异（比如始终为 32’hxx?x0x?），则很有可能仿真工具出错。重启电脑甚至重建工程试试。 实在无法从波形里区分出是什么错。可以尝试先运行综合，看出综合后的 Error、Critical warning 和 warning。其中Error是必须要修正的，Critical warning是强烈建议要修正的，warning是建议能修则修的。 经常有些不符合规范的代码，Vivado也不会报出 Warning，需要大家仔细复核自己的代码。常见的隐蔽错 误有：对input信号进行了赋值，模块调用信号连接错误，reset信号接成了clock信号，等等。 逻辑出错 逻辑出错则是包罗万象，错误类型是设计的电路功能有错，此时波形界面看起来是很正常的，我们需要利用波形观察各信号的变化，结合预定的电路功能进行定错。 以数据和控制分开来看，逻辑出错可分为两类：数据通路出错和控制信号出错。其中数据通路通常属于较简单的错，比如加法器算两个加数的和，结果不对；而控制信号出错则往往比较难调，往往是设计时的边角问题考虑不周导致的，比如 CPU 的访存系统出错。这些都是逻辑上出错了，但是很不幸的是，在我们未能定位出该错误的源头时，我们往往不能判断出其是数据通路出错，还是控制信号出错。电路设计者在设计之初应当对整个电路 有较全面的认识和考虑，尽量减少控制信号出错的情况。 逻辑出错时，不同的电路设计有其特定的调试手段，难以总结出统一的调试手段，但他们的指导思想是一致的：时间上先定错，空间上再定错。\n以下我们将针对CPU的逻辑出错调试作简单的说明，主要以流水线CPU为例进行说明。\n定位出错时间源头 首先需要各流水级信号分组抓出，比如抓出每级流水里的 PC 值、指令编码和执行结果。 流水级间的进入和退出的控制信号也尤其重要，必须抓出，CPU 初期调试往往都是流水线控制出错了。 具体调试时，可以采用一下方案：\n在波形最后出错处，确认取回的指令和 PC 值是对应正确的，也就是确认取指正确，这时就需要对照反汇编程序test.s。 如果取指不正确，则往前追溯，直到第一个取指正确的地方。追溯的方法也有讲究，有时不能简单一条条指令追溯，因为第一个取指正确的地方可能在很早之前，必要的时候，应跨越一大段指令段，去确认取指是否正确。追溯过程就是程序段不停的压缩，直到找到第一个取指正确的地方，此时往往要用到仿真工具中加标签的方法。 找到第一条指令正确的地方后，可以先确认该指令执行结果是否正确。随后我们的调试目标是确认时间上第一个出错的地方是在该指令前还是在该指令后。确认方法就需要结合测试程序，比如判断该指令位于的函数，确认该函数是否应该执行，其进入条件是否正确。这里有很多种调试方法，需要根据具体情况具体分析，无法很好的总结分类，需要大家在实践中进行总结。总而言之，需要将测试程序代码和 CPU 结合起来联调。 以上方法是由后往前追，如果追溯过程中发现无法再追了，则可以考虑由前往后追。这里的“前”就需要大家好好定位了，甚至可能存在运气的成分，一定要确保这个“前”之前的程序执行时对，这样往后追才能追到正确的第一个错误的店，否则，只会将自己引向错误的方法。 时间上的定错，要求大家对func测试程序有一定的了解和掌握。\n定位出错空间源头 在完成时间上的定错后，也就是找到一个执行出错的指令后，需要进行空间定错了。\n空间定错时需要大家对CPU微结构有更深入的理解。建议大家以空间划分的视角去理解CPU，特别是流水线CPU，每一流水级都是有对应的部件的，应当理解清楚各流水级的划分。 空间定位时，有两种方法：\n从CPU流水前端向流水后端排查，确认指令在哪个流水级开始出错。首先要排查的就是取指是否正确。 从 CPU 流水后端向流水前端排查，确认指令是从哪个流水级出错的。首先要排查的就是写回结果是否正确。 上板调试 当出现上板和仿真的行为不一致的时候, 调试起来就会变得非常困难, 请按照以下步骤进行调试:\n复核生成、下载的bit文件是否正确 请再次确认烧录的bit文件是否是最新正确的bit文件。 bit文件默认在 \\project\\loongson.runs\\impl_1\\ 目录下的 soc_lite_top.bit 文件。\n复核仿真结果是否正确 顶层不能出现“X”或“Z”, 特别是控制信号。\n检查时序报告 Vivado 界面左侧“IMPLEMENTATION” -\u0026gt; “Open Implemented Design” -\u0026gt; “Report Timing Summary”, 确保所有时序都是正的。 如果有负值, 可以点击数值查看具体路径(称为关键路径), 右键点击原理图查看具体路径, 根据路径分割关键路径使得时序满足。 一般我们用以下几个方法解决建立时间不满足问题:\n简化逻辑 插入触发器 降低时钟频率 时序报告阅读教程可参考或者自行百度。\n修正warning 认真排查综合和实现时的Warning，特别是Critical Warning，尽量修正。 可以使用Vivado界面左侧\u0026quot;RTL ANALYSIS\u0026quot; -\u0026gt; \u0026ldquo;Run Linter\u0026quot;查看Linter Warning。 检查RTL代码 认真排查RTL代码规范，避免多驱动、阻塞赋值乱用、模块端口乱接、时钟复位信号接错\u0026hellip;\u0026hellip;\n调整随机种子复现上板错误 如果上板时发现在某一些随机种子下测试通过，在另一些随机种子情况下出错，请确认出错的随机种子，修改 rtCONFREG/confreg.v 里的 RANDOM_SEED 的定义，改为出错时的随机种子，随后进行仿真：如果有错，则调试；如果发现仿真没错，则在上板时找寻下一个出错的随机种子，同样设定好RANDOM_SEED后进行仿真，如果还是没错则转下一步。 最后的功能测试通过的要求是：上板后，随意切换拨码开关，均不会出错。\n使用逻辑分析仪进行在线调试 请先重点排查其他问题，最后再使用在线调试的方法 这个真的超级超级麻烦 请参考 如果还是解决不了直接转下一步\n反思 真的，现在除了反思还能干什么？\n","date":"2024-11-28T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/debug%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/","title":"Debug方法概论"},{"content":"基于trace比对的调试框架 在调试C程序的时候应该都使用过单步调试这种调试手段。在“慢动作”运行程序的每一行代码的情况下，能够及时看到每一行代码的运行行为是否符合预期，从而能够及时定位到出错点。在实验开发环境中提供的这套基于trace比对的调试辅助手段，借鉴的就是这种“单步调试”的策略。\n其具体实现方式是：我们先用一个已知的功能上是正确的CPU运行一遍测试指令序列，将每条指令的PC和写寄存器的信息记录下，记为golden_trace；然后在验证myCPU的时候运行相同的指令序列，在myCPU每条指令写寄存器的时候，将myCPU中的PC和写寄存器的信息同之前的golden_trace进行比对，如果不一样，那么立刻报错并停止仿真。\n简单的来说, golden_trace就是参考答案, 通过比对myCPU的运行结果和golden_trace的运行结果, 来判断myCPU功能的正确性。\n功能测试环境使用方法 基于NSCSCC2024 团体赛功能测试 它是CPU设计实战\u0026ndash;Loongarch版的实验环境的exp16\n开发环境组织结构介绍 整个实验开发环境的基本目录结构及各部分功能简介如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 |--func/ 功能验证测试程序 | |--obj/ 编译生成的二进制测试程序 | |--inst_ram.coe 测试程序对应上板用的二进制纯数据文件 | |--inst_ram.mif 测试程序对应功能仿真用的二进制纯数据文件 | |--inst_ram.txt 测试程序汇编代码说明 | |--gettrace/ trace文件生成工程 | |--gettrace.xpr 生成golden_trace的Vivado工程文件 | |--golden_trace.txt 生成的golden_trace文件 | |--myCPU/ 待验证的CPU设计代码目录 | |--soc_verify/soc_axi 所现的CPU的SoC验证环境 |--rtl/ 验证用SoC设计代码目录 | |--soc_lite_top.v SoC的顶层文件 | |--CONFREG/ confreg模块，用于访问实验板上的LED灯、拨码开关等外设 | |--xilinx_ip/ 定制的Xilinx IP，包含clk_pll、inst_ram | |--testbench/ 功能仿真验证平台 | |--mycpu_tb.v 功能仿真顶层，该模块会抓取debug信息与golden_trace.txt进行比对 | |--run_vivado/ Vivado工程的运行目录 |--constraints/ Vivado工程设计的约束 |--create_project.tcl 创建Vivado工程的tcl脚本 SoC_Lite片上系统结构介绍 用于验证myCPU的片上系统 PLL: 锁相环，用于产生时钟信号 iram: 指令内存，用于存放测试程序 dram: 数据内存，用于存放数据 confreg: 外设控制器，用于控制LED灯、拨码开关等外设 mycpu: 待验证的CPU设计 因为在LoongArch指令系统架构下，所有I/O设备的寄存器都是采用memory mapped方式访问的。我们这里实现的confreg也不例外。Memory mapped的访问方式意味I/O设备中的寄存器各自都有一个唯一内存编址，所以CPU可以通过load、store指令对其进行访问。\n生成golden_trace func功能测试程序 以下涉及Linux编译的部分不要求大家初期掌握, 包里已经提供了编译好的最终文件\nfunc测试程序说明 func程序分为func/start.S和func/inst/*.S，都是LoongArch32汇编程序:\nfunc/start.S ：主函数，执行必要的启动初始化后调用func/inst/下的各汇编程序。 func/inst/*.S ：针对每条指令或功能点有一个汇编测试程序。 func/include/*.h ：测试程序的配置信息和宏定义。 主函数func/start.S中主体部分代码如下，分为三大部分，具体查看注释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 ...... #以下是设置程序开始的LED灯和数码管显示，单色LED全灭，双色LED灯一红一绿。 LI (a0, LED_RG1_ADDR) LI (a1, LED_RG0_ADDR) LI (a2, LED_ADDR) LI (s1, NUM_ADDR) LI (t1, 0x0002) LI (t2, 0x0001) LI (t3, 0x0000ffff) lu12i.w s3, 0 NOP4 st.w t1, a0, 0 st.w t2, a1, 0 st.w t3, a2, 0 st.w s3, s1, 0 #以下是运行各功能点测试，每个测试完执行idle_1s等待一段时间，且数码管显示加1。 inst_test: bl n1_lu12i_w_test #lu12i.w bl idle_1s bl n2_add_w_test #add.w bl idle_1s ...... #以下是显示测试结果，PASS则双色LED灯亮两个绿色，单色LED不亮； #Fail则双色LED灯亮两个红色，单色LED灯全亮。 test_end: LI (s0, TEST_NUM) NOP4 beq s0, s3, 1f LI (a0, LED_ADDR) LI (a1, LED_RG1_ADDR) LI (a2, LED_RG0_ADDR) LI (t1, 0x0002) NOP4 st.w zero, a0, 0 st.w t1, a1, 0 st.w t1, a2, 0 ...... inst/ 目录下每个功能点的测试代码程序名为n#_*_test.S，其中“#”为编号，如有15个功能点测试，则从n1编号到n15。每个功能点的测试，其测试代码大致如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ...... LEAF(n1_lu12i_w_test) addi.w s0, s0 ,1 #加载功能点编号s0++ addi.w s2, zero, 0x0 lu12i.w t2, 0x1 ###test inst addi.w t1, zero, 0x0 TEST_LU12I_W(0x00000, 0x00000) ...... #测试程序，省略 TEST_LU12I_W(0xff0af, 0xff0a0) ###detect exception bne s2, zero, inst_error ###score ++ #s3存放功能测试计分，每通过一个功能点测试，则+1 addi.w s3, s3, 1 ###output (s0\u0026lt;\u0026lt;24)|s3 inst_error: slli.w t1, s0, 24 NOP4 or t0, t1, s3 #s0高8位为功能点编号，s3低8位为通过功能点数， #相或结果显示到数码管上。 NOP4 st.w t0, s1, 0 #s1存放数码管地址 jirl zero, ra, 0 END(n1_lu12i_w_test) 从以上可以看到，测试程序的行为是：当通过第一个功能测试后，数码管会显示0x0100_0001，随后执行idle_1s；执行第二个功能点测试，再次通过数码管会显示0x0200_0002，执行idle_1s……依次类推。显示，每个功能点测试通过，应当数码管高8位和低8位永远一样。如果中途数码管显示从0x0500_0005变成了0x0600_0005，则说明运行第六个功能点测试出错。\n最后来看 start.S 文件中 idle_1s 函数的代码，其使用一个循环来暂停测试程序执行的。其主体部分代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 idle_1s: ...... #initial t3 //读取confreg模块里的switch_interleave的值 ld.w t2, t0, 0 #switch_interleave: {switch[7],1\u0026#39;b0, switch[6],1\u0026#39;b0...switch[0],1\u0026#39;b0} NOP4 xor t2, t2, t1 //拨码开关拨上为0，故要xor来取反 NOP4 slli.w t3, t2, 9 #t3 = switch interleave \u0026lt;\u0026lt; 9 NOP4 sub1: addi.w t3, t3, -1 //t3累减1 #select min{t3, switch_interleave} //获取t3和当前switch_interleave的最小值 ld.w t2, t0, 0 #switch_interleave:{switch[7],1\u0026#39;b0,switch[6],1\u0026#39;b0...switch[0],1\u0026#39;b0} NOP4 xor t2, t2, t1 NOP4 slli.w t2, t2, 9 #switch interleave \u0026lt;\u0026lt; 9 NOP4 //以上ld.w-xor-slli.w三条指令再次获取switch_interleave sltu t4, t3, t2 //无符号比大小，如果t3比switch_interleave 小则置t4=1 NOP4 bne t4, zero, 1f //t4!=0,意味着t3比switch_interleave大，则跳1f nop addi.w t3, t2, 0 //否则，将t3赋值为更小的switch_interleave NOP4 1: bne t3,zero, sub1 //如果t3没有减到0，则返回循环开头 jirl zero, ra, 0 //结束idle_1s 从以上代码可以看到，idle_1s 会依据拨码开关的状态设定循环次数。在仿真环境下，我们会模拟拨码开关为全拨下的状态，以使 idle_1s 循环次数最小。之所以这样设置，是因为 FPGA 运行远远快于仿真的速度，假设CPU运行一个程序需要106个CPU周期，再假设CPU在FPGA上运行频率为10MHz，那其在FPGA上运行完一个程序只需要0.1s；同样，我们仿真运行这个程序，假设我们仿真设置的CPU运行频率也是10MHz，那我们仿真运行完这个程序也是只需要0.1s吗？显然这是不可能的，仿真是软件模拟CPU运行情况的，也就是它要模拟每个周期CPU内部的变化，运行完这一个程序，需要模拟106个CPU周期。我们在一台2016年产的主流X86台式机上进行实测发现，Vivado自带的Xsim仿真器运行SoC_Lite的仿真，每模拟一个周期大约需要600us，这意味着Xsim上模拟106个周期所花费的实际时间约10分钟。\n同一程序，运行仿真测试大约需要10分钟，而在FPGA上运行只需要0.1秒（甚至更短，比如CPU运行在50MHz主频则运行完程序只需要0.02s）。所以我们如果不控制好仿真运行时的 idle_1s 函数，则我们可能会陷入到idle_1s长时间等待中；类似的，如果我们上板时设定 idle_1s 函数很短（比如拨码开关全拨下），则 idle_1s 时间太短导致我们无法看到数码管累加的效果\n如果大家在自实现CPU上板运行过程中，发现数码管累加跳动太慢，请调小拨码开关代表的数值；如果发现数码管累加跳动太快，请调大拨码开关代表的数值。\nLoongArch-GCC交叉编译工具的安装 自行编译func程序需要使用LoongArch32R的GCC交叉编译工具。该工具链的安装可以从 https://gitee.com/loongson-edu/la32r-toolchains 下载源码自行编译、安装，也可以直接从 https://gitee.com/loongson-edu/la32r-toolchains/releases 下安装包。我们这里主要介绍后一种方式的安装步骤。\n下载安装包时请根据所用机器是X86还是LoongArch选择对应的版本。下载压缩包 loongarch32r-linux-gnusf-*.tar.gz 至Linux操作系统自身的文件系统中。需要特别提醒的是，目前X86版本LoongArch32R的GCC交叉编译工具只支持64位系统（在系统下运行uname -a命令显示架构为x86_64的）。接下来：\n（1）打开一个terminal，进入压缩包所在目录，进行解压：\n$ sudo tar zxvf loongarch32r-linux-gnusf-*.tar.gz -C /opt/ （2）确保目录/opt/loongarch32r-linux-gnusf-*/bin/存在，随后执行：\n$ echo “export PATH=/opt/loongarch32r-linux-gnusf-*/bin/:$PATH” \u0026gt;\u0026gt; ~/.bashrc （3）重新打开一个terminal，输入loongarch32然后敲击tab键，如果能够-linux-gnusf-之类的补全，就说明工具链已经安装成功。此时可以编写一个hello.c 然后用工具链进行编译看其是否可以工作。\n$ loongarch32r-linux-gnusf-gcc hello.c func测试程序编译说明 编译脚本 func测试程序的编译脚本为验证平台目录下的func/Makefile，对Makefile了解的可以去看下该脚本。该脚本支持以下命令：\nmake help ：查看帮助信息 make ：编译得到仿真下使用的结果 make clean ：删除*.o，*.a和./obj/目录 编译结果 func测试程序编译结果位于func/obj/下, 主要会用到的文件及作用如下:\ninst_ram.coe ：定制inst_ram所需的数据文件 inst_ram.mif ：仿真时inst_ram读取的数据文件 test.s : 对main.elf反汇编得到的文件 golden_trace生成 进入 gettrace/ 目录，打开gettrace.xpr工程文件，运行仿真，自动生成参考结果golden_trace.txt。 重点关注此时inst_ram加载的确实是前一个步骤编译出的结果。 要等仿真运行完成，golden_trace.txt才有完整的内容。\n验证自己的CPU CPU对外总线接口 一般来说我们根据由易到难挨个实现SRAM接口, 带握手的SRAM接口, AXI总线接口, 这里我们以SRAM接口为例:\n名称 位宽 方向 描述 clk 1 input 时钟信号, 来自clk_pll的时钟输出 resetn 1 input 复位信号, 低电平同步复位 int 8 input 中断信号, 8个硬件中断信号, 高电平有效 inst_sram_en 1 output 指令内存使能信号, 高电平有效 inst_sram_wen 4 output 指令内存字节写使能信号, 高电平有效 inst_sram_addr 32 output 指令内存地址, 字节寻址 inst_sram_wdata 32 output 指令内存写数据 inst_sram_rdata 32 input 指令内存读数据 data_sram_en 1 output 数据内存使能信号, 高电平有效 data_sram_wen 4 output 数据内存字节写使能信号, 高电平有效 data_sram_addr 32 output 数据内存地址, 字节寻址 data_sram_wdata 32 output 数据内存写数据 data_sram_rdata 32 input 数据内存读数据 debug_wb_pc 32 output 写回级（多周期最后一级）的PC debug_wb_rf_we 4 output 写回级写寄存器堆(regfiles)的写使能，为字节写使能 debug_wb_rf_wnum 5 output 写回级写寄存器堆(regfiles)的目的寄存器号 debug_wb_rf_wdata 32 output 写回级写寄存器堆(regfiles)的写数据 打开Vivado工程 测试平台采用tcl脚本来创建工程, 方法如下:\n启动Vivado 点击最下方的\u0026quot;Tcl Console\u0026quot;标签 cd到 /soc_verify/soc_axi/run_vivado/ 目录下 输入 source create_project.tcl 创建Vivado工程 如果你的CPU设计代码在 /myCPU/ 目录下, 则会自动导入到工程中, 请检查是否导入成功, 如未成功请手动导入 更具体可参考\nfunc测试验证结果判断 仿真结果正确判断 仿真结果正确判断有两种方法。\n第一种方法，也是最简单的，就是看Vivado控制台打印Error还是PASS。正确的控制台打印信息如下图: 第二种方法，是通过波形窗口观察程序执行结果func正确的执行行为，抓取confreg模块的信号led_data、led_rg0_data、led_rg1_data、num_data：\n开始，单色LED写全1表示全灭，双色LED写0x1和0x2表示一红一绿，数码写全0； 执行过程中，单色LED全灭，双色LED灯一红一绿，数码管高8位和低8位同步累加； 结束时，单色LED写全1表示全灭，双色LED均写0x1表示亮两绿，数码管高8位和低8位数值（十六进制）相同，对应测试功能点数目。 上板验证结果正确判断 func正确的执行行为是：\n开始，单色LED全灭，双色LED灯一红一绿，数码管显示全0； 执行过程中，单色LED全灭，双色LED灯一红一绿，数码管高8位和低8位同步累加； 结束时，单色LED全灭，双色LED灯亮两绿，数码管高8位和低8位数值相同，对应测试功能点数目。 如果func执行过程中出错了，则数码管高8位和低8位第一次不同处即为测试出错的功能点编号(只要不同步变化即有错误)，且最后的结果是单色LED全亮，双色LED灯亮两红，数码管高8位和低8位数值不同。\n最后FPGA验证通过的效果如下图: 拨码开关的作用 1.复位后，拨码开关控制wait_1s的循环次数，也就是控制数码管累加的速度。每两个功能点之间会穿插一个wait_1s函数，wait_1s通过一段循环完成计时的功能：在上板时，wait_1s 循环次数由拨码开关控制，可设置循环次数为 （0~0xaaaa）*$2^9$ 。请在复位后，通过拨码开关选择合理的wait_1s延时。 2.复位期间，拨码开关控制随机种子（只对 soc_axi_func 环境有用），也就是axi_ram访问随机延迟的初始种子。 上板时，按下复位键，会自动采样8个拨码开关的值，传为初始随机种子，且会显示初始随机种子低16位到单色 LED 灯上。 上板时随机种子与拨码开关对应关系如下表，需要注意的时延迟类型依据拨码开关的值分为三大类：长延迟、短延迟和无延迟类型。在上板运行时都应当覆盖到这三类延迟类型。\n拨码开关状态 LED显示 初始种子 拨上为1 每个拨码开关对应两个led 长延迟:[7:0]!=8\u0026rsquo;hff, 短延迟:[7:0]=8\u0026rsquo;hff, 无延迟:[15:0]==16\u0026rsquo;h00ff 8\u0026rsquo;h00 16\u0026rsquo;h0000 {7\u0026rsquo;b1010101, 16\u0026rsquo;h0000} 8\u0026rsquo;h01 16\u0026rsquo;h0003 {7\u0026rsquo;b1010101, 16\u0026rsquo;h0003} 8\u0026rsquo;h02 16\u0026rsquo;h000c {7\u0026rsquo;b1010101, 16\u0026rsquo;h000c} 8\u0026rsquo;h03 16\u0026rsquo;h000f {7\u0026rsquo;b1010101, 16\u0026rsquo;h000f} \u0026hellip; \u0026hellip; \u0026hellip; 8\u0026rsquo;hff 16\u0026rsquo;hffff {7\u0026rsquo;b1010101, 16\u0026rsquo;hffff} 进阶: chiplab的difftest测试平台 difftest相比于trace比对的调试平台更加强大, 它将相同的指令分别给设计核核参考核执行, 之后比对所有的通用寄存器和csr寄存器的值，如果完全相同则认为设计核执行正确。\n在trace比对中, 有些转移指令和store指令不写寄存器, 此时如果发生错误并不会立即停止仿真，而是等到下一条写寄存器的指令才会发现错误。 而在difftest中则不会有这个问题，一旦store指令中的物理地址和存储数据与参考核不同，也会立即暂停仿真，以此来尽早定位错误。\n具体使用可参考\n","date":"2024-11-28T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/","title":"功能测试"},{"content":"关于课程计划 由于临近期末（一月初考试），同时我们（助教）最近在编写操作系统（可以看到我又换回了 Arch Linux 进行工作）上占用大量时间，所以我们决定尽快结束课程。预计下一周是最后一周课程。计划下周讲解协程及 Async/Await 等内容。原计划第 13 周讲解的 Dynamic Dispatch 被取消。因为大家对 OOP 的理解不够深入，而且 Rust 的 OOP 与传统 OOP 有很大不同，所以我们决定取消这一部分内容。\n同时，Dynamic Dispatch 也不是原计划的内容，原计划的内容仍然会在下周讲解完毕。\n关于作业 从本周开始，不再布置作业。仅有最后一份期末作业，涉及到本学期所有的内容以及编写操作系统所需要的所有基本知识。Rustlings 和期末作业的参考答案我已经完成，下周一并发布。期末作业大家自行完成即可，不需要提交。有疑问还是请及时联系助教。\nhttps://github.com/Loongson-neuq/2024-neuq-os-2024-neuq-final-assignment-1\n目前这份作业中涉及的内容只有以下部分还没有讲解：\n系统调用 锁/原子操作 协程 Async/Await 前三个部分会在这节课讲解完毕，协程和 Async/Await 会在下周讲解。\n后面的路怎么走？ 有很多同学很迷茫，总是问我学完了能会什么，或者学完了就能编写操作系统了吗？\n我可以负责任地告诉大家，大部分同学仍然离操作系统编写很远。但是知识是日积月累而不是一蹴而就的。你要清楚一个事实，操作系统是一个非常庞大的系统，涉及到的知识非常多，而且很多知识都是非常深入的。你花的几个月的间断的学习，凭什么能超过别人数年甚至数十年的积累？更别说别人经验比你丰富，基础比你扎实，会的知识面比你广泛。\n再问自己一些问题：\n你有丰富的软件工程经验吗？ 你能写出高质量的代码吗？高质量意味者代码可读性好，可维护性好，性能好，安全性好。你能写出这样的代码吗？ 你有大型项目的经验吗？你最多的一个项目写过几万行代码？你有没有一个人参与过一个项目的设计，开发，测试，部署，维护的全过程？ 你有多少编程语言的经验？你有多少编程范式的经验？你有多少编程工具的经验？ 这些只是编程的基础，编写操作系统，要求你的编程基础非常扎实，更需要的是对操作系统原理的深入理解，对硬件的深入理解，对软硬件协同的深入理解。操作系统是软件与硬件高度耦合的产物。你既要对软件有深入理解，又要对硬件有深入理解。你要知道你的代码是如何在硬件上运行的，你的代码是如何与硬件交互的。\n对软件的深入理解意味着你要对编程语言有深入理解，你看着高级语言的代码，就能知道它是如何在底层运行的。会执行哪些指令，会访问哪些内存，会调用哪些系统调用。\n对硬件的深入理解意味着你要对计算机组成原理有深入理解，你要知道计算机是如何工作的，CPU 是如何工作的，内存是如何工作的，外设是如何工作的。对软硬件协同的深入理解意味着你要知道操作系统是如何管理硬件的，是如何与硬件交互的，是如何保证软硬件的正确协同工作的。\n那是不是就搞不出来了呢？当然不是。你需要慢慢积累，慢慢学习。并且我同样可以负责任地告诉你，学习操作系统是提升底层编程能力的最快途径。只是需要一定知识基础的。\n**关于 rcore 实验，如果你已经明显感觉到自己难以理解某些操作系统的概念，我的建议是立即停止。以提升软件工程能力为主，等你有了一定的软件工程能力，再回过头来学习操作系统，会事半功倍。**否则目前的学习只会让你感到困惑，所谓的学习也只是抄代码，能学到的东西非常有限。\n最早的计划是要包含对软件工程的训练的，要求大家独立完成一个大型项目，同时包含设计模式的训练和课程，考虑到大家还是比较急于学习操作系统，所以这部分内容被取消了，只保留了编写操作系统需要的主线知识。\n上次作业 上次的作业的完成的情况我就不多说了，大家自己清楚，也没有人来问问题。我只能认为大家可能还有些困难，那这节课我来带着大家完成，顺便讲解一下如何手动使用系统调用。\n简答题 关于简答题，大部分都是上次课件里的内容，直接参考课件即可。这里我只讲解一下一些补充内容。\n手动使用 brk 系统调用 题目：\u0026ldquo;尝试使用 brk 或 sbrk 分配 1024 字节，并尝试访问第 1024 ~ 4095 字节的内存，说明为什么可以访问这些内存？\u0026rdquo;\n这里以 brk 系统调用为例，讲解一下系统调用是什么，如何使用系统调用。\n系统调用 系统调用是操作系统提供给用户程序的接口，用户程序通过系统调用可以请求操作系统提供服务。系统调用是用户态程序与内核态程序之间的桥梁。用户态程序通过系统调用请求内核态程序执行某些操作，比如读写文件，分配内存等。\n看着比较抽象？实际上，就跟你调用外部库的一个函数一样。只不过这个函数是操作系统提供的，你需要通过一些特殊的方式调用。\n下面我们从另一个角度，来看看系统调用到底是怎么特殊的。\n系统调用是操作系统的一种异常。而异常和中断在操作系统中都属于Trap。Trap 是一种异步事件，它会打断 CPU 的正常执行流程，转而执行操作系统内核中的一段代码。这段代码就是系统调用的实现。\n本质上来说，当Trap发生的一瞬间，会发生一下改变：\nCPU特权级被提升，从用户态提升到内核态 x86 中是从 ring3 提升到 ring0。RISC-V 中是从 U 模式提升到 S 模式。 PC 指针被修改，指向内核态的代码。PC 指针是 CPU 核心当前/或下一条执行指令的地址，操作它就是操作 CPU 的执行流程。 这两者是同时且瞬间发生的，从发生异常的指令到内核态代码执行，这个过程是没有空隙的，是瞬间完成的。\n当Trap发生后，也就是 PC 来到了操作系统的代码，操作系统会首先保存用户态的寄存器状态，然后根据 Trap 的类型，执行相应的操作。\n如果是系统调用，操作系统会根据用户传递的参数，执行相应的操作，然后将结果返回给用户程序。这个过程是一个系统调用的过程。例如 brk 就是给用户程序分配内存的系统调用，exit 是退出程序的系统调用。\n系统调用由特殊汇编指令触发，在 x86 中是 syscall 指令，在 RISC-V 中是 ecall 指令。在进入操作系统 Trap 后，操作系统可以读取 CPU 特权寄存器，判断 Trap 到底是 Exception 还是 Interrupt。Exception 是 Syscall，还是其他异常。根据这些信息，操作系统可以执行相应的操作。\n如果是其他不可恢复的异常，比如除零异常，操作系统会直接终止用户程序的执行（由于信号机制的出现，操作系统现在通常不会直接杀死进程），然后将控制权交给其他程序。操作系统也会利用异常来实现一些功能，比如页错误异常，就是操作系统用来实现虚拟内存和COW的一种方式。\n而中断是一种异步事件，分为硬中断和软中断。外部中断是由硬件设备发出的，比如键盘中断（仅针对PS接口，USB接口是轮询机制），网卡中断等，目的是让 CPU 处理硬件设备的事件。时钟中断是由CPU时钟发出的，目的是让 操作系统从用户程序中夺回控制权，进行调度。如果没有时钟中断，CPU 就会一直执行用户程序，操作系统就无法进行调度。假如我在这里写一个死循环，那么其他进程就无法被执行，因为同一时刻一个CPU的PC只能指向一个地址。同时操作系统的代码也永远无法执行，也就意味着操作系统无法杀死这个进程。\n因此，异常是操作系统与用户程序交互的方式，中断是操作系统夺回 CPU 控制权的方式。\n下面来看看我们如何触发一个系统调用。\n在 x86 中，我们可以使用 syscall 指令来触发系统调用。使用系统调用，我们需要做以下几件事：\n在指定寄存器中存放系统调用号，这个号码是操作系统用来查找系统调用的实现。因为所有系统调用都是通过syscall指令触发的，所以操作系统需要根据这个号码来查找对应的系统调用实现。 在指定寄存器中存放系统调用的参数，这些参数是用户程序传递给操作系统的，操作系统根据这些参数来执行相应的操作。 参数必须是寄存器宽度的，因为我们只能通过寄存器传递参数。在 x86 中，系统调用的参数是通过 rax, rdi, rsi, rdx, r10, r8, r9 这几个寄存器传递的。rax 寄存器存放系统调用号，rdi, rsi, rdx, r10, r8, r9 分别存放系统调用的参数。在 RISC-V 中，系统调用的参数是通过 a0, a1, a2, a3, a4, a5 这几个寄存器传递的。 a7 寄存器存放系统调用号。上面的期末作业中给出了一些系统调用的号码，这些号码是操作系统用来查找系统调用实现的。\n这里给出一个 x86_64 的 syscall 表，包含系统调用的寄存器使用约定: https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/\n可以看到，系统调用的返回值是存放在 rax 寄存器中的。系统调用 id 也被放在 rax 寄存器中。然后我们还需要在 rdi 中放置第一个参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 #![no_std] #![no_main] use core::arch::asm; use core::panic::PanicInfo; #[allow(unused)] #[allow(unused_mut)] #[allow(unreachable_code)] #[no_mangle] pub extern \u0026#34;C\u0026#34; fn main() { let brk_start: usize; unsafe { // brk 是指向用户堆的指针。我们使用brk是扩大堆的大小，也就是分配内存。 // 但是我们需要知道堆的起始位置，所以我们需要先获取当前的brk值。 asm!( \u0026#34;mov rax, 12\u0026#34;, // sys_brk system call number on x86_64 \u0026#34;mov rdi, 0\u0026#34;, // brk(0) to get the current brk value \u0026#34;syscall\u0026#34;, out(\u0026#34;rax\u0026#34;) brk_start, options(nostack) ); let mut new_brk: usize = brk_start + 1024; // 分配 1024 字节内存 let brk_ret: isize; // 系统调用返回值 // 调用 brk 系统调用进行内存分配 asm!( \u0026#34;mov rax, 12\u0026#34;, // sys_brk system call number on x86_64 \u0026#34;syscall\u0026#34;, in(\u0026#34;rdi\u0026#34;) new_brk, out(\u0026#34;rax\u0026#34;) brk_ret, options(nostack) ); if brk_ret == -1 { new_brk = brk_start; // 分配失败，恢复原来的 brk panic!(\u0026#34;brk failed\u0026#34;); } let mut ptr = brk_start as *mut u8; ptr.write_volatile(42); // 访问 brk 的第一个字节 print(\u0026#34;brk success\\n\u0026#34;); for i in 0..4099 { unsafe { ptr.add(i).write_volatile(42); // 访问超出分配的内存 // 你应该一定会看到4096行的write success。一行不多，一行不少。 print(\u0026#34;write success\\n\u0026#34;); } } } } #[no_mangle] pub extern \u0026#34;C\u0026#34; fn __libc_start_main() -\u0026gt; ! { main(); print(\u0026#34;main returned\\n\u0026#34;); exit(0); } pub fn print(s: \u0026amp;str) { let ptr = s.as_ptr(); let count = s.len(); unsafe { asm!(\u0026#34;syscall\u0026#34;, in(\u0026#34;rax\u0026#34;) 1, // sys_write system call number on x86_64 in(\u0026#34;rdi\u0026#34;) 1, // file descriptor 1 is stdout in(\u0026#34;rsi\u0026#34;) ptr, // pointer to the buffer in(\u0026#34;rdx\u0026#34;) count, // buffer size ) } } fn exit(code: i32) -\u0026gt; ! { unsafe { // 退出程序 asm!(\u0026#34;syscall\u0026#34;, in(\u0026#34;rax\u0026#34;) 60, // sys_exit system call number on x86_64 in(\u0026#34;rdi\u0026#34;) code, // exit code; options(noreturn, nostack) ) } } #[panic_handler] fn panic(_info: \u0026amp;PanicInfo) -\u0026gt; ! { print(\u0026#34;panicked!\\n\u0026#34;); exit(1); } 你可以在这里找到这个代码的完整版本。\n使用\n1 cargo +nightly run -Z build-std=core --target x86_64-unknown-linux-gnu 来编译运行\n你可以看到，刚好在第 4096 行的时候，程序会被操作系统杀死。这是因为我们访问了超出分配的内存，操作系统检测到了这个错误，就会杀死程序。\n但是我们明明只要了 1024 个字节，为什么我们可以访问 4096 字节呢？这是因为操作系统会按照页的大小来分配内存。在 x86_64 上，页的大小是 4096 字节。所以我们分配 1024 字节的时候，实际上操作系统会分配 4096 字节的内存。这个内存是连续的，所以我们可以访问 1024 ~ 4095 字节的内存。按页分配内存是为了提高内存的使用效率，因为内存是按页来管理的，所以我们只能按页来分配内存。分页机制同时也是虚拟内存和内存权限控制的基础。\n上面你可以看到我使用汇编调用exit, write系统调用的实现，这是因为我们在 no_std 环境下，没有标准库，所以我们需要自己实现这些功能。这里我使用了汇编来调用系统调用。\n探索调用栈 - 手动栈展开 接下来看下一道题：https://github.com/Loongson-neuq/mem-management-01/tree/main/explore-call-stack\n题目要求我们通过修改栈，来实现修改控制流。\n让我们先来看看这个题的简化版本，也是一个经典的返回地址攻击：\n1 2 3 4 5 6 7 8 9 10 11 int main() { foo(); } int foo() { // 在这里修改栈，使得代码不回到 main，而是回到 bar } int bar() { // Some dangerous code that can be exploited } 这需要如何实现呢？我们首先需要知道函数是什么。\n函数也叫子过程，是一段代码的集合，从汇编或者说内存的角度说，就是一片内存区域，这片内存区域储存了指令。函数实际上就只是这片内存区域的地址，或者说这些指令集合的第一条指令的地址。而其他的参数，返回值都是编译器设计的约定，实际上就是一些寄存器或者内存的操作。如果我们自己编写汇编代码，则需要自己实现以及遵守这些约定。\n函数的特性包括以下几点:\n传递参数给子过程 转移控制权给子过程 子过程返回返回值 子过程返回控制权给父过程 我们今天不关注 1 和 3，有兴趣的同学请自己搜索 Calling Conventions。\n2 和 4 都涉及控制权的转移，通过上面的内容，你应该知道，实际上就是修改 PC 指针。\n对于 2，通常由一条 \u0026ldquo;call\u0026rdquo; 指令实现，call 指令是一条比较复杂的伪指令，实际上是多条指令的组合。\n让我先介绍一个简单跳转指令 jmp。它的作用就只是修改PC到目标地址，没有任何其他操作。\n接下来再说说 call 指令。call 指令的作用是将当前的指令的下一条指令的地址压入栈，然后跳转到目标地址。\n也就是\n1 2 push \u0026lt;ADDRESS_OF_NEXT_INSTRUCTION\u0026gt; \u0026#39; 需要注意的是\u0026lt;ADDRESS_OF_NEXT_INSTRUCTION\u0026gt;由编译器硬编码嵌入到指令中，所以我们无法直接获取到这个地址 jmp \u0026lt;TARGET_ADDRESS\u0026gt; 这样就实现了函数调用。\n那返回时呢？返回时我们需要从栈中弹出地址，然后跳转到这个地址。\n1 2 pop t0 \u0026#39; 将\u0026lt;ADDRESS_OF_NEXT_INSTRUCTION\u0026gt;弹出到t0 jmp t0 \u0026#39; 跳转到t0 这就是 ret 指令。ADDRESS_OF_NEXT_INSTRUCTION 被称为 Return Address。某些架构例如 RISCV 使用专用寄存器保存 Return Address，但是对于嵌套函数，仍然需要将 Return Address 压入栈中。\n在 ret 前，需要清空当前栈帧，这样pop弹出的才是正确的地址。而不是局部变量。\n这就是函数调用的原理。\n接下来再让我们从高处看看栈的结构，以上面的代码为例：\n1 2 3 4 5 6 7 +-------------------+ --+ \u0026lt;- rbp | | | | | | | | +--- main 的栈帧 | | | | | | +-------------------+ --+ \u0026lt;- rsp 这是 main 的栈帧，在进入 main 时，就确定了大小和位置。在调用 foo 前，栈的结构是这样的。\n接下来我们执行 call foo 指令的第一件事，压入 Return Address，栈的结构变成这样：\n1 2 3 4 5 6 7 8 9 +-------------------+ --+ \u0026lt;- rbp, BASE POINTER，也就是序幕代码中的 rsp 或者 riscv 中的 sp | | | | | | | | +--- main 的栈帧 | | | | | | +-------------------+ --+ \u0026lt;- rsp | RETURN ADDRESS | +-------------------+ 接下来我们执行 jmp foo 指令，控制权转移到 foo 函数。但是还没有执行 foo 函数的代码，所以 foo 的栈帧还没有建立，栈的结构保持不变。\n我们知道，函数具有 prelude 代码，包含以下两条指令：\n1 2 push rbp mov rbp, rsp 这是为了建立当前函数的栈帧。其中，push 将 rsp 指令 +8，然后将 rbp 的值压入栈中。然后将 rsp 的值赋给 rbp。这样就建立了当前函数的栈帧。现在栈的结构变成这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 +-------------------+ --+ | | | | | | | | +--- main 的栈帧 | | | | | | +-------------------+ --+ | RETURN ADDRESS | +-------------------+ | SAVED RBP | +-------------------+ \u0026lt;- 新的 rbp, 这里我们不关注 rsp，因为 rsp 是动态的 | | | | \u0026lt;--- foo 的栈帧 | | | | 你可以看到，foo 的栈帧建立完成。现在我们可以执行 foo 的代码了。\n现在回来考虑返回地址攻击，其实非常简单，只要修改 Return Address 就可以了。我们可以通过修改 Return Address 来控制程序的控制流。那如何知道 Return Address 的地址呢？事实上，对于本函数的 Return Address，我们是很容易知道的，它就位于 SAVED RBP 的正上方。而 SAVED RBP 的地址是 rbp 的值。\n也就是说，RETURN ADDRESS 的地址就是 rbp + 8。\n我们使用((size_t*)(rbp + 8)) = bar，就能够修改 Return Address 为 bar 的地址。\n这下，在 foo 返回时，pop 出来的地址就是 bar 的地址，程序就会跳转到 bar 函数。\n这就是返回地址攻击的原理。\n现在让我们回来看我们的题目。我们的题目稍微复杂了一些，因为我们不再是修改自己的返回地址了，而是修改自己上方某个函数的返回地址。这就需要我们知道上方函数的栈帧的大小，以及 Return Address 的地址。那我们如何知道上方函数的栈帧的大小呢？我们可以遍历基指针实现。\n还是考虑这个例子，我们知道，main 也是被别人调用的，也有 RETURN ADDRESS 和 SAVED RBP。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 +-------------------+ --+ | | | | | | | | +--- main 的栈帧 | | | | | | +-------------------+ --+ | RETURN ADDRESS | +-------------------+ | SAVED RBP | +-------------------+ \u0026lt;- 新的 rbp, 这里我们不关注 rsp，因为 rsp 是动态的 | | | | \u0026lt;--- foo 的栈帧 | | | | rbp 寄存器指向的是当前函数的栈帧的底部，也就是 SAVED RBP 的地址。那我们对 rbp 进行解引用，就可以得到上一个函数的 rbp 的地址。再次解引用，就可以得到上上一个函数的 RBP。如此循环下去，直到某一个 SAVED RBP 为 0，就说明到了栈的底部。这就是栈的展开的原理。\n这就是我们的题目的原理。我们需要遍历栈，找到我们要修改的函数的栈帧，然后修改 Return Address。\n需要补充的一点是，现代编译器并不总是会保存 RBP，因此这种遍历栈的方法并不总是有效。他们使用 fda 来保存栈帧的大小，这样就不需要 RBP 了。这样就能够多出一个通用寄存器。在 RISCV 中，基指针 fp 有两个名字，在保存基指针时，叫做 fp，如果不保存基指针，叫做 s0，即 saved register 0。多一个通用寄存器的好处是显著的，因为通用寄存器是非常宝贵的资源。但是进行栈展开就变得困难了，因为解析 fda 是非常困难的。但是你可以对指示链接器强制保存基指针。\n汇编视角的栈内存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 foo: ; 函数序幕 PUSH BP ; 保存基指针 MOV BP, SP ; 初始化基指针 PUSH t0 PUSH t1 PUSH t2 PUSH t3 PUSH t4 ; int a = 42; MOV t0, 42 ; 将值 42 存入 t0 寄存器 PUSH t0 ; 将 t0 的值压入栈，栈顶即为变量 a 的地址 ; int* ptrA = \u0026amp;a; LEA t1, [BP-8] ; 获取变量 a 的地址，存入 t1 PUSH t1 ; 将 t1 的值压入栈，栈顶即为变量 ptrA 的地址 ; Object* obj = new Object(); HEAP_ALLOC t3, 32 ; 分配 32 字节的堆空间，存入 t3 MOV [t3], \u0026lt;Program.exe+Object::GetHashCode\u0026gt; ; 初始化 vtable 的第一个函数地址 MOV [t3+8], \u0026lt;Program.exe+Object::ToString\u0026gt; ; 初始化 vtable 的第二个函数地址 MOV [t3+16], \u0026lt;Program.exe+Object::Equals\u0026gt; ; 初始化 vtable 的第三个函数地址 PUSH t3 ; 将堆地址压入栈，栈顶即为变量 obj 的地址 ; char* str = \u0026#34;Hello\u0026#34;; MOV_STR t0, \u0026lt;Program.exe+offset_of_Hello\u0026gt; ; 假设字符串 \u0026#34;Hello\u0026#34; 的偏移地址 PUSH t0 ; 将 t0 的值压入栈，栈顶即为变量 str 的地址 ; StructType value = StructType {1, 2, 3}; MOV t0, 1 ; 将值 1 存入 t0 寄存器 PUSH t0 ; 将 t0 的值压入栈，初始化 field1 MOV t0, 2 ; 将值 2 存入 t0 寄存器 PUSH t0 ; 将 t0 的值压入栈，初始化 field2 MOV t0, 3 ; 将值 3 存入 t0 寄存器 PUSH t0 ; 将 t0 的值压入栈，初始化 field3 ; 你也可以使用静态SP的方式 ; SUB SP, 12 ; 为结构体 value 分配 12 字节的栈空间 ; MOV [SP-4], 1 ; MOV [SP-8], 2 ; MOV [SP-12], 3 ; StructType* pValue = (StructType*)malloc(sizeof(StructType)); HEAP_ALLOC t3, 12 ; 分配 12 字节的堆空间，存入 t3 MOV [t3], 1 ; 初始化堆上的 field1 MOV [t3+4], 2 ; 初始化堆上的 field2 MOV [t3+8], 3 ; 初始化堆上的 field3 PUSH t3 ; 将堆地址压入栈，栈顶即为变量 pValue 的地址 ; std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3}; PUSH 3 ; 将 3 压入栈，初始化 vector 的大小 PUSH 3 ; 将 3 压入栈，初始化 vector 的容量 HEAP_ALLOC t3, 12 ; 分配 12 字节的堆空间，存入 t3 MOV [t3], 1 ; 初始化堆上的第一个元素 MOV [t3+4], 2 ; 初始化堆上的第二个元素 MOV [t3+8], 3 ; 初始化堆上的第三个元素 PUSH t3 ; 将堆地址压入栈，栈顶即为变量 vec 的地址 ; std::vector\u0026lt;int\u0026gt;* pVec = new std::vector\u0026lt;int\u0026gt;({1, 2, 3}); HEAP_ALLOC t3, 12 ; 分配 12 字节的堆空间，存入 t3 MOV [t3], 1 ; 初始化堆上的第一个元素 MOV [t3+4], 2 ; 初始化堆上的第二个元素 MOV [t3+8], 3 ; 初始化堆上的第三个元素 HEAP_ALLOC t4, 24 ; 分配 24 字节的堆空间，存入 t4 MOV [t4], 3 ; 初始化堆上的大小 MOV [t4+4], 3 ; 初始化堆上的容量 MOV [t4+8], t3 ; 初始化堆上的指针 PUSH t4 ; 将堆地址压入栈，栈顶即为变量 pVec 的地址 ; int array[512]; SUB SP, 2048 ; 为数组 array 分配 512 * 4 字节的栈空间 LEA t2, [BP-2056] ; 获取数组 array 的基址，存入 t2 ; 我决定将这个数组放在最后，因为这样其他局部变量的偏移就会比较小 ; 清理局部变量 ADD SP, 2048 ; 清理数组 array 的栈空间 POP ; 清理 pVec ADD SP, 12 ; 清理 vec ADD SP, 8 ; 清理 pValue ADD SP, 12 ; 清理 value ADD SP, 8 ; 清理 str ADD SP, 8 ; 清理 obj ADD SP, 8 ; 清理 ptrA ADD SP, 4 ; 清理 a ; 恢复临时寄存器 POP t4 POP t3 POP t2 POP t1 POP t0 ; 函数尾声 POP BP ; 恢复基指针 RET 这里我使用的是动态 sp，某些编译器不会使用动态 sp，而是使用 rbp + 固定偏移，也就是课件中代码的形式。 使用哪种方式完全取决于编译器的实现，这里只是为了说明栈内存的分配。并且现代编译器也是多种方式混合使用，例如保存 rbp 的时候都是使用的 push/pop，但是局部变量的偏移是使用 rbp + 固定偏移的方式。\n补充：寻址模式 我们进行内存访问，总是需要一个根，然后再加上一个偏移量。这个根叫做基址，这种寻址方式叫做基址寻址。基址寻址是一种非常常见的寻址方式，但是并不是唯一的寻址方式。\n我们还有一种寻址方式叫做立即数寻址，这种寻址方式是直接使用一个立即数作为地址。这种寻址方式通常用于访问全局变量，因为全局变量的地址是固定的。\n这里稍微说一下基址寻址。除了全局符号外，所有的寻址都是基址寻址。对于堆内存，它的根总是栈上的某个局部变量，这也是 Gargage Collection 的基础，对于引用托管堆对象的局部变量被视为 GC 根，通过遍历 GC 根，可以确定所有可达的托管对象。然后其他被判定为不可达的对象就可以被回收。\n而对于栈内存，它的根是栈顶指针，也就是 rsp 或者 rbp。因此，不管是堆内存还是栈内存，通过寄存器来访问内存，无非是一次跳转和多次跳转的区别。\n继续 Rust 所有权原理的内容 回到上次的课件\n","date":"2024-11-24T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/os-week6-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-2-rust-%E6%89%80%E6%9C%89%E6%9D%83/","title":"[OS Week6] 内存管理 2 \u0026 Rust 所有权"},{"content":"本次课程的部分内容摘抄自 Microsoft Learn 上的 Get started with Rust 课程。\nOverview Rust 是一种系统编程语言，因此可用于编写系统（如操作系统）。 但它也可用于编写性能和可信度很重要的应用程序。 Rust 语言语法可以与 C++ 语法相媲美，提供了与新式 C++ 相当的性能；\n❕INFO\nC++是什么垃圾也配\n对于许多有经验的开发人员来说，Rust 在编译和运行时模型、类型系统和确定性终止化方面都是正确的。\n❕INFO\n在系统编程中，控制流可能被扰乱，某些优化并不完全正确，需要开发者具有丰富的经验对生成的汇编代码进行审查。不能完全依赖编译器。\n此外，Rust 的设计保证了内存安全，而不需要进行垃圾回收。\n那么，我们为什么要选择 Rust 作为 Windows 的最新语言投影呢？ 其中一个因素是，Stack Overflow 的年度开发人员调查显示，Rust 是目前为止年复一年最受欢迎的编程语言。 虽然你可能会发现此语言有陡峭的学习曲线，但一旦你越过了这个峰，就很难不爱上它了。\nRust development toolset/ecosystem crate 是 Rust 编译和链接单元。 crate 可以源代码形式存在，然后能够被处理成以二进制可执行文件（简称二进制文件）或二进制库（简称库）形式存在的 crate 。通常一个 crate 就是一个 project。\nRust 项目称为包。 一个包可以包含一个或多个 crate，以及描述如何生成这些 crate 的 Cargo.toml 文件。更准确的说法是 solution。\nrustup 是 Rust 工具链的安装程序和更新程序。\nCargo 是 Rust 包管理工具的名称。也用于构建、测试和发布 Rust 项目。\nrustc 是 Rust 编译器。 大多数情况下，你不会直接调用 rustc，而是通过 Cargo 间接调用它。\ncrates.io (https://crates.io/) 是 Rust 社区的 crate 注册表。crates.io 托管大量的 crate，可以通过 Cargo 下载，并自动解决依赖关系。\nProgramming language Concepts Type syetem Strong typing? Weak typing? 在编程语言的类型系统中，强类型（strong typing）和弱类型（weak typing）是两个核心概念，用于描述编程语言对数据类型的约束程度。\n强类型（Strong Typing） 强类型语言要求变量的数据类型在使用时要严格遵守，通常不允许不同类型之间的隐式转换。例如，Rust、.NET都属于强类型语言。以下是强类型的特征：\n严格的类型检查：强类型语言在编译期或运行期都会进行严格的类型检查，如果类型不匹配，代码就会报错。例如，在Rust中将整数赋值给一个字符串类型的变量会直接报错，而不会自动转换类型。\n安全性：强类型语言通常可以防止许多潜在的错误，因为它们在操作不兼容类型时会立即报错，帮助程序员更早地发现错误。例如在Rust中，试图将整型变量作为浮点型来处理，编译器会立即提醒，这避免了许多运行时错误。\n类型转换需要显式：在强类型语言中，类型转换一般需要显式声明，编译器不会进行隐式转换。例如在Rust中，let x: i32 = 10; let y: f64 = x as f64;。as关键字显式地将i32类型转换成了f64。\n⚠️ NOTE\nRust 仅在安全的情况下允许隐式转换，例如let x: i32 = 10; let y: f64 = x;是合法的，因为i32可以隐式转换成f64。并且 Rust 还有自动解引用机制，实现了一定程度的隐式转换。\n内存安全：强类型语言更容易实现内存安全，因为严格的类型系统有助于防止无效的内存访问。例如，Rust的所有权系统和借用检查在类型系统中嵌入了内存管理的概念，确保了线程安全和内存安全。 弱类型（Weak Typing） 弱类型语言对类型的限制较少，通常允许不同类型之间的隐式转换，例如JavaScript具有弱类型的特性。以下是弱类型的特征：\n更宽松的类型转换：弱类型语言在不同类型之间可以自由转换。例如在JavaScript中，\u0026quot;5\u0026quot; + 10 会自动将数字10转换成字符串，然后得到字符串\u0026quot;510\u0026quot;。这种隐式转换提供了便利，但也可能导致难以发现的错误。\n更高的灵活性：弱类型允许开发者快速编写代码，减少了类型检查的约束，代码在运行时的适应性更高。例如，JavaScript中的函数可以接受任何类型的参数，不必进行严格的类型定义。\n容易出错：由于类型不严格，弱类型语言更容易引发错误，尤其是在无意中发生隐式类型转换时。比如在C语言中，整数和指针之间可以自由转换，这会导致很多内存和安全问题。\nRust 的强类型优势 Rust 是一种强类型系统的语言，其设计注重内存安全和性能，通过严格的类型检查和所有权模型来保证代码的可靠性。Rust 的强类型特性让开发者在编译时可以捕捉到许多潜在的错误，减少了运行时的崩溃风险，同时通过显式转换机制避免了隐式转换带来的隐患。\n最后，类型是仅对于高级语言抽象层的概念，在底层的硬件层，一切都是二进制的。所有的类型实例不过是一段 memory block，在汇编中我们使用同样的指令来操作所有的类型。因此，在 C 这种仅对汇编进行薄封装的语言中，类型的概念并不是很重要。\nSystems programming language “系统编程语言”通常指的是适合底层开发、硬件交互和性能优化的语言，与更高层抽象的应用编程语言相比，它们有一些独特的特点：\n直接硬件访问和内存控制(Most important to us)： 系统编程语言通常支持对硬件和内存进行低层次的访问，例如手动管理内存（Rust、C/C++的malloc/free或new/delete）。这让开发者能精确控制程序的内存分配和释放，提高性能和资源利用率。\n高效的执行性能： 系统编程语言（如Rust、C、C++）通常会编译成原生机器码（针对特定架构及操作系统的汇编指令），以确保代码在执行时的效率和速度。这在操作系统、嵌入式系统等需要实时响应和高效性能的场景中尤为重要。\n⚠️ NOTE\n不完全正确，事实上，JIT 和 GC 的组合更能够在保证极端性能的完全释放和最大延迟。只是 JIT 依赖运行时，并且 GC 不能保证确定性时延。这些缺陷在系统编程中是不可接受的。因为运行时依赖操作系统。而 GC 导致的不确定性时延会导致系统的不可预测性。\n细粒度的并发控制： 系统编程语言支持低级并发控制（如Rust中的无锁数据结构、C++的线程库和原子操作）。Rust特别强调安全的并发，通过借用检查器和所有权系统来避免数据竞争，帮助在保持并发性能的同时防止线程安全问题。\n内存安全： 像Rust这样的现代系统编程语言注重内存安全，避免空指针和悬空指针等问题。Rust的所有权系统在编译期防止了数据竞争、悬挂引用和双重释放等内存问题，大幅降低了由于内存管理引发的漏洞风险。\n零成本抽象： 系统编程语言（特别是Rust和C++）支持高效的抽象机制，允许编写高性能、模块化的代码。\n系统编程语言的这些特点使它们适合于操作系统、驱动程序、嵌入式系统、数据库引擎和游戏引擎等对性能和硬件直接交互有严格要求的场景。相比之下，高层次的编程语言（如Python、JavaScript）更适合于快速开发和构建应用程序接口（API）、数据处理或前端交互，因为它们提供了更丰富的标准库、内置内存管理和更高的抽象能力，但牺牲了一部分性能和对系统的直接控制。\nWhy Rust? 我们要编写的是操作系统内核，不是一般的用户程序！\n内存安全性：Rust独特的所有权系统和借用检查机制在编译阶段保证了内存安全，避免了常见的内存错误，如空指针引用、悬空指针和数据竞争问题。这对于编写操作系统内核尤为重要，因为内核中的错误通常会导致系统崩溃。Rust的安全检查帮助新手在不依赖垃圾回收的情况下实现更高的内存安全性，从而在早期阶段减少调试和崩溃问题。\n现代化语法，开发者友好：Rust的语法较为现代化且接近高级语言，易于理解。相比传统的系统编程语言（如C/C++），Rust能让新手更快上手，写出结构化、可读性高的代码，从而减少理解操作系统开发的语言门槛，使其更专注于系统逻辑和底层实现。\n高效的错误信息和强类型系统：Rust的编译器提供详细的错误提示，帮助开发者快速定位和解决问题。Rust的强类型系统在编译时检查代码中的潜在错误，特别是在内核开发中，这种类型检查可以大大减少运行时的错误和潜在的安全漏洞。\n低层次控制和高性能：Rust与C一样可以访问底层硬件和控制内存布局，但同时还能提供更高的性能和资源控制能力。这使得新手能够更灵活地操作RISC-V平台的硬件资源，同时获得接近C的性能，这是编写高效操作系统内核的重要特性。\n丰富的生态和社区支持：Rust社区对操作系统开发的支持日渐丰富，包括riscv crate等对RISC-V架构的支持库、core和alloc等标准库，以及x86_64和riscv等架构支持工具。社区中有许多成熟的项目和开源代码可供参考，新手可以借鉴这些资源加速学习。\n无运行时、轻量编译选项：Rust允许在no_std环境中开发，即不依赖标准库，从而更适合裸机（bare metal）开发。对于RISC-V平台操作系统内核，Rust可以使用#![no_std]配置，这样就能完全剥离标准库，直接进行裸机编程，符合操作系统开发的需求。\n我最看重什么？ 大量第三方库：Rust 社区的生态系统非常丰富，有大量的第三方库可供使用，可以大大提高开发效率。\n项目质量: 不规范换行？不规范缩进？不规范命名？clippy 全部给你报错！代码全部塞一个类一个函数里？测试过不了你就老实了！\nRust is good enough? 我不认为 Rust 够好，事实上它除了内存安全的一点保证之外远远能让我满意。上述的优点 Rust 也并没有做到最好。\nSUCK virtual dispatch: Rust 的多态性主要基于泛型，倾向于静态分派，在编译期生成专用代码来替代泛型参数，因此很少使用动态分派（dyn Trait），这提高了性能，但也限制了动态多态的灵活性。相比之下，.NET 提供了灵活的接口和虚函数机制，适合需要基于对象或接口进行频繁动态分派的场景。\nSUCK async programming: 许多人认为 async/await 是 Rust 的一大优势，但实际上，Rust 的异步编程模型相对简陋。Rust 的异步编程主要基于Future和async/await语法，但缺乏像.NET Core中的Task和async/await那样完善的异步编程框架和库。Rust的异步编程需要依赖第三方库（如tokio、async-std）来实现，而且在使用过程中需要处理更多的错误和异常情况，不如.NET Core的异步编程模型简洁和易用。\nMacro? Garbage!: 我最讨厌的东西！宏分为两种，一种是声明式宏，一种是过程式宏。声明式宏类似 C 里面的宏，通常只用于简单的文本替换，只是添加了一些语法约束。过程宏是用于编译期代码生成的工具，但是 Rust 的过程宏相当简陋，仅支持 syntax analysis，.NET 的增量代码生成器则强大得多，不需要宏就能实现更强大的代码生成功能。\nRust 还有许多缺点，但是我认为不太重要，因此不再叙述。例如饱受诟病的编译速度慢，命名空间管理毫无逻辑等等。当然，Rust 太难不是 Rust 的问题。\n但是在我们的场景下，Rust 是最适合的语言。\nSetup your own Rust development environment Prerequisites Windows 由于 Rust 依赖 C 编译套件用于编译的最终阶段，因此在 Windows 上安装 Rust 时，需要安装 C 编译套件。 Windows 上的 C 运行时主要是 MSVS，因此你需要安装 Microsoft Visual C++。你可以下载 Microsoft C++ Build Tools，也可以（推荐）首选直接安装 Microsoft Visual Studio。安装 Community 版本的 Visual Studio 即可。安装时仅勾选 Desktop development with C++ 选项即可。\nDetailed instructions\nLinux 安装对应平台和与宿主主机相同的架构的 GCC 即可。\nDevelopment environment RustRover? RustRover 是 JetBrains 开发的 Rust 语言的 IDE，它是一个基于 IntelliJ 平台的 IDE，提供了 Rust 语言的代码编辑、调试、自动补全、代码重构等功能。RustRover 也支持 Cargo 包管理工具，可以帮助你更方便地管理 Rust 项目。类似于 Idea, PyCharm, Clion 等。并且 RustRover 社区版是免费的。\n但是！\n不要用！由于我们的最终目的是系统编程，RustRover 是面向用户级应用的 IDE，它的调试器和代码提示等功能对于系统编程并不友好。\n因此我要求大家使用 Cargo 命令行　+　你自己喜欢的文本编辑器（VSCode, Vim, Emacs, Sublime Text, Notepad++）进行开发。\nInstall Rust 不管你用的什么操作系统，打开 https://rustup.rs。\n如果你是 Windows 用户，点击最上面的rustup-init.exe下载并运行。 如果你是 Linux 用户，复制网址下面的命令到终端运行。\n然后根据提示，一路回车即可。\n某些发行版可能会将 rustup 添加至软件源，当然上述方式也可以\nVerify installation 打开终端，输入cargo --version，如果输出了版本号，说明安装成功。\n1 2 PS C:\\Users\\Caiyi Hsu\u0026gt; cargo --version cargo 1.80.0 (376290515 2024-07-16) Rust with Visual Studio Code 确保你已经安装了 Visual Studio Code 和 Cargo。打开 Visual Studio Code，安装 rust-analyzer 插件。\nMore usages:\nRust with Visual Studio Code\nRust basic syntax The Rust Programming Language\nUnofficial Chinese Translation\n强烈建议使用 Brown University 的实验性交互版本，尤其是对所有权和借用感到困惑的同学。\nrust-book.cs.brown.edu\n如果感觉鸟语看着难受可以对照中文翻译看，但一定要以这个这个版本为主要材料。\n下集预告 有重量级内容，敬请期待！\nUnderstanding Rust via Memory management\n做了 Rustlings 的同学可以提前看一下。\n","date":"2024-10-27T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/os-week2-get-started-with-rust/","title":"[OS Week2] Get started with Rust"},{"content":"Prerequisite Memory Management Stack Remember:\nAll variables you defined in a function/method is allocated on the STACK, even non-fixed size types and reference types.\nBut the thing you can access directly or actually stored on the stack must be fixed size types.\n1 2 3 4 5 6 7 8 void foo() { int i = 0; int* p = \u0026amp;i; Object* obj = new Object(); std::string str = \u0026#34;Hello, world\u0026#34;; StructType value = StructType {1, 2, 3}; } All variable you can use directly is allocated on the stack (frame).\nThis is not what I heard from others/the Internet! Reference types String Vector Dynamic allocation (eg. malloc) People all told me that these types are allocated on the HEAP!\nI would say, that\u0026rsquo;s the root of your confusion. Why don\u0026rsquo;t we talk about the Heap first then?\nAnd I used two different term: define and access\nHeap Heap is a large contigous memory managed by both the Operating System and the language runtime.\nRuntime may be the Standard library, eg. the libC or GC, eg. Go, .NET \u0026hellip;\nWe don\u0026rsquo;t have to care about what\u0026rsquo;s happening in the background, at least for now.\nWe only care about two functions:\nOne for alloacting memory 1 void* alloc(size_t size_of_bytes); which is malloc, new, new[] \u0026hellip;\nAnother for returning allocated memory 1 void free(void* ptr); which is free, delete, delete[] \u0026hellip;\nOne interesting thing you should have noticed is, when we returning a piece of memory, we only need to pass the pointer to the function, but not the size of the memory.\nWhy? Because Someone must have recorded the size of the memory when it was allocated.\nThe guy is the Memory Allocator, a part of the runtime.\nWhen you call alloc method, the allocator simply find a piece of memory that is large enough to hold the data you want to store, and then record the size of the memory.\nBut where is the large piece of meory(the allocator uses) from?\nThe answer is the Operating System.\nThe OS provides a system call to allocate a piece of memory, and the allocator will use this system call to get the memory.\nUnix-like system The unix-like system provides a system call brk or sbrk to allocate memory.\nThe system call is like the function below, but is NOT a real function.\n1 2 int brk(void *addr); void *sbrk(intptr_t increment); Additional info: brk syscall\nA note from the page:\n1 2 Avoid using brk() and sbrk(): the malloc(3) memory allocation package is the portable and comfortable way of allocating memory. When you call the brk, the OS will allocate memories Right After the end of the previous memory block. So when you constently call the brk, the memory block will grow larger and larger, but the memory block is always contiguous.\nThe malloc function will use the brk system call to allocate memory, and uses the memory block for the allocation and recording the size of the memory.\nHow do the OS gurantee the memory block is contiguous or the end of the memory block always have enough space for the next allocation?\nThe answer is, the OS atually doesn\u0026rsquo;t gurantee that. Actually, memory pieces that a user program feels contiguous may NOT be contiguous in the physical memory. The OS uses a technique called Virtual Memory and Page Table to make the memory block contiguous in the user program\u0026rsquo;s view.\nThe OS simply maps the virtual memory to the physical memory. This technique is done with the help of hardwares like MMU, a part of the CPU.\nWindows Windows does basically the same thing, but with a different system call, and the system call is wrapped by the VirtualAlloc function form the Kernel32.dll.\n1 2 3 4 5 6 LPVOID VirtualAlloc( [in, optional] LPVOID lpAddress, [in] SIZE_T dwSize, [in] DWORD flAllocationType, [in] DWORD flProtect ); Additional info: VirtualAlloc\nBasically same as the brk system call from the Unix-like system, but with more options.\nContinue to talk about the Heap Think about all code you write about the heap, all allocated object you want to access, you must have a pointer to the object.\nThat\u0026rsquo;s exactly the problem.\nTake a look at the words again:\nAll variables you defined in a function/method is allocated on the STACK, even non-fixed size types and reference types.\nWhat you can access directly is Only the pointer, not the object itself. You MUST uses the pointer to access the object. And the pointer is allocated on the stack.\nNote that reference type is basically safe pointer, the reference is allocated on the stack, and the object is allocated on the heap.\nThere\u0026rsquo;s still one thing we have to talk about:\n1 2 vector\u0026lt;int\u0026gt; vec1; vector\u0026lt;int\u0026gt;* vec2 = new vector\u0026lt;int\u0026gt;(); What\u0026rsquo;s the difference between the two?\nI want to talk about the implementation and underlying of the vector first.\nWhen we talk about the dynamic array, we always have a pointer to the actually array, and the size of the array. So the vector is like this:\n1 2 3 4 5 6 7 // Note that I declared it as a struct, I\u0026#39;ll explain it later struct Vector\u0026lt;T\u0026gt; { T* data; size_t size; size_t capacity; } The first line of the code above actually allocated the three fields on the stack, Pointer to the data, size of the data, and the capacity of the data.\nThe second line of the code above actually allocated the three fields on the heap, Pointer to the data, size of the data, and the capacity of the data. And we uses a pointer to access the object.\nValues Allocated in Rust without Smart Pointer were all like the first line of the code above. Which is, All fields allocated on the stack.\nSmart pointer is like the Vector above(actually vector is a smart pointer), it allocates the fields on the stack, including a pointer to the actual object.\nFixed size? Actually, a class defination determined that class is also fixed size, just like the struct.\nBut class has a special feature: Polymorphism.\nThat\u0026rsquo;s is, when you reference an class object, it may not be the exactly the type, but a derived type. And derived type may have more fields than the base type. Which means the size of the object is not fixed.\nStruct and Class Struct instance were allocated on the stack by default, and class instance were allocated on the heap by default.\nSince the struct is allocated on the stack, we Call it Value Type. Value means we are not accessing it by a pointer, reference or something like that. But directly, we can touch it.\nWhy I declared the Vector as a struct? Simply because C++ allows you allocate a class instance on the stack. And I don\u0026rsquo;t want to make things confusing for people uses other languages.\nalthough this loses the most important feature of the class: polymorphism, which makes a class like a struct.\nWhy All instances allocated on the stack MUST be fixed size? Allocation calls for Value Types were generated at the the compile time, and the size of the object must be known at the compile time.\nAlso, the allocations calls hardcoded the size of the object, which means the size of the object must be fixed.\nSince the class has a special feature: Polymorphism, the size of the object is not fixed, so we can\u0026rsquo;t allocate it on the stack. But without Polymorphism, we can allocate a class instance on the stack, just like C++ does.\nMicro views of the stack I\u0026rsquo;ve talked about where is the heap, but not the stack. Stack is also a contiguous memory block. For simplicity, I\u0026rsquo;ll say that stack were managed by the OS, although it\u0026rsquo;s not true in some cases.\nStack of a program is Program Stack or Call Stack or Execution Stack. It\u0026rsquo;s used to store the local variables, function parameters, and the return address of the function.\nWhen a process starts, the OS will allocate a memory block for the process. And make a certain register point to the end of the memory block(High address). This register is called the Stack Pointer, which is rsp in x86_64 and sp in RISC-V.\nWhen you try allocate an instance on the stack, like, a int, we simply minus the stack pointer.\nYou might know stack is FILO or LIFO, but that doesn\u0026rsquo;t mean we have to pop the stack if we want to access the inner object. The FILO or LIFO is only for the stack frame, which keeps everything essential to allow function calling/returning.\nSince all instance on the stack is fixed size, all of their position is fixed, we know where the object is at the compile time. We know that all local variables can be accessed by frame pointer plus a fixed offset.\nActually, we have to uses address to access all memory blocks, including those allocated on the stack. But we seems never uses a pointer. That\u0026rsquo;s because when we have to uses a pointer, the address can NOT be known at the compile time, we have to fetch the address at runtime. But for those allocated on the stack, the known local variables, we know where they are, we can access them directly with sp + offset, where offset is a constant. So the address(sp + offset) is embedded in the instruction.\nThe stack is array-like, but not a real array. It\u0026rsquo;s a memory block, a memory block means that you can access whatever you want with the memory block. Stack is just a convention which constraints the way we access the memory block - FILO or LIFO.\nAn example is that, in Rust, we don\u0026rsquo;t have a specific data structure for Stack. In C++, in python, in .NET you would have a Type like Stack\u0026lt;T\u0026gt;, but in Rust, we don\u0026rsquo;t have that. We just use Vec\u0026lt;T\u0026gt;(vector\u0026lt;T\u0026gt; in Cpp). As long as you only call push and pop method.\nWhy the stack is faster than the heap? When we access the object on the stack, we know where the object is, we access it with a single instruction which contains the frame pointer and the offset.\nBut when we access the object on the heap, we have to read the pointer to a register, and then access the object with the pointer. That\u0026rsquo;s two instructions.\nAlso, accessing instance on the heap may cause cache miss, which is the REAL reason that heap is slower than the stack.\nMicro views of the stack allocation Having talked about the stack so much, you might wonder when do we push and pop.\nThe name of call stack implied that the stack has strong connection with Fuction Call.\nYou must have seen stack trace when the runtime throw an exception. The stack trace is actually the call stack.\nStack trace when a exception is thrown in .NET:\n1 2 3 4 5 Unhandled exception. System.Exception: Exception from Buz at Program.Buz() in /home/caiyi/loongson-blog/content/post/move-semantic/StackTraceDemo/Program.cs:line 24 at Program.Bar() in /home/caiyi/loongson-blog/content/post/move-semantic/StackTraceDemo/Program.cs:line 17 at Program.Foo() in /home/caiyi/loongson-blog/content/post/move-semantic/StackTraceDemo/Program.cs:line 11 at Program.Main(String[] args) in /home/caiyi/loongson-blog/content/post/move-semantic/StackTraceDemo/Program.cs:line 5 Remove some of the information, we get:\n1 2 3 4 at Program.Buz() in Program.cs:line 24 at Program.Bar() in Program.cs:line 17 at Program.Foo() in Program.cs:line 11 at Program.Main(String[] args) in Program.cs:line 5 Code can be obtained from https://github.com/Loongson-neuq/blog/tree/main/content/post/move-semantic/StackTraceDemo\nWhy do we have so many functions from the Stack trace? Because the functions are called nestedly.\nThe top function is where the exception was actually thrown, and the lower function is where the top function was called. Since the main thread of our program begins with Main() function, the bottom function is always Main().\nWhen a function is called, the runtime will push a new frame to the stack, and when the function returns, the runtime will pop the frame from the stack.\nA frame stores everyting essential to restore the envrionment before the function was the frame call another function.\nWe know that CPU must read datas to its own register to do the calculation, and the register is limited. So we have to store the local variables and other things in somewhere else. That\u0026rsquo;s the stack frame. A frame only stores datas of the function, and the frame is popped when the function returns.\nLet\u0026rsquo;s look at some assembly code Having talked about how the stack so much, you might think it\u0026rsquo;s rather complicated to push and pop the stack. But it\u0026rsquo;s not. As I said before, we only have to minus the stack pointer and the minused size of memory is yours! To return the memory, we only have to add the size to the stack pointer.\nNO NEED TO CLEAR THE MEMORY when we push/pop the stack. CAN YOU THINK ABOUT WHY?\nThe same code as the one at the beginning of the article:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;string\u0026gt; class Object { private: int _value; }; struct StructType { int value1; int value2; int value3; }; void foo() { int i = 0; int* p = \u0026amp;i; Object* obj = new Object(); std::string str = \u0026#34;Hello, world\u0026#34;; StructType value = StructType {1, 2, 3}; } The assembly code of the function foo is like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 section .data str db \u0026#34;Hello, world\u0026#34;, 0 section .text global foo foo: ; 函数开始，保存栈帧 push rbp ; 保存原始栈帧 mov rbp, rsp ; 设置新的栈帧 ; int i = 0; mov dword ptr [rbp-4], 0 ; 将变量 i 初始化为 0，并保存在栈中偏移 -4 ; int* p = \u0026amp;i; lea rax, [rbp-4] ; 取得变量 i 的地址 mov qword ptr [rbp-8], rax ; 将 p 指向 i 的地址并保存偏移 -8 ; Object* obj = new Object(); mov edi, 4 ; Object 的大小为 4 字节 call _Znwm ; 调用 operator new mov qword ptr [rbp-16], rax ; 保存返回的对象地址到 obj 中（偏移 -16） ; std::string str = \u0026#34;Hello, world\u0026#34;; lea rdi, [rel str] ; 将字符串地址加载到 rdi lea rsi, [rbp-32] ; 准备 str 变量的栈位置（偏移 -32） call _ZNSsC1EPKc ; 调用 std::string 构造函数 ; StructType value = StructType {1, 2, 3}; mov dword ptr [rbp-48], 1 ; 将 1 存储到 value.value1（偏移 -48） mov dword ptr [rbp-44], 2 ; 将 2 存储到 value.value2（偏移 -44） mov dword ptr [rbp-40], 3 ; 将 3 存储到 value.value3（偏移 -40） ; 函数结束，恢复栈帧并返回 mov rsp, rbp ; 恢复原始栈指针 pop rbp ; 弹出原始栈帧 ret ; 返回 We even do have to actually DO a allocation operation. We just know that where every variable should be and read/wirte the place directly. See instructions like mov dword ptr [rbp...], ...\nAdditinally, push and pop instructions are also used to store/access the stack, but they are just pseduo instructions. The real instructions are mov and add.\nFrom the assembly code, we can see that how much we push/pop the stack is determined at the compile time, hard coded in the assembly instructions. You should know why all value types must be fixed size now.\nSince we only care about current frame, which is at the top of the stack, we don\u0026rsquo;t need to have store the size of every frame, the base of the whole stack, or the end of the stack. We only need to store the stack pointer, which is the top of the stack, or the base of the current frame.\nThen I\u0026rsquo;ll talk about why do we never clean the stack.\nWhen we pop a frame, the depth of stack just got smaller, and there will be no chance of reading uninitialized data or overwriting the data.\nWhen we push a frame, we always write the data before we can access it. Remember that the Compiler always say Uninitialized variable when you try to access a variable before you write it. The compiler gurantee that you will never read uninitialized data at the compile time, so we don\u0026rsquo;t have to clear the memory, which makes function call faster.\nData inconsistency issue in Multi-threaded scenarios Watch a demo\nor Download and run yourself\nhttps://github.com/Loongson-neuq/blog/tree/main/content/post/move-semantic/MuitlThreadDemo\nNote: You need to have a .NET 8 runtime installed to run the demo. Install it from dot.net\nLock Read-write Lock We don\u0026rsquo;t really have to lock the whole object always. In fact, the lock is to resolve the data inconsistency issue, and the data inconsistency issue is caused by the write operation.\nIf all threads is just reading the data, the data never changes, it\u0026rsquo;s just there. So we can allow multiple threads to read the data at the same time as long as there\u0026rsquo;s no thread is writing the data.\nSo the key is:\nOnly allow one thread to write the data Allow multiple threads to read the data Can\u0026rsquo;t have read lock and write lock at the same time The lock that can resolve the issue is called Read-Write Lock.\nThink about Rust\u0026rsquo;s borrow rule? Did you find the similarity?\nRust WARN: the follow content were generated by ChatGPT\nUnderstanding Rust\u0026rsquo;s Ownership and Borrowing Rules through the Lens of Read-Write Locks and Stack Memory Management Rust’s Single Owner Rule and Single Mutable Reference Rule can be better understood when examined through the principles behind read-write locks and stack-based memory management.\nRust’s Ownership and Borrowing Rules as a Read-Write Lock Analogy In multi-threaded environments, a read-write lock is a synchronization mechanism allowing multiple readers to access a resource simultaneously or granting exclusive access to a single writer. Rust’s ownership and borrowing rules mirror this access control strategy, enforcing exclusive or shared access to data at compile time:\nSingle Owner Rule: Rust’s concept of a single owner aligns with the idea of an exclusive lock on a resource. Only one variable or function can own a piece of data at any point, ensuring exclusive access and avoiding any conflicts in memory access.\nSingle Mutable Reference Rule: This rule is conceptually similar to read-write locks and provides two access states:\nShared, Immutable Access: Multiple immutable references (using \u0026amp;T) to a resource are allowed, resembling the behavior of a read lock. Exclusive, Mutable Access: Only one mutable reference (using \u0026amp;mut T) can exist at any time, akin to a write lock, preventing simultaneous modifications by others and ensuring safe mutation. By enforcing these rules, Rust’s compiler performs a static analysis to eliminate race conditions and memory conflicts at compile time, achieving thread safety without the runtime overhead of locks.\nSafe Memory Management with Stack Allocation Rust’s ownership rules apply to both stack and heap memory management, maintaining safety and efficiency across both types of allocations:\nStack Memory Management: In Rust, variables allocated on the stack are assigned a clear, finite lifecycle determined at compile time, corresponding to the stack’s Last-In-First-Out (LIFO) principle. The ownership system prevents issues like double frees, as the ownership rules guarantee that only the active owner has control over memory deallocation.\nHeap Memory Management: When data is allocated on the heap, Rust’s ownership rules still apply, managing the memory lifecycle through single ownership. Heap memory is controlled by the owning variable, and once the variable goes out of scope, the data is automatically deallocated, freeing developers from the need for manual memory management.\nBorrowing rules further ensure that data on the heap avoids race conditions. By allowing multiple immutable references (akin to a read lock) but only one mutable reference (like a write lock), Rust’s system dynamically enforces safety similar to a runtime read-write lock.\nCase Study: Ownership and Borrowing in Action with Concurrency To illustrate Rust’s ownership and borrowing in action, let’s consider a simple multithreaded example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 use std::thread; fn main() { let mut data = vec![1, 2, 3]; // Transfer ownership of `data` to the spawned thread. let handle = thread::spawn(move || { data.push(4); // Mutating `data`, ownership is now exclusively with the new thread. }); handle.join().unwrap(); // Any attempt to access `data` in the main thread would result in a compilation error, // as ownership has been transferred. } In this example, ownership of data is transferred to the new thread using move, meaning the main thread no longer has access to it. This model functions similarly to an exclusive lock but relies on ownership transfer rather than explicit locks. Rust’s ownership system enforces access control here without locks, allowing memory allocation to remain efficient while eliminating data races at compile time.\nRust’s Advantage: Compile-Time Lock-Like Guarantees Compared to traditional lock-based synchronization, Rust’s ownership and borrowing rules rely on compile-time checks to ensure memory safety, removing the need for runtime locks. The Rust compiler statically analyzes a variable’s lifecycle and reference status, ensuring memory access safety without runtime overhead, which both boosts memory efficiency and minimizes errors.\nConclusion Rust’s ownership and borrowing model integrates the benefits of read-write locks with stack-based memory management principles. By statically enforcing exclusive or shared access, Rust guarantees thread safety and efficient memory management without the performance costs of locks. This unique approach ensures that concurrent programming in Rust is both efficient and safe by design.\n","date":"2024-10-25T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/advanced-rust/","title":"Advanced Rust"},{"content":"用 GitHub 网页端编辑文件 不要在 GitHub 网页端编辑文件！！！否则你会收到下面的警告:\n以及一封邮件：\n我们在将来可能会强制删除你的提交如果你继续在网页端编辑文件。\n10.25 更新：目前已经实装，使用网页进行操作的任何文件会被强制破坏:\nls -d ../*/ 题目要求“列出父文件夹的文件夹项”。可能是翻译问题，Directory entry被我直接翻译成文件夹项可能导致大家（当然还有大家的好帮手 chatGPT）产生了误解，应当翻译为目录项更为准确。\nDirectory entry　是指一个文件夹内包含的如文件夹，文件，链接等项，因此只需要ls ..就可以列出父文件夹的目录项。\n补充信息 ls 通过getdents系统调用获取目录项。getdents就是 get directory entries 的缩写。\ngetdents syscall\n环境变量？ 误区 - Where is Environment Variables? 我看到有同学说在 “.bashrc 里修改环境变量”，这种说法是不准确的。\n环境变量是操作系统的一部分，不是某个文件里的内容。.bashrc 是一个 shell 脚本，用于配置 shell 的行为，它会在　Shell 启动时执行。因此你事实上是在 .bashrc 里添加了修改环境变量的命令。\n那到底环境变量是储存在哪儿的呢？ 环境变量是一个与进程绑定的概念。在进程被创建时，操作系统会将环境变量传递给进程。\n操作系统传递环境 在 fork，exec 等系统调用中，操作系统会在进程的地址空间中创建一个环境变量表，然后将父进程的环境变量表复制到子进程的环境变量表中。并在子进程的sp指针后面的某一个位置存放一个指向环境变量表的指针。\n进程接收环境变量 子进程刚开始运行时（在你们熟知的main函数前），会通过 sp 指针构造参数 int argc, char *argv[], char *envp[]。envp 就是指向环境变量表的指针。这三个参数也是 C 语言的标准 main 函数签名的参数。\n某些跨平台语言会对环境变量的接收方式进行封装，因为不同的操作系统可能有不同的实现。不过你仍然可以通过标准库的函数获取环境变量，例如　C# 的 System.Environment.GetEnvironmentVariable() 和 Python 的 os.environ。\nroot 用户的命令提示符 普通用户的 shell 提示符通常是 $ 或 \u0026gt;，而 root 用户的 shell 提示符通常是 #。\n连续创建嵌套文件夹 记得添加 -p 选项。如\n1 mkdir -p top/middle/bottom 重命名 test 文件夹为 test1？ 可能错误的做法：\n1 mv test/ test1/ 正确的做法：\n1 mv test test1 问题？\n1 2 3 4 5 6 7 8 9 10 11 12 13 caiyi@LAPTOP-I80ETG8J /tmp \u0026gt; cd $(mktemp -d) caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; mkdir test caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; mv test/ test1/ caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; ls test1/ caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; # test 被重命名 caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; mkdir test caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; mv test/ test1/ caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; ls test1/ caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; ls test1/ test/ caiyi@LAPTOP-I80ETG8J /t/tmp.mABXKSHACy\u0026gt; # test 被移动 Fork 仓库再提交？ 课上说\n工作目录问题 课上说\nLinux 命令执行成功？ 没有报错就是成功了，一般都不会有输出。\nls 命令没有输出 那是因为文件夹就是空的。\n最后 提醒大家不要过度相信 AI，AI 可能会给出错误的答案。即使 AI 给出了正确答案，你也要自己去理解才能更好地掌握知识。\n有的同学的答案太离谱了，完全就是 AI 生成的答案。题目明明是一张图片，但是直接把 markdown 原文复制给 AI，AI 又看不到图片，就只能回答“这是一张图片”。\n但是并不是反对大家使用 AI，只是要保存怀疑和求证的态度，以及自己的思考能力和学习能力。\n","date":"2024-10-22T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/os-week1-%E4%BD%9C%E4%B8%9A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","title":"[OS Week1] 作业常见问题"},{"content":"编码规范 上次课上提醒了，Rust 有 clippy 和 fmt --check 工具来严格检查代码风格，这次作业中有同学的代码风格不够规范，希望大家能够注意一下。\n总的来说，无非就是\n该有空格的地方别省，不该有的地方别多。\n不该 mutable 的变量别加 mut。\n定义变量时就要应该想明白这个变量需不需要是 mutable 的 空格 1. 逗号后面要有空格 这也是英语语法的规范，逗号后面要有空格，前面没有。\nGood:\n1 foo(1, 2, 3); Bad:\n1 foo(1,2,3); 2. Operator 前后要有空格 Good:\n1 2 3 4 let x = 1 + 2; if x \u0026gt; 1 { } Bad:\n1 2 3 4 let x = 1+2; if x\u0026gt;1 { } 3. 函数定义时，参数列表的括号后要有空格，前面不能有 Good:\n1 2 3 fn foo(x: i32) { } Bad:\n1 2 3 4 5 6 7 fn foo (x: i32) { } fn foo(x: i32){ } 4. 括号内不要有空格 Good:\n1 foo(1); Bad:\n1 foo( 1 ); 5. : 标明类型时，与类型间要有空格，前面没有 Good:\n1 let x: i32 = 1; Bad:\n1 2 let x:i32 = 1; let y : i32 = 1; 6. { 与前面的元素间要有空格 Good:\n1 2 3 if x \u0026gt; 1 { } Bad:\n1 2 if x \u0026gt; 1{ } 7. if 和逻辑表达式间要有空格 Good:\n1 2 3 if x \u0026gt; 1 { } Bad:\n没有 bad，你根本编译不过\n8. 不要连续搞多个空行 Good:\n1 2 3 4 5 let x = false; if x { println!(\u0026#34;x is true\u0026#34;); } Bad:\n1 2 3 4 5 6 let x = false; if x { println!(\u0026#34;x is true\u0026#34;); } 9. -\u0026gt; 前后要有空格 Good:\n1 2 3 fn foo() -\u0026gt; i32 { 1 } Bad:\n1 2 3 fn foo()-\u0026gt;i32 { 1 } 10. { 不要单独起一行 我不喜欢（因为我是 Microsoft 系的），但是写 Rust 就要符合 Rust 的规范\nGood:\n1 2 3 fn foo() { println!(\u0026#34;foo\u0026#34;); } Bad:\n1 2 3 4 fn foo() { println!(\u0026#34;foo\u0026#34;); } 11. 别瞎几把缩进 Good:\n1 2 3 fn foo() { println!(\u0026#34;foo\u0026#34;); } Bad:\n1 2 3 fn foo(){ println!(\u0026#34;foo\u0026#34;); } 12. 没必要的地方别加空格 Good:\n1 2 3 fn foo() { println!(\u0026#34;foo\u0026#34;); } Bad:\n1 2 3 fn foo (·) {··· println!(\u0026#34;foo\u0026#34;);···· }···· 为了明显用 · 表示的空格\n该加空格的地方一般加一个就够了，别加一大堆\n例如，行尾注释的 // 前后一个空格就够了\n编码规范总结 大概就这些规则最常用，希望大家能够注意一下，写代码的时候多注意一下，不要让自己的代码风格太差。\n记不得让 clippy 和 fmt --check 来检查一下\nRustlings if1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // if1.rs // // Execute `rustlings hint if1` or use the `hint` watch subcommand for a hint. pub fn bigger(a: i32, b: i32) -\u0026gt; i32 { // Complete this function to return the bigger number! // Do not use: // - another function call // - additional variables if a \u0026gt; b { a } else { b } // HINT: in Rust, if you want to compare two values, // cmp is PREFERRED over \u0026gt;, \u0026lt;, \u0026gt;=, \u0026lt;= // eg. // match a.cmp(\u0026amp;b) { // std::cmp::Ordering::Greater =\u0026gt; a, // _ =\u0026gt; b, // } // std::cmp 可以处理 parital （偏序）关系， // 而运算符会无法处理偏序关系，因此可能出现a \u0026gt; b, a \u0026lt; b 和 a == b 同时为 false 的情况。 // 搜索：自反性 // 因此对于自定义类型，最好使用 cmp 方法。 // 同时，使用 match 控制流还更容易处理多分支的情况。 } if2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // if2.rs // // Step 1: Make me compile! // Step 2: Get the bar_for_fuzz and default_to_baz tests passing! // // Execute `rustlings hint if2` or use the `hint` watch subcommand for a hint. pub fn foo_if_fizz(fizzish: \u0026amp;str) -\u0026gt; \u0026amp;str { if fizzish == \u0026#34;fizz\u0026#34; { \u0026#34;foo\u0026#34; } else if fizzish == \u0026#34;fuzz\u0026#34; { \u0026#34;bar\u0026#34; } else { \u0026#34;baz\u0026#34; } // HINT: in such circumstances, pattern matching is more elegant // match fizzish { // \u0026#34;fizz\u0026#34; =\u0026gt; \u0026#34;foo\u0026#34;, // \u0026#34;fuzz\u0026#34; =\u0026gt; \u0026#34;bar\u0026#34;, // _ =\u0026gt; \u0026#34;baz\u0026#34; // } } if3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // if3.rs // // Execute `rustlings hint if3` or use the `hint` watch subcommand for a hint. pub fn animal_habitat(animal: \u0026amp;str) -\u0026gt; \u0026amp;\u0026#39;static str { // HINT // In real development situations, // if you really need to convert an animal to an identifier and then to habitat, // You should split this function into two functions. // Also, pattern matching is more elegant in this case. let identifier = if animal == \u0026#34;crab\u0026#34; { 1 } else if animal == \u0026#34;gopher\u0026#34; { 2 } else if animal == \u0026#34;snake\u0026#34; { 3 } else { -1 }; // DO NOT CHANGE THIS STATEMENT BELOW let habitat = if identifier == 1 { \u0026#34;Beach\u0026#34; } else if identifier == 2 { \u0026#34;Burrow\u0026#34; } else if identifier == 3 { \u0026#34;Desert\u0026#34; } else { \u0026#34;Unknown\u0026#34; }; habitat } quiz1 1 2 3 4 5 6 7 8 9 10 11 12 13 fn calculate_price_of_apples(qty: i32) -\u0026gt; i32 { if qty \u0026gt; 40 { qty } else { qty * 2 } // HINT: You will like pattern matching // match qty { // 0..=40 =\u0026gt; qty * 2, // _ =\u0026gt; qty // } } alphabetic? 你可能不信，除了你认为的 ascii 英文字母，以下字符都是 alphabetic 的\n字 a Chinese character あ and ア Hiragana and Katakana ㅎ Korean Hangul ａ Fullwidth Letter(this is NOT a) and characters from other languages! in fact, all CJK characters are alphabetic. And letters from other languages like russian, greek, etc. are also alphabetic. But I can\u0026rsquo;t show you because I don\u0026rsquo;t know how to type them.\n这些是由 Unicode 规范定义的，所以 Rust 的 char::is_alphabetic 方法也是按照 Unicode 规范来判断的。\n因此，你可能会想使用is_ascii_alphabetic 而不是 is_alphabetic\n1 2 3 4 5 6 7 8 9 10 11 12 fn main() { assert!(\u0026#39;字\u0026#39;.is_alphabetic()); assert!(\u0026#39;あ\u0026#39;.is_alphabetic()); assert!(\u0026#39;ア\u0026#39;.is_alphabetic()); assert!(\u0026#39;ㅎ\u0026#39;.is_alphabetic()); assert!(\u0026#39;ａ\u0026#39;.is_alphabetic()); // uncomment this line will cause panic // assert!(\u0026#39;1\u0026#39;.is_alphabetic()); println!(\u0026#34;All tests passed!\u0026#34;); } run this code!\nLinks:\nUnicode standard\nRust char::is_alphabetic\n1 2 3 4 5 6 7 8 9 #[must_use] #[stable(feature = \u0026#34;rust1\u0026#34;, since = \u0026#34;1.0.0\u0026#34;)] #[inline] pub fn is_alphabetic(self) -\u0026gt; bool { match self { \u0026#39;a\u0026#39;..=\u0026#39;z\u0026#39; | \u0026#39;A\u0026#39;..=\u0026#39;Z\u0026#39; =\u0026gt; true, c =\u0026gt; c \u0026gt; \u0026#39;\\x7f\u0026#39; \u0026amp;\u0026amp; unicode::Alphabetic(c), } } Extract the second element of a tuple Common solution:\n1 let second = tuple.1; Also, you can use pattern matching to deconstruct the tuple:\n1 let (_, second, ..) = tuple; if you need to the first 3 elements of a 10-element tuple, this is the way to go.\nInclusive range Rust just merged inclusive ranges in 1.80.0(quite recent)\nsee https://github.com/rust-lang/rust/issues/37854\nso you can write:\n1 let slice = \u0026amp;array[1..=3]; This is basically equivalent to:\n1 let nice_slice = \u0026amp;a[1..4]; Implicit range .. 不指定开始和结束端点，实际等价于TYPE::MIN..=TYPE::MAX\n通常情况下为 i32，也就是 -2147483648..=2147483647\n用作 indexer 时类型为 usize，也就是 0..=18446744073709551615\n也可以仅指定一边的端点，例如 ..5 或 5..\nSolutions https://github.com/Loongson-neuq/rustlings-Cai1Hsu/pull/7/files\n","date":"2024-10-22T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/os-week2-%E4%BD%9C%E4%B8%9A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","title":"[OS Week2] 作业常见问题"},{"content":"Git Installations Windows Download installer from Git For Windows\nor use winget\n1 winget install Git.Git Linux Install with your package manager\nMacOS Install with Homebrew\nConfiguration Global Configuration Detailed instructions: manual.caiyi1.me\n1 2 git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;Your Email\u0026#34; Authentication For code hosting services like GitHub, GitLab, Gitee, etc, you have to proof the user pushing(or pull) the code HAS the permission to do so.\nTraditional way is to use SSH key, which is a pair of keys, one is public, one is private. Public key is stored on the server, and private key is stored on your local machine.\n国内平台如 Gitee 只能使用 SSH key 进行认证, 不能使用 credential helper。\nStill widely used, but is outdated. As Git allows custom credential helper, you can use a more secure way(and easier) to authenticate.\nWindows Uses git credential-manager, which is a part of Git for Windows.\nAuth Github 1 git credential-manager github login Follow the GUI instructions to login.\nLinux Auth Github uses GitHub CLI, which is provided by the distro\u0026rsquo;s package manager.\n1 2 # Debian/Ubuntu sudo apt install gh Login with\n1 gh auth login Setup git info\n1 gh auth setup-git Follow the instructions to login.\nBasic Usage Detailed instructions: manual.caiyi1.me\nInit Clone Commit Push Pull Fetch Linux Basics Linux 不只是一个工具，也可以是像 Windows 一样用于日常工作的操作系统。\nKDE 桌面环境提供与 Windows 类似的体验，几乎没有任何学习成本。\nInstallations Choose a way to install Linux Physical Machine\nFull performance Graphics interface Take up a lot of space May not be easy to install if you are not experienced Recommend for those who want immersive experience WSL2\nEasy to install Extremely low performance cost Disk-friendly Battery-friendly Only Command Line Interface, but you still uses Windows\u0026rsquo; GUI Good integration with Host OS(Windows) Can run Linux GUI applications with X server (although not recommended for performance) Virtual Machine - Really not recommended\nReally low performance Memory unfriendly Battery unfriendly Graphics interface Installation Guide\nWhy Linux Excellent Command Line Interface\nShell 各种命令行工具 丰富的管道命令 丰富的脚本语言，易于自动化 Software Package Management\n无需手动下载安装 依赖自动解决 减少重复软件下载 便于卸载，没有毒瘤软件 Developer-friendly\nEditor Vim/Nvim VSCode \u0026hellip; Compiler GCC Clang \u0026hellip; Cross-platform development\nCMake/Make LLVM，GCC OS 内核需要 cross-compile Highly customizable\nShell Window Manager Desktop Environment \u0026hellip; Open Source\n无需担心软件的安全性 无需担心软件的可用性 无需担心软件的可维护性 无需担心软件的隐私问题 (大多数情况，取决于你的使用方式) Shortcomings Sucks when you need to use Windows-only software Suck graphics driver support (Not for all hardware) Suck graphics backend support X.org Old, and has not been updated for a long time May have some security issues May not support some new features But still widely used Good support for software Wayland Lacks many features Bad support for some software Really HIGH rendering latency You can feel it! Not suitable for latency-sensitive games, like rhythm games Nvidia support sucks Games may run with lower performance Higher power consumption than X.org Modern, updated frequently Trending But I still recommend you to use Wayland as long as you don\u0026rsquo;t have any problems with it.\nUnboxing 以下内容以相对稳定且简单 Ubuntu 22 作为演示。\nPackage Manager Whats Package Manager 包管理器用于管理 GNU/Linux 发行版的包（应用），不同于 Windows 的手动下载并安装，在 Linux 下安装 Git 只用输入一条命令。\n可以通过类比的方式理解包管理器和包：\n左右两项不等价\nWindows Linux 应用商店 包管理器 App 包 大多数 Linux 发行版都有自己的包管理器：\nDebian RPM Pacman apt, dpkg yum, rpm pacman Ubuntu 的包管理器是 apt 和 dpkg，其中 apt 用于安装云端软件源的包，dpkg 则用于安装本地包。\n1 2 apt --version # output: apt 2.4.12 (amd64) Usage 如果遇到了网络问题，请跳转下方 Mirror。\n更新软件包列表 在安装包之前，一般会同步云端软件包信息，保证依赖关系的正确。\n1 sudo apt update 更新所有软件包 1 sudo apt upgrade 安装软件源的包 将 \u0026lt;name\u0026gt; 换成要安装的包名，多个则以空格分隔。\n1 sudo apt install \u0026lt;name\u0026gt; 安装本地 deb 包 安装中可能会提示依赖缺失，应使用 apt 安装缺失的依赖。\n1 sudo dpkg -i /path/to/xxx.deb 卸载包 将 \u0026lt;name\u0026gt; 换成要卸载的包名，多个则以空格分隔。\n1 sudo apt remove \u0026lt;name\u0026gt; 查找包 1 apt search xxx Mirror 在使用 apt 时提示网络错误时，可以通过换源解决。\n修改系统重要文件前记得备份：\n1 2 sudo cp /etc/apt/sources.list /etc/apt/sources.list.back sudo vim /etc/apt/sources.list 在 Ubuntu 24.04 之前，Ubuntu 的软件源配置文件使用传统的 One-Line-Style，路径为 /etc/apt/sources.list；从 Ubuntu 24.04 开始，Ubuntu 的软件源配置文件变更为 DEB822 格式，路径为 /etc/apt/sources.list.d/ubuntu.sources。 参考 https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/\n在文件的顶部加入以下行：\n1 2 3 4 5 6 7 # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-backports main restricted universe multiverse 最后更新软件包列表\n1 sudo apt update Install Common Software Pakage for OS Development Git 1 2 sudo apt update sudo apt install git VSCode 以下内容来自 manual\n实体机用户请在 Linux 下安装 VSCode：\n手动安装：\n从 VSCode 官网 下载 deb 包。\n使用 dpkg 安装。\n1 sudo dpkg -i code_xxx.deb 包管理器安装：\n添加源。 1 2 3 4 5 sudo apt-get install wget gpg wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor \u0026gt; packages.microsoft.gpg sudo install -D -o root -g root -m 644 packages.microsoft.gpg /etc/apt/keyrings/packages.microsoft.gpg echo \u0026#34;deb [arch=amd64,arm64,armhf signed-by=/etc/apt/keyrings/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main\u0026#34; |sudo tee /etc/apt/sources.list.d/vscode.list \u0026gt; /dev/null rm -f packages.microsoft.gpg 安装。 1 2 3 sudo apt install apt-transport-https sudo apt update sudo apt install code # or code-insiders Rust 以下内容源自 rCore-Tutorial-Guide-2024S 文档\n如果遇到网络问题 配置环境变量：\n可以在当前终端执行（当前终端有效），或者写入 ~/.bashrc（永久，打开新的终端后）。\n1 2 export RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static export RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup 编辑 ~/.cargo/config：\n添加以下行：\n1 2 3 4 5 [source.crates-io] replace-with = \u0026#39;ustc\u0026#39; [source.ustc] registry = \u0026#34;sparse+https://mirrors.ustc.edu.cn/crates.io-index/\u0026#34; 安装 rustup 1 curl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh QEMU 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 安装依赖 sudo apt install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \\ gawk build-essential bison flex texinfo gperf libtool patchutils bc \\ zlib1g-dev libexpat-dev pkg-config libglib2.0-dev libpixman-1-dev git tmux python3 # 下载 QEMU 源码 wget https://download.qemu.org/qemu-7.0.0.tar.xz # 解压 tar xvJf qemu-7.0.0.tar.xz # 进入子目录 cd qemu-7.0.0 # 编译安装并配置 RISC-V 支持 ./configure --target-list=riscv64-softmmu,riscv64-linux-user make -j$(nproc) Awesome Tools 为了提高开发效率，推荐部分小工具。\nCLI tools ranger: 文件管理器\nbat: 文件查看器，更好的 less\ntmux: 终端复用器\nlazygit: git TUI 管理工具\neza: 有色彩和图标的 ls\nCommand Line Foreword Shell 是一个解释器，它接受用户输入的命令，然后调用相应的应用程序或内建命令函数。\nWindows\nPowerShell - fairly good, but lack customization. Slow, for still using .NET Framework(capability reasons, but can be replaced by .NET) Update to PowerShell 7, which is cross-platform https://aka.ms/PSWindows CMD Unix-like (inclue Linux, MacOS, FreeBSD\u0026hellip;)\nBash - default, but MUCH better than Windows' Zsh - most popular, maybe hard to configure Fish - easy to use, but not recommended for scripting \u0026hellip; like sh, dash 对于 Unix, 各种 Shell 的语法大致相同，内建命令大多数与 Bash 相同。甚至 Windows 的 PowerShell 也开始为某些 Bash 的内建命令通过 alias 提供支持。\nFish 是一个很好的 Shell，但是不适合用于编写脚本，因为它的语法和其他 Shell 不同。因此建议大家使用 Bash 或者 Zsh。如果你想配置一个好看并且功能强大的 Shell，可以尝试使用 Zsh。\nDetailed instructions: manual.caiyi1.me\nShell script Shell 脚本是一种文本文件，其中包含了一系列的命令（和我们在 shell 前端中输入的一样）。Shell 会按照脚本中的命令顺序执行。\n下面尝试把你输入过的命令写入一个脚本文件，然后执行这个脚本文件。\n1 2 3 pwd echo \u0026#34;----------------\u0026#34; ls 执行时，如果使用./script.sh执行，需要给予执行权限，使用chmod +x script.sh。如果调用 shell 执行，例如bash script.sh，则不需要给予执行权限。\n执行 shell 脚本时，会新开一个 shell 进程执行脚本，因此脚本中的变量不会影响到当前 shell。\n脚本的工作目录与执行脚本的 shell 的工作目录相同。不是脚本文件的目录。\nAdditional: Linux Installation Guide WSL2 Boot up your Windows, enter Microsoft Store, search for \u0026ldquo;WSL\u0026rdquo;, select an distro and install it.\nUbuntu is recommended for beginners as it has official support.\nAfter installation, you can open it from Start Menu or Windows Terminal.\nThe first time you uses it, you have to set up a username and password, not asking for your windows\u0026rsquo;s password.\nPhysical Machine Partition your disk in Windows. You have to create at least two partitions, one for Boot volume, one for Root(Where the system files are stored).\nThe Boot volume should be at least 1GB, and the Root volume should be at least 50GB.\nDownload a distro\u0026rsquo;s ISO file from its official website, and flash it to a USB drive to make a bootable drive.\nReboot your computer to BIOS/UEFI, and boot from the USB drive.\nChoose manual partitioning if you don\u0026rsquo;t want to lose your data and Windows.\nAssign the Boot volume to /boot, and the Root volume to /.\nChoose the boot volume to be formatted as FAT32, and the root volume to be formatted as ext4 or Btrfs.\nAfter installation, you can shutdown your computer and unplug the USB drive.\n##MUST READ## You may lose the ability to boot into Windows, as the bootloader is replaced by the Linux bootloader.\nYou can either select the system to boot in the BIOS/UEFI, or use a bootloader like GRUB/rEFInd.\nNote that GRUB can NOT detect bootable devices at runtime while rEFInd can.\nVirtual Machine Download a distro\u0026rsquo;s ISO file from its official website, and create a new VM in your VM software. Assign at least 50GB of disk space and 4GB of RAM.\nMount the ISO file to the VM, and boot from it.\nInstall the system following the instructions along the way.\nYou can choose \u0026ldquo;Clean Install\u0026rdquo; since we don\u0026rsquo;t have any data to lose.\nAfter installation, you can shutdown the VM and unmount the ISO file. Then you can boot into the system.\n","date":"2024-10-19T00:00:00Z","image":"https://loongson-neuq.pages.dev/p/os-week1-git-and-linux-basics/background_hub7bd9424949445f7cb4edac68fee9448_2942088_120x120_fill_box_smart1_3.png","permalink":"https://loongson-neuq.pages.dev/p/os-week1-git-and-linux-basics/","title":"[OS Week1] Git and Linux Basics"},{"content":"基础知识 模块(Module) ​Verilog中的module可以看成一个具有输入输出端口的黑盒子，该黑盒子有输入和输出接口(信号)，通过把输入在盒子中执行某些操作来实现某项功能。(类似于C语言中的函数)\n模块描述 顶层模块(top_module)结构用Verilog语言可描述为：\n1 2 3 4 5 6 7 8 9 module top_module( input a, input b, output out ); ...... endmodule 模块以module 开始，endmodule结束 top_module 为模块名 input : 为输入端口 output: 为输出端口 所有代码必须处于module模块中！ 同理，次级模块(mod_a)结构用Verilog语言可描述为：\n1 2 3 4 5 6 7 8 9 module mod_a( input in1, input in2, output out ); ...... endmodule 注意事项：每个模应单独块处于一个.v文件中，模块名即为文件名(规范代码！)\n模块输入输出信号 输出：output 输入：input 模块的输入输出端口都可看出模块的信号，若不写信号类型则默认为wire类型信号！\n1 2 3 4 // 以下两个语句本质是一致的 input a; input wire a; 除了wire型信号，还有reg型信号，具体详见1.4节！\n模块实例化 如图1所示，top_module的两个输入端口连接到次级模块(mod_a)的输入端口，那如何在top_module模块模块中使用mod_a模块的功能呢？这就需要通过模块实例化，可以把top_module看成C语言中的主函数，次级模块mod_a看成普通函数，这样就可以在主函数中调用其他函数来完成相应的功能！\n在top_module中实例化mod_a的方式为：\n模块实例化语法：模块名 实例名(定义连接port的信号);\n1 2 3 4 5 6 7 8 module top_module( input a, input b, output out ); mod_a instance1 (a, b, out); // 按mod_a定义的端口顺序实例化 mod_a instance2 (.in1(a), .in2(b), .out(out)); // 按mod_a端口名实例化(推荐此种写法) 逻辑块(always、generate) always逻辑块 always块可构建 组合逻辑块 和 时序逻辑块，复杂的逻辑操作都需要处于该逻辑块中，如if、case、for等\n组合逻辑块 1 2 3 4 5 6 7 module top_module(); always @(*) begin ...... end endmodule always逻辑块中任意信号变化时立即触发，执行begin - end之间的语句 begin - end用于将多条语句组成一个代码块，只有一条语句时可省略 时序逻辑电路 1 2 3 4 5 6 7 module top_module(); always @(posedge clk) begin ...... end endmodule clk 信号的上升沿触发 posedge: 上升沿 negedge: 下降沿 generate逻辑块 generate主要结合for循环使用，主要用途有：\n对向量中的多个位进行重复操作 对同一个模块进行多次重复实例化(主要用途) 操作向量 1 2 3 4 5 6 7 8 module top_module(input [7:0] in, output [7:0] out); genvar i; // genvar i;也可以定义在generate内部 generate for(i = 0; i \u0026lt; 8; i = i + 1) begin // verilog中for循环不支持i++ assign out[i] = ^in[7:i]; // ^:异或运算符 end endgenerate endmodule 模块重复多次实例化 1 2 3 4 5 6 7 8 9 10 11 12 module top_module( input a, input b, output out ); genvar i; generate for(i = 0; i \u0026lt; 8; i = i + 1) begin : gen_mod_a // gen_mod_a为每个begin_end结构的名称 mod_a instance2 (.in1(a), .in2(b), .out(out)); end endgenerate endmodule 注意：模块多次实例化时必须写每个begin_end结构的名称(gen_mod_a) 仿真器会通过gen_mod_a来标识生成结构: gen_mod_a[0],gen_mod_a[1]\u0026hellip;. initial块 initial块可以理解为一个初始化块，在initial的起始位置的语句在0时刻即开始执行，之后如果遇到延时，则延时之后执行接下来的语句。\n初始块是不可综合的，因此不能将其转化为带有数字元素的硬件原理图。因此初始块除了在仿真中使用外，并没有太大的作用。\n如:在仿真文件中初始化各种参数：\n1 2 3 4 5 6 7 initial begin sys_clk = 1\u0026#39;b1; sys_rst_n = 1\u0026#39;b0; #50 // #n 代表延时n个时间单位 sys_rst_n = 1\u0026#39;b1; end 注意：\ninitial 块在电路中不可综合，故一般不出现在RTL代码中 initial 一般只在仿真文件中使用 若需要在RTL代码中初始化参数，需要用always块，用initial块会导致错误！\n如下所示，在RTL代码中初始化存储器的方式为：\n1 2 3 4 5 6 7 8 9 10 reg [255:0] char_data[4:0]; always @ (posedge clk) begin char_data[0] \u0026lt;= 256\u0026#39;h0000000000000000000000000000000000000000000000000000000000000000; char_data[1] \u0026lt;= 256\u0026#39;h0000000000000000000000000000000000000000000000000000000000000000; char_data[2] \u0026lt;= 256\u0026#39;h0000000000000000000000000000000000000000000000000000000000000000; char_data[3] \u0026lt;= 256\u0026#39;h0000000000000000000000000000000000000000000000000000000000000000; char_data[4] \u0026lt;= 256\u0026#39;h0000000000000000000000000000000000000000000000000000000000000000; end 赋值方式 Verilog 中赋值方式有三种：连续赋值、阻塞赋值、非阻塞赋值\n连续赋值(assign) 1 assign x = y; 该语句表示把x和y两个信号进行连接，真实的物理连接！ 不能在always块中使用 阻塞赋值(=) 1 2 3 4 5 6 // 组合块 always @(*) begin out1 = a; a = b; out2 = a; end 组合always块中用阻塞式赋值 执行顺序：按照begin_end语句块中的顺序依次执行，上述输出结果为：out1 = a ，out2 = b 非阻塞赋值(\u0026lt;=) 1 2 3 4 5 6 // 时序块 always @(posedge clk) begin out1 \u0026lt;= a; a \u0026lt;= b; out2 \u0026lt;= a; end 时序always块中用非阻塞赋值 执行顺序：begin_end中所有语句并行执行，上述输出结果为：out1 = a ，out2 = a 基础语法 标识符 用途：标识符用于定义常数、变量、信号、端口、参数名、模块名等。 组成：字母、数字、$、下划线任意组合而成 注意事项： 区分大小写(Verilog 和 verilog是不同的) 第一个字符只能是字母或下划线(123demo 是非法标识符) 逻辑值与逻辑运算 逻辑值 Verilog中有4中逻辑值：0、1、x、z\n0: 低电平 1: 高电平 x: 表示状态未知 z: 表示高阻状态 注意：这里的z、x是不区分大小写的(X、Z也可)\n逻辑运算 逻辑运算符：\u0026amp;\u0026amp;(与)、==（相等）、||（或）、!=（不等） 如 m\u0026amp;\u0026amp;n : 判断m和n是否全为真(非0即为真)，真则输出1\u0026rsquo;b1，否则输出1\u0026rsquo;b0 (4’b1010\u0026amp;4’b0101 = 1’b1) 最后输出结果只有1bit 按位运算符：\u0026amp;、|、~、^、~\u0026amp;、~^、~| 如 m\u0026amp;n : 是把m的每一位与n的每一位按位做与运算 (4’b1010\u0026amp;4’b0101 = 4’b0000) 输出结果与m/n的bit数相同 归约运算符： \u0026amp;、|、~、^、\u0026amp;、~^、~| 只有一个参量参与运算时( \u0026amp;为一元运算符),表示规约与，即向量内部进行与运算 1 2 3 \u0026amp;a [3:0] // 表示a[3]\u0026amp;a[2]\u0026amp;a[1]\u0026amp;a[0] 相当于(a[3:0]==4\u0026#39;b1111) |b [3:0] // 表示b[3]|b[2]|b[1]|b[0] 相当于(b[3:0]!=4\u0026#39;b0000) ^c [3:0] // 表示c[3]^c[2]^c[1]^c[0] 即(\u0026amp;4’b0101 = 0\u0026amp;1\u0026amp;0\u0026amp;1 = 1\u0026rsquo;b0 ) 最后输出结果只有1bit 常量的表示方法 与C语言类似，常量主要有：整数型、实数型和字符串型三种\n用十进制整数表示整型常量 (1) 正数：直接写 10 表示位宽为32bit的十进制整数(系统默认) (2) 负数：-10需要用二进制补码表示，多了一位符号位(1 1010) (3) 用科学计数法表示：12.345e3 表示 12345\n用基数法表示整数型常量 [换算成二进制数后的位宽]\u0026rsquo;[数制符号][与数制对应的值]\n二进制(b): 8\u0026rsquo;b1000_1100 十六进制(h): 8\u0026rsquo;h8c 八进制(o): 8\u0026rsquo;o214 十进制(d): 8\u0026rsquo;d140 注意事项：\n当表示二进制时，最好每4位写一个下划线以增强可读性：如8\u0026rsquo;b1000_1100 与8\u0026rsquo;b10001100 是一样的 基数表示法中遇到x时：十六进制表示4个x，八进制中表示3个x 当位宽大于二进制位数时左边自动补0，小于二进制数时2从左边截断！ 字符串(用双引号) 每个字符由1个8位的ASCII码值表示，即需要1byte存储空间 如：“Hello world”字符串由11个ASCII符号构成，需要11byte存储空间 注释方式 Verilog中注释主要有行注释(//)和块注释(/* \u0026hellip;. */)两种，表示方法与C语言一致！\n1 2 3 4 5 6 // 行注释 /* 块注释 */ 变量(wire、reg) Verilog中的变量主要有两种：wire和reg\nwire (1) 线网型(wire): 表示电路间的物理连接，wire定义的变量也可看成信号端口 (2) 当两个wire信号被连续赋值时，在逻辑块中会被映射成真实的物理连线，此时这两个信号端口的变化是同步的！\nreg (1) 寄存器型(reg): 表示一个抽象的数据存储单元 (2) reg 具有对某一时间点状态进行保持的功能\n用法与注意事项 (1) 在always、initial语句中被赋值的变量(赋值号左边的变量)都是reg型变量 (2) 在assign语句中被赋值的变量，为wire型变量\n向量(vector)与 参数(常量) parameter 参数(常量) (1) 参数是一种常量，通常出现在module内部，常被用于定义状态、数据位宽等\n1 parameter STATE = 1\u0026#39;b0; (2) 只作用于声明的那个文件，且可以被灵活改变！ (3) 局部参数localparam，只在本模块中使用\n1 localparam WIDTH = 8; (4) 参数的名称一般为大写，以区分其他变量 向量(vector) vector(向量)，是一组信号的集合,可视为位宽超过1bit 的 wire 信号。\n(1) 定义方式：\n1 2 3 4 5 6 7 // 输入输出型 input [7:0] a,b, output reg [7:0] out // 模块中间向量 wire [7:0] c,d; reg [7:0] d; (2) 向量的位宽定义：\n[upper:lower] 定义位宽，如 [7:0] 表示位宽为8 bit ，即upper=7，lower=0 vector_name可以一次写多个向量 向量片选 a[3:0] 取向量a的0~4位数据 b[n] 取向量b的第n位数据 c[-1:-2] 取向量c的最低2位数据 c[0:3] 取向量c的最高4位数据 多路选择器应用：实现一个 256 选 1 选择器，sel 信号作为选择信号，当 sel = 0 时选择 in[3:0]，sel = 1 时选择 in[7:4],以此类推。\n1 2 3 4 5 6 7 8 9 10 11 module top_module ( input [255:0] in, input [7:0] sel, output [3:0] out ); assign out = {in[sel*4+3], in[sel*4+2], in[sel*4+1], in[sel*4+0]}; // assign out = {in[sel*4 +: 4]}; // assign out = {in[sel*4+3 -: 4]}; endmodule 片选信号sel输入为n位二进制数，当参与运算、充当索引时会自动转换成十进制数 该题所选取的信号片段为: in[sel*4+3: sel*4] ,但这不符合Verilog的片选语法规则故应写成： in[sel*4 +: 4] 表示索引从sel*4开始的高4bit信号\nin[sel*4+3 -: 4] 表示索引从sel*4+3开始的低4bit信号\n或是直接选出需要的每一位，再用{ }拼接成新向量： {in[sel*4+3], in[sel*4+2], in[sel*4+1], in[sel*4+0]}\n三元表达式 (1) 与C语言相同，Verilog也有三元表达式：\n1 condition ? if_true : if_false 当条件为真，表达式值为if_true ，否则表达式值为if_false。\n(2) 应用\n1 2 3 4 5 6 (sel ? b : a) // 一个二选一MUX，通过sel的值选择a或b always @(posedge clk) // 一个T触发器 q \u0026lt;= toggle ? ~q : q; assign out = ena ? q : 1\u0026#39;bz; // 三态缓冲器 分支语句(if-else、case) if-else语句 (1) 最常用的形式：(优势：输出的所有可能都写到，不存在未知电平输出！)\n1 2 3 4 5 6 7 8 9 if (condition1) begin ...... end else if (condition2) begin ...... end else begin ...... end (2) 不建议使用if-else嵌套，会存在优先级问题，导致逻辑混乱， (3) 所有if-else语句都应写成(1)的形式！ (4) 根据条件表达式依次比较，*存在优先级！ *\ncase 语句 (1) 书写形式：\n1 2 3 4 5 6 7 8 9 10 11 12 case (\u0026lt;控制表达式\u0026gt;) \u0026lt;分支语句1\u0026gt;: begin ...... end \u0026lt;分支语句2\u0026gt;: begin ...... end ...... default: begin ...... end endcase 比较\u0026lt;控制表达式\u0026gt;与\u0026lt;分支语句n\u0026gt;的取值相等则执行对应语句，否则执行default后语句！\n(2) 执行完某一分支语句后立即跳出case语句结构，终止case语句执行。 (3) \u0026lt;分支语句n\u0026gt;的取值必须互不相同！ (4) 以encase结束case语句块 (5) 各分支语句间不存在优先级！ (6) 具体应用: 用case语句搭建多路选择器，（以9选1多路选择器为例）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 module top_module ( input [15:0] a,b,c,d,e,f,g,h,i, input [3:0] sel, output [15:0] out ); always @(*) begin case(sel) 4\u0026#39;b0000: out = a; 4\u0026#39;b0001: out = b; 4\u0026#39;b0010: out = c; 4\u0026#39;b0011: out = d; 4\u0026#39;b0100: out = e; 4\u0026#39;b0101: out = f; 4\u0026#39;b0110: out = g; 4\u0026#39;b0111: out = h; default: out = 16\u0026#39;hffff; endcase end endmodule for循环语句 (1) 书写形式：\n1 2 3 4 5 6 integer i; always @(*) begin for(i = 0; i \u0026lt; 8; i = i + 1) begin : for_name ...... end end 执行\u0026lt;循环语句\u0026gt;n次 for_name为每一次循环的名称 关系运算符(\u0026gt;、\u0026lt;、\u0026gt;=、\u0026lt;=) 运算结果为真返回 1 运算结果为假返回 0 若某个操作数值不定(x)，则返回值为 x 拼接运算符({ , }) 拼接 用一对花括号加逗号组成“{ , }”拼接运算符，逗号隔开的数据按顺序拼接成新数据！\n通过拼接实现移位 在左边拼接实现右移，右边拼接实现左移！\n1 2 {a[3:0], 4\u0026#39;b0000} // a[3:0]左移4位 {4\u0026#39;b0000, a[3:0]} // a[3:0]右移4位 连接符中重复多次的操作 语法： {重复次数{vector}}\n1 2 {4{a[3:0]}} // 重复4次a[3:0] {3\u0026#39;d5, 4{a[3:0]}} // 3\u0026#39;d5与a[3:0]重复4次拼接 移位运算符 移位运算符用于将左边操作数左移或右移指定的位数！移位后空闲位用0填充。\n左移运算符：\u0026laquo; 如：4‘b1101 \u0026laquo; 3 结果为：4‘b1000\n右移算法符: \u0026raquo; 如：4‘b1101 \u0026raquo; 3 结果为：4‘b0001\n移位运算符其他用途：左移一位可以看成是乘以 2，右移一位可以看成是除以 2。\n移位运算符代替乘除法可以节省资源！\n完整模块示例 二进制全加器 a、b为输入 1bit 数据 cin为上一个加法器进位输入 cout为本加法器的进位输出 sum = a+b $$ \\begin{array}{c} sum=a \\wedge b \\wedge cin \\\\ cout=(a \\\u0026 b) | (a \\\u0026 cin) | (b \\\u0026 cin) \\end{array} $$ 代码实现：\n1 2 3 4 5 6 7 8 9 10 11 module full_adder( input a, input b, input cin, output sum, output cout ); assign sum = a ^ b ^ cin; assign cout = (a \u0026amp; b) | (a \u0026amp; cin) | (b \u0026amp; cin); endmodule 16进制全加器 16进制全加器如上图所示，它可由上节中16个二进制全加器组合而成。\n用Verilog实现16进制全加器代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 module adder16( input [15:0] a, input [15:0] b, input cin, output [15:0] sum, output cout ); wire [16:0] c; assign c[0] = cin; genvar i; generate for(i = 0; i \u0026lt; 16; i = i + 1) begin : gen_full_adder full_adder instance1 (.a(a[i]), .b(b[i]), .cin(c[i]), .sum(sum[i]), .cout(c[i+1])); end assign cout = c[16]; endmodule 模块中的参数传递 定义可传递参数的模块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 module counter // 参数 #( parameter COUNT_MAX = 25\u0026#39;d24_999_999, parameter STATE = 1\u0026#39;b0 ) ( input wire sys_clk, output reg led_out ); ...... endmodule 带参数模块的实例化 1 2 3 4 5 6 7 counter #( .COUNT_MAX(25\u0026#39;d24_999_999), // 参数赋值 .STATE(1\u0026#39;b0) ) counter_instance ( .sys_clk(sys_clk), .led_out(led_out) ); ","date":"2024-10-19T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/verilog-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"Verilog 基础知识"},{"content":"下载安装包 百度搜索vivado，找到\u0026quot;下载 - Xilinx\u0026quot;，进入vivado下载页面\n选择2023.2版本，下载链接\n下载Windows环境下的在线安装器（Windows Self Extracting Web Installer）\n下载需要登陆AMD。如果已有AMD账户直接填写用户名和密码登陆，如果没有账户则点“Create account”免费创建一个新账户。 点击链接后会要求输入个人信息，随便填即可。 如果在线安装器下载不下来 在线安装 双击运行已下载的可执行文件FPGAs_AdaptiveSoCs_Unified_2023.2_1013_2256_Win64.exe。（使用管理员权限，允许网络访问）\n如果弹出更新窗口，点击“continue”。\n点击“Next”。\n登录下载时注册的AMD账号，点击“Next”。\n选择“vivado”，点击“Next”。\n选择免费的标准版，点击“Next”。\n在“Device”中必勾选“Artix-7”，因为开发板搭载的FPGA是Artix-7，其他器件可以根据需要进行选择，“Design Tools”和“Installation Options”按照默认即可。\n全部“I agree”，点击“Next”。\n选择Vivado安装目录，默认安装在“C:\\Xilinx”下，可以点击浏览或者直接更改路径，注意安装路径中不能出现中文和空格。点击“Next”。\n我由于安装过了，显示和大家不一样。\n查看summary，点击“install”。\n等待安装完成。\n问题 不同版本间的编译逻辑可能有所不同，可能会导致不可预知的差异，我们建议使用比赛指定的23.2版本 注意安装路径不要有中文和空格！包括后续项目文件路径中都不能出现中文和空格！！！ 如果你的用户名不幸的有中文的话，STFW改成英文的吧，不然会有更多奇奇怪怪的bug 如果在线安装器有网络问题的话，尝试关闭魔法多试几次，实在不行使用完整的安装包选择本地安装（官网103GB的版本）。 与代码编辑器的联动 VIVADO使用vscode实现实时纠错与自动补全等功能_vivado代码自动对齐_fujiayu1997zz的博客-CSDN博客 Sublime与Verilog【一】：从安装到使用，提高FPGA开发效率！ - 知乎 (zhihu.com) ","date":"2024-10-18T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/vivado-2023.2%E5%AE%89%E8%A3%85/","title":"vivado 2023.2安装"},{"content":" 缘起 进入本世纪，移动互联网、大数据、云计算、物联网、人工智能等新一代信息技术快速发展，促进形成了不同形态的新型计算系统。计算机人才的培养从“程序性开发能力”进化为更重要的“系统性设计能力”。要求计算系统开发人员必须了解不同系统平台的底层结构，具有系统观和系统思维，能够进行软硬件协同设计及其贯通，以强大的系统平台技术保证各项应用功能的实现，成为能力的关键特性，即计算机系统能力。计算机系统能力培养对于解决计算机领域卡脖子关键问题，培育我国高端芯片、关键基础软件的后备人才尤为紧迫和重要。\n为此，2019年5月，教育部高等学校计算机类专业教学指导委员会授予我校计算机系统能力培养试点高校。我校正式开始计算机系统能力培养试点建设。2019年6月，我校与龙芯建立深度合作关系并签署了框架合作协议，与龙芯中科有限公司合作，成立龙芯华北基地暨龙芯-东北大学（秦皇岛）联合实验室。旨在培养计算机系统能力，以及为我国培养在卡脖子的计算机核心关键技术领域人才。2019年8月，创立龙芯班，主要培养中央处理器（CPU）、操作系统（OS）、编译器（Compiler），以及嵌入式芯片与系统设计等等。\n计算机系统能力竞赛 全国大学生计算机系统能力大赛旨在以学科竞赛推动专业建设和计算机领域创新人才培养体系改革，培育我国高端芯片、关键基础软件的后备人才，始终坚持围绕CPU、编译系统、操作系统、数据库管理系统的设计和实现，在赛题和赛制上不断推陈出新。2024年启动智能系统创新设计赛（小米杯）、智能计算创新设计赛（先导杯），形成了从计算机系统核心软硬件到完整系统的比赛格局。\n作为“计算机类专业系统能力培养”教育生态的重要组成部分，大赛创办八年来，参赛学校、参赛人数不断增加，以赛促学、以赛促教的作用明显，学生的专业核心能力、工程能力、创新能力不断提升，2023年更是成功入选中国高等教育学会《2023全国普通高校大学生竞赛分析报告》竞赛目录，成为计算机领域重要的学科竞赛。\n2024年，多家新闻媒体对赛事报道。钱江晚报，澎湃新闻网等媒体以“继ACM后，计算机系统能力大赛受众多互联网大厂热捧，为啥？”为标题对赛事进行报道。诸多互联网大厂越来越重视CPU，操作系统、编译器等自主化，它们也将目光投到大学系统人才培养上来。它们通过冠名全国大学生系统能力大赛，比如CPU大赛由“龙芯”冠名，编译系统设计赛由华为“毕昇”冠名，智能系统创新设计赛由“小米”冠名，以提前参与到大学系统设计开发人才培养中来。操作系统功能赛由华为、麒麟、龙芯、蚂蚁、OPPO、vivo、小米、龙蜥社区、国科环宇、飞腾等企业专家命题，吸引350支队伍报名，涉及863名同学和159位指导教师。“华为、龙芯等把它们公司的实际科技问题，拿到了比赛当中，看看在校大学生们怎么解决行业前沿问题，真正体现了业界需求和高校人才培养的‘双向奔赴’。\n目标与规划 以培养学员融会贯通计算机系统的软硬件知识，设计出自己的CPU，并在上面运行自己的操作系统，还在上面运行自己的编译器和数据库等系统软件为目标的龙芯班。\n目前，主要面向龙芯班学员开设两门公选课程《CPU设计艺术》和《操作系统》。其中，《CPU设计艺术》课程将于秋季学期十一后开课，《操作系统》将于春季学期开课。\n选拔龙芯班的优秀学员参加全国计算机系统能力竞赛，力争取得优异成绩。\n选拔龙芯班的优秀学员作为助教团队，辅导新学员学习。\n鼓励优秀学员，参加科创课题团队，一生一芯计划和百芯计划等活动，进一步树立投身科技事业的理想和锻炼能力。\n指导教师 方淼，男，东北大学计算机科学与技术专业工学学士学位，大连理工大学计算机应用技术专业工学博士学位，现任计算机工程系副主任（负责本部门教学工作），学院科研团队“语言与智能系统实验室”负责人，学院“计算机系统能力培养实验班（龙芯实验室）”负责人。目前主要从事自然语言理解，机器学习和计算机系统等方向的科研和教学工作。\n王鑫，男，1978年10月生，河北丰南人，东北大学计算机应用技术工学硕士学位，现任教于计算机科学系计算机科学与技术专业，讲师，主要从事教学工作。负责操作系统教学。\n张旭，女，1988年4月出生，河北迁西人，内蒙古大学计算机专业工学硕士学位，现任教于学院实验教学中心，实验师。目前主要从事实验教学工作，指导学生参加2019年（第12届）中国大学生计算机设计大赛软件应用与开发类决赛（作品：基于网络通信的远程解锁工具）荣获全国二等奖。负责CPU设计教学。\n科创课题指导教师暂未列出。\n优秀学员 Photo Profile 孟祥东，2017级，毕业进入龙芯公司基础软件部工作 杨兆鑫，2017级，考入中科院计算所龙芯实验室研究生 陈虹胜，2019级，毕业进入龙芯公司从事研发工作 宋雨，2018级，毕业考入中科大先进研究院，现加入龙芯实验室从事研究工作 田宇，2018级，毕业考入中科大先进研究院，现加入龙芯实验室从事研究工作 付震宇，2019级，保送到中科大 USTC 解博元，2020级，因竞赛优异成绩被华为免试录取 取得成绩 2020年，我校首次入围CPU赛道全国总决赛，荣获团队赛三等奖一项和个人赛三等奖一项。\n2021年，我校再创佳绩，在CPU赛道全国总决赛，获得团队赛三等奖两项，个人赛二等奖一项。\n2022年，我校继续入围CPU赛道全国总决赛，团队赛三等奖一项，个人赛三等奖一项。\n2023年，我们在全国总决赛CPU赛道获得团队赛三等奖两项，在OS赛道，获得团队赛三等奖一项，优胜奖一项。\n2024年，我们在全国总决赛智能系统创新设计赛道获得团队赛一等奖，在CPU赛道获得团队赛二等奖两项，在OS赛道，获得团队赛三等奖一项。\n召唤 如果你有梦想，想设计自己的CPU，运行自己的OS，安装自己设计的编译器，请加入我们！ 如果你有梦想，想在大学期间做一款自己的CPU产品，流出一块自己的芯片，请加入我们！ 如果你有梦想，掌握计算机领域核心技术，到计算机系统能力大赛舞台展现实力，毕业到大厂工作，请加入我们！ 如果你有梦想，希望掌握计算机核心技术，为科技强国做出自己的贡献，请加入我们！ 加入我们，开启你的技术进阶之旅！与志同道合的伙伴一起，探索前沿技术，成就你的未来梦想！ 强烈呼唤各位的到来，独行者速，众行者远！ 报名要求：\n热爱计算机系统和CPU、OS、Compiler设计，有志为国家计算机事业发展做贡献； 积极主动、坚持不懈，有较强的团队责任心和自学能力； 大一、大二，以及大三学生（能专心做芯片设计毕设，工作非考研的同学）。 招生规模：暂定为不超过60人\n开班日期：十一假期后\n报名截止日期： 2024年10月9号 24:00\n加入招新群：231607730\n联系人：\n白聪（OS方向）： QQ：1561331574，邮箱：1561331574@qq.com\n杨欣蕊（CPU方向）：QQ：1010191094，邮箱：1010191094@qq.com\n地点：基础楼304\n","date":"2024-09-28T16:51:51+08:00","permalink":"https://loongson-neuq.pages.dev/p/loongson-lab/","title":"Loongson-Lab"},{"content":"假设你需要连续完成某个相同操作 2 次时，你可能这样写代码：\n1 2 Foo(); Foo(); 通常情况下你都会这样做，而不是使用一个 for loop。\n当这个此时大于或等于 10 次时，你大概就不会一个一个写了，而是使用　for 循环。\n然而，如果你稍微思考一下，你都知道：\n1 2 3 4 Foo(); Foo(); Foo(); // 省略 99997 条 Foo　call。 与\n1 2 3 4 for (ulong i = 0; i \u0026lt; 100_000; i++) { Foo(); } 并不完全等价。\n让我们以 CPU 的视角审视一下这个过程：\n对于第一个版本，就完全是 100, 000 条 call 指令。\n对于第二个版本，来说则是\n1 2 3 4 5 6 7 8 9 设置寄存器　i = 0 // xor rcx, rcx, rcx .loop_begin 判断 i 是否小于 100, 000， 如果不是就跳转　.exit_loop // cmp rcx, 100000　\u0026amp;\u0026amp; jge label 调用 Foo 函数　// call Foo 自增索引寄存器 // inc rcx 回到循环开始 // jmp .loop_begin .exit_loop 这两个版本各有各的优势以及缺陷：\n对于第一个版本：\n完成所有任务将执行 100, 000 条指令 所有指令也将占用 100, 000 * 4 字节的内存 对于第二个版本：\n完成所有任务将执行大约 100，000 * 6 条指令 所有指令仅占用　6 * 4 字节的内存 从性能上讲，第一个版本少执行大量指令，意味着更高的性能。但是从内存占用上讲，第一个版本将消耗大量内存，意味着更大的二进制可执行文件。详细可以看最后一节\n思考 那我们能否找到一个平衡点，即，损失一点内存占用，但是提高性能？\n不难发现，第二个版本的性能损失来自于每次循环中的以下部分：\n判断循环索引寄存器 自增循环索引寄存器 跳转 label 因此，我们的任务便是减少这三条指令的执行次数。那么如何减少呢？\n答案非常简单，让我们按照第一个版本的代码，在循环体中多次调用 Foo()。这样，我们就可以减少循环次数，也就减少了额外的指令开销。\n例如，我们可以按照以下方式改写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 循环次数变成了原来的 1/10 for (ulong i = 0; i \u0026lt; 10_000; i++) { // 循环一次执行十条 call Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); } 这下，我们只需要执行大约 10_000 * 5 + 100_000 条指令，以及大幅减少了执行指令的条数。\n这个过程就是循环优化。大部分编译器都支持这种优化。\n问题 循环优化好是好，但是事情并不总是这么美好。当循环次数不是展开倍率的整数倍时，我们需要在循环完成后再手动执行。当循环次数不是常量时，就更麻烦了！\n要实现一个对于任意给定循环次数 n 都能够正确执行的循环展开，我们可以使用以下代码来实现：\n注意我切换成了 C 语言，这是为了给后面的达夫设备埋下伏笔\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 void task(int n) { const int UNROLL_COUNT = 10; size_t loop_count = (n + UNROLL_COUNT - 1) / UNROLL_COUNT; for (size_t i = 0; i \u0026lt; loop_count; i++) { foo(); foo(); foo(); // 省略 7 行 } // 执行剩余的次数 switch (n % UNROLL_COUNT) { case 9: foo(); case 8: foo(); case 7: foo(); case 6: foo(); case 5: foo(); case 4: foo(); case 3: foo(); case 2: foo(); case 1: foo(); } } 达夫设备 我猜大部分人都会这样写，虽然可能会有一些小区别。然而 Tom Duff 给出了一个估计只有外星人才能一眼看明白的解法1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 void task(int count) { register count; { register n = (count + 7) / 8; switch(count % 8) { case 0: do{ foo(); case 7: foo(); case 6: foo(); case 5: foo(); case 4: foo(); case 3: foo(); case 2: foo(); case 1: foo(); } while (--n \u0026gt; 0); } } } 我特意关闭了语法高亮。一眼看上去，这 tm 是人能写出来的？你大概甚至很难相信这个代码能够通过编译。但它确实可以，并且据 Tom Duff 所说，它运行得很好1。\n我这里给出我直译的版本。尽管仍有一点区别，但是这个区别正是达夫设备的价值所在。\n直译版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void task(int count) { register count; { register n = (count + 7) / 8; switch(count % 8) { case 0: goto .remainder_is_0; case 7: goto .remainder_is_7; case 6: goto .remainder_is_6; case 5: goto .remainder_is_5; case 4: goto .remainder_is_4; case 3: goto .remainder_is_3; case 2: goto .remainder_is_2; case 1: goto .remainder_is_1; } do { .remainder_is_0: foo(); .remainder_is_1: foo(); .remainder_is_2: foo(); .remainder_is_3: foo(); .remainder_is_4: foo(); .remainder_is_5: foo(); .remainder_is_6: foo(); .remainder_is_7: foo(); } while(--n \u0026gt; 0); } } 当刚进入函数时，会先计算余数，并根据余数跳转到循环体内部，先执行相应次数的 foo()。接着，将会开始 do-while 循环，通过循环的方式执行剩下的次数。\n当我们仅考虑 foo() 的执行情况，我们可以得出以下版本的代码。\n意译版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void task(int count) { register count; { register n = (count + 7) / 8; switch(count % 8) { case 0: foo(); case 7: foo(); case 6: foo(); case 5: foo(); case 4: foo(); case 3: foo(); case 2: foo(); case 1: foo(); } do { foo(); foo(); foo(); foo(); foo(); foo(); foo(); foo(); } while(--n \u0026gt; 0); } } 这个版本的代码仅用于你了解这个过程中发生了什么。让我们回到上面直译版的代码。\n我前面提到，直译版的代码于 Tom Duff 给出的版本仍有一点区别。这个区别就是，我在 switch 语句的各个 case 中又使用　goto　跳转到了对应的位置，但是 Tom Duff 直接利用了 switch 语句跳转到了对应的部分。\n在这个过程中，每一个 case 就像 label 一样仅用于标识指令的地址而不影响 switch 语句内部其他的语句的语义，也不影响内部的控制流。\n达夫设备的性能 从性能上讲，达夫设备与我们编写的循环展开或者上面的意译版性能相同。不过，达夫设备并不总是在所有情况下提供最高性能（假设循环展开次数相同）。你可以查看 达夫设备 - 维基百科 了解更多。\n达夫设备应用？ 那么这个“特性”有什么作用呢？\nPuTTY 的作者使用这种特性，在 C 语言中实现了不改变代码控制流的情况下的无栈协程。\n通常来说，对于这样的协程方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public static IEnumerable\u0026lt;int\u0026gt; Fib() { int prev = 0, next = 1; yield return prev; yield return next; while (true) { int sum = prev + next; yield return sum; prev = next; next = sum; } } 会被编译成一个完全状态机：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 public static IEnumerable\u0026lt;int\u0026gt; Fib() =\u0026gt; new FibStateMachine(-2); [CompilerGenerated] private sealed class FibStateMachine : IEnumerable\u0026lt;int\u0026gt;, IEnumerable, IEnumerator\u0026lt;int\u0026gt;, IEnumerator, IDisposable { private int state; private int current; private int prev; private int next; private int sum; int IEnumerator\u0026lt;int\u0026gt;.Current =\u0026gt; this.current; object IEnumerator.Current =\u0026gt; this.current; public FibStateMachine(int state) =\u0026gt; this.state = state; private bool MoveNext() { switch (this.state) { default: return false; case 0: this.state = -1; this.prev = 0; this.next = 1; this.current = this.prev; this.state = 1; return true; case 1: this.state = -1; this.current = this.next; this.state = 2; return true; case 2: this.state = -1; break; case 3: this.state = -1; this.prev = this.next; this.next = this.sum; break; } this.sum = this.prev + this.next; this.current = this.sum; this.state = 3; return true; } IEnumerator\u0026lt;int\u0026gt; IEnumerable\u0026lt;int\u0026gt;.GetEnumerator() { if (this.state == -2) { this.state = 0; return this; } return new FibStateMachine(0); } IEnumerator IEnumerable.GetEnumerator() =\u0026gt; ((IEnumerable\u0026lt;int\u0026gt;)this).GetEnumerator(); void IEnumerator.Reset() =\u0026gt; throw new NotSupportedException(); void IDisposable.Dispose() { } } 可以看到，方法的控制流被编译器完全改变，因为每一个 yield return 语句都意味着下一次进入函数时要从一个新的状态开始继续运行。不仅如此，原有方法现在仅仅返回一个新的状态机对象，而不包含任何实现。这意味着，在原方法中，不改变控制流的情况下很难实现协程效果。\nSimon Tatham 利用达夫设备和宏，在 C 语言中，仅需插入少许代码即可实现无栈协程！就像我在前面给出的 C# 版本的协程一样。你一眼就能理解修改后的协程方法的控制流。\n你可以点击以下链接进行了解\n原文（英语） 译文（站外链接） 然而 Simon Tatham 的无栈协程也仅仅能存在于理论中，并且他给出的代码使用全局变量来保存协程上下文，因此不能同时调用同一个协程方法。而且，就像 Simon Tatham 在最后说的一样，这些“可怕破坏性的 crReturn 宏”，“非常糟糕的清晰度”以及“难如登天的重写复杂度”都阻止你在任何场合使用它。\n不过在了解这些原理的过程中，你的能力又提升了不少，不是吗？\n循环展开的性能 让我们回到文章一开始的三个代码片段。\n并非第一个版本的性能就是第二个版本的 1/6，由于存在大量指令，CPU 取指令同样消耗时间，并且这是一个相对耗时的任务。CPU 也具有分支预测等优化技巧来减少每次条件判断的耗时。并且在这种情况下，分支预测通常有较高的正确率。\n同时，Foo 内部的实现也影响执行效率的倍率。当 Foo 内部的实现越复杂，指令越多，循环所导致的性能缺陷就越不明显。\n因此，当你实际 Benchmark 这两段代码时，可能并不会有那么可观的差距。\n我使用以下代码进行 Benchmark：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 public class BenchmarkLoopUnroll { [MethodImpl(MethodImplOptions.NoInlining | MethodImplOptions.NoOptimization)] public static void Foo() { } [Benchmark] [MethodImpl(MethodImplOptions.NoInlining | MethodImplOptions.AggressiveOptimization)] public void ForLoopCompilerOptimized() { for (int i = 0; i \u0026lt; 1000; i++) { Foo(); } } [Benchmark] [MethodImpl(MethodImplOptions.NoInlining | MethodImplOptions.NoOptimization)] public void ForLoop10TimesUnroll() { for (int i = 0; i \u0026lt; 100; i++) { Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); Foo(); } } [Benchmark] [MethodImpl(MethodImplOptions.NoInlining | MethodImplOptions.NoOptimization)] public void ForLoopNoOptimization() { for (int i = 0; i \u0026lt; 1000; i++) { Foo(); } } [Benchmark(Baseline = true)] [MethodImpl(MethodImplOptions.NoInlining | MethodImplOptions.NoOptimization)] public void HardCodedThousandCall() { Foo(); Foo(); Foo(); // 省略 997 行 } } 使用 RyuJIT 得到以下测试结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // * Summary * BenchmarkDotNet v0.14.0, Ubuntu 24.04 LTS (Noble Numbat) WSL 13th Gen Intel Core i5-13500H, 1 CPU, 16 logical and 8 physical cores .NET SDK 8.0.108 [Host] : .NET 8.0.8 (8.0.824.36612), X64 RyuJIT AVX2 DefaultJob : .NET 8.0.8 (8.0.824.36612), X64 RyuJIT AVX2 | Method | Mean | Error | StdDev | Ratio | RatioSD | |------------------------- |---------:|----------:|----------:|------:|--------:| | HardCodedThousandCall | 1.095 us | 0.0129 us | 0.0120 us | 1.00 | 0.02 | | ForLoopNoOptimization | 1.110 us | 0.0211 us | 0.0187 us | 1.01 | 0.02 | | ForLoop10TimesUnroll | 1.050 us | 0.0193 us | 0.0180 us | 0.96 | 0.02 | | ForLoopCompilerOptimized | 1.070 us | 0.0117 us | 0.0109 us | 0.98 | 0.01 | // * Legends * Mean : Arithmetic mean of all measurements Error : Half of 99.9% confidence interval StdDev : Standard deviation of all measurements Ratio : Mean of the ratio distribution ([Current]/[Baseline]) RatioSD : Standard deviation of the ratio distribution ([Current]/[Baseline]) 1 us : 1 Microsecond (0.000001 sec) // ***** BenchmarkRunner: End ***** Run time: 00:00:59 (59.07 sec), executed benchmarks: 4 可以看到，ForLoopNoOptimization 相较于 HardCodedThousandCall 并没有慢很多，虽然确实慢了一些。不过我们手动展开的方法 ForLoop10TimesUnroll 确实是有效的，并且比编译器自带的优化效果还要好。\n作者: Caiyi Shyu Email: caiyishyu@outlook.com https://swtch.com/duffs-device/td-1983.txt\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-09-25T16:18:43+08:00","permalink":"https://loongson-neuq.pages.dev/p/%E4%BB%8E%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80%E5%88%B0%E8%BE%BE%E5%A4%AB%E8%AE%BE%E5%A4%87/","title":"从循环展开到达夫设备"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] One line code block 1 \u0026lt;p\u0026gt;A paragraph\u0026lt;/p\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-07T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Math Typesetting Stack has built-in support for math typesetting using KaTeX.\nIt\u0026rsquo;s not enabled by default side-wide, but you can enable it for individual posts by adding math: true to the front matter. Or you can enable it side-wide by adding math = true to the params.article section in config.toml.\nInline math This is an inline mathematical expression: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n1 $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$ Block math $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ 1 2 3 $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ 1 2 3 $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ Inline Shortcodes For more details, check out the documentation.\nBilibili video Tencent video YouTube video Generic video file Your browser doesn't support HTML5 video. Here is a link to the video instead. Gist GitLab Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Photo by Codioful on Unsplash\nImage gallery Hugo theme Stack supports the creation of interactive image galleries using Markdown. It\u0026rsquo;s powered by PhotoSwipe and its syntax was inspired by Typlog.\nTo use this feature, the image must be in the same directory as the Markdown file, as it uses Hugo\u0026rsquo;s page bundle feature to read the dimensions of the image. External images are not supported.\nSyntax 1 ![Image 1](1.jpg) ![Image 2](2.jpg) Result Photo by mymind and Luke Chesser on Unsplash\n","date":"2023-08-24T00:00:00Z","permalink":"https://loongson-neuq.pages.dev/p/hugos-markdown-extension-usages/","title":"Hugo's markdown extension usages"}]